[{"content":"昨天下午，我永远失去了我爷爷。\n很遗憾的是，我本来有机会能救他的，尽管三番五次注意过，但还是没有坚持走流程处理自己的判断，没有亲力亲为过问和监控情况。就像前几天看的日剧说的一样，介护过程中，什么问题都可能发生，一次疏忽可能还有希望，但是奇迹不会发生第二次，忽略和没做冗余的应对措施终究带来不可挽回的后果。\n幸好我之前一直有与他同步我的进展，说我在研究ai底层应用，没有给他丢脸，他很高兴；这一点上没有后悔的地方，该说的话都是一期一会的说的，该送的礼物每年都送甚至见面都会带，每次见面都要有最后一面的觉悟。不然我真的后悔死了，可还是留下了后悔的地方，这使我反省。\n他是个桃李满园，光荣的人民教师；是一个简朴勤劳，乐于助人，不喜欢给别人添麻烦，严谨认真，负责任的数学老师；即便90多岁了，还坚持看书看报；而我之所以喜欢看书，也正是因为在小学的时候就和他一起看报，逐渐同化养成了习惯。他太简朴了，用的钱包的封皮早就磨烂了，苹果有时候不舍得吃都放坏了，三块钱的黄糖可以放到融化，但给我压岁钱毫不手软；我也和他每次强调我都去买了很多书。很多人都和我说过他以前帮助困难学生上学，以及鼓励女性不留在乡下要独立读书的故事。\n他喜欢吃马蹄（水果）、蒜泥茄子、饺子、青菜配蒜；他还会做酿豆腐、葛粉等等；这些也同样成为了我的喜好。人类的生命是脆弱的，但是精神是可以永远传承的。我一直认为，一个人的思想还存在的话，这就是他生命的延续。他说的我都记在心里并实践，而且我俩都学过基础学科，他是数学我是物理，可惜物理真没数学难，比起来我物理也学的不好。我自认为是他思想的传承人，希望这点上他能得到慰藉；他是一个乐于传播知识、培养青年、帮助别人的人；而我也希望能让ai落地的价值更好的普世于每一个普通人，以后会以他命名开源一项老人状态监测系统，这样很多事情就不再会发生，可惜我现在能力不足，现在还不能做出实用的东西，惭愧。\n人一旦到老，什么事情都可能发生；为了防止后悔，请一定在每一次见面的时候做好最后一面的准备，多拍点照片多留下回忆，少留下遗憾，想要传达的感情就一定要传达，虽然最后都会化为虚无，但人类最可爱的一点莫过于生命仍跳动时，人与人之间栖息的丰富感情。请务必珍惜眼前人，珍爱生命，莫使金樽空对月。\n世界上最可怕的事情就是“我本可以”。但我知道他肯定不希望我一直遗憾；我只能做到不丢脸，尝试做出有用的东西，若干年后能说一句“很残酷，之做了一点微小的贡献”，要做的事情还有很多，所以要认真做事，人要学会负责任。\n2023年1月3日下午，我永远失去了我爷爷；但他也永远在我心中，从未离去，也会陪伴我经历之后的每一个人生阶段。\n因为如果我走了，即便不在了，想见一个人的话我就会出现，也会一直努力守护它；而我想他也是，不仅是因为我们是同一战线，更是因为我们互相信任，以及爱。\n","date":"2023-01-04T22:00:00+08:00","permalink":"https://sanbuphy.github.io/p/%E7%BA%AA%E5%BF%B5%E6%88%91%E7%9A%84%E7%88%B7%E7%88%B7/","title":"纪念我的爷爷"},{"content":"【注意：多图，难以加载建议科学上网,或查看知乎的镜像文章： https://zhuanlan.zhihu.com/p/596739480 】\nhttps://www.bilibili.com/video/BV1hD4y1k7Ty/\n感谢原视频作者，华为昇腾架构师ZOMI酱（我愿称之为肝帝！）的超级贡献，有个视频提到了他录制的时候是凌晨一点（还有其他的休息时间）\n可以看出他是真正热爱深度学习编译器、AI框架相关工作的，向他学习/致敬！绝对值得一键三连\n第二节-为什么都用计算图 2.1神经网络框架遇到的问题 首要的问题是我们能够如何定义神经网络\n除了程序表示的问题，还要研究怎么让我们的表示在硬件框架能够高效执行。\n深度学习如何进行运行时管理？如何编译呢？如何适配不同后端？\n综上所述，我们先给出了统一表示——计算图\n2.2基于计算图的基本框架组成 形状这么理解（从3，2，5反着理解）：我们有个元素为5的数组，然后这样的数组有两排；这样两排的数组一共有三大块。\n为什么使用张量而不用其他数据结构的优点如上所述。上层表示为张量数组，说明有了统一数据结构可以做一个统一的内存映射，方便做切片等操作。'\n2.3不同数据的张量化表示 2.4基于计算图的计算框架 算子有大有小，小到加减乘除大到右边的那些一堆。\n计算图（DAG）计算框架\n特殊的操作会复杂化计算图。（后续会说）\n这里说的计算图比较简略，想看详细的版本可参考：\n深度学习入门与Pytorch|2.1 计算图的概念与理解 - aHiiLn的文章 - 知乎 https://zhuanlan.zhihu.com/p/412542969\n第三节-怎么用计算图表示自动微分 3.1复习训练过程 反向传播过程就是为了找到最小鞍点（高度非凸函数）\n为什么说自动生成反向计算程序？是因为前向是人工构造的；反向很复杂，我们希望系统可以帮助我们构建。\n3.2反向传播与微分 比如这样的一个网络模型（我们只写了正向传播）\n那右边的反向程序怎么办？不能手写，希望框架能够自动帮我们构建（构建DAG的有向无环图，即计算图表达我们的正向和反向）\n我们回顾一下自动微分里面涉及到的简单微分方式：\n首先是符号微分：\n（注意到表达式膨胀以及无法求导的算子）\n第二种方法——数值微分\n3.3自动微分 第三种方式——自动微分！\n那么什么是中间变量呢？？\n比如v-1到v5都是中间变量。每经过一个边运算产生一个中间变量。（分治法）\n前面看的是正向的，我们再看看反向。\n在反向传播中，偏导数也算中间变量。\n黄色部分是神经网络的“一层”，把他当成一个抽象函数 Y = G(X) ，其中X是v1,v2组成的一个抽象张量；输出Y就是v3,v4。\n为了更好的在数学上表示Y对X的导数我们引入了雅可比矩阵。 我们计算完最终的导数f(x1,x2）后就要开始反向传播的过程。 我们在v4,v3反向传播的时候先暂时把它当作：\n（实际上这个玩意儿是为了求反向输出：）\n可以看出每个结点无论前后都是接受输入给出输出。\n我们把计算图分离出来看是这样的，注意到有时候我们还是会用到正向的变量，所以我们要吧中间变量存下来。所以说占据显存。。。因为神经网络会存大量的中间变量数据。\n两个小问题：\n接下来看几种自动微分的形式：\n看一下mindspore的优化实现\n最后复习一下，有了某个语言表示的计算图（正向）然后有了自动微分，有了正反向的计算图，然后就可以成为深度学习训练之前的完整的计算图。\n3.4 pytorch和tensorflow的区别 这个是自己的额外整理部分。以这样一个计算图为例：\n左边是tensorflow的静态图，先构建然后进入运行时；右边是torch动态图，相当于每一个输出都可以在不同环节得到。类似静态编译和动态编译。\n左图从代码中可以看出静态结构，因为我们可以看到，一旦在一个会话中，我们不能定义新的操作（或节点），可使用sess.run()方法中的feed_dict属性来改变输入变量。他的缺点是：\n对可变维度输入的扩展性很差。例如，一个CNN（卷积神经网络）架构有一个静态的计算图，在28×28的图像上训练，如果没有大量的预处理模板代码，在不同尺寸的图像（如100×100）上就不会有好的表现。 调试性差。这些都是很难调试的，主要是因为用户无法接触到信息流是如何发生的。 erg:假设用户创建了一个畸形的静态图，用户无法直接跟踪这个错误，直到TensorFlow会话在计算反向传播和前向传播时发现一个错误。当模型巨大时，这就成为一个主要问题，因为它既浪费了用户的时间又浪费了计算资源。 pytorch动态图相关的优点为：\n对不同维度输入的可扩展性。对不同维度的输入有很好的扩展性，因为新的预处理层可以动态地加入到网络本身。 调试容易。这些都是非常容易调试的，也是很多人从Tensorflow转向Pytorch的原因之一。由于节点是在任何信息流经它们之前动态创建的，因此错误变得非常容易发现，因为用户完全控制了训练过程中使用的变量。 第四节 计算图优化和执行 4.1 图优化 计算图的好处是作为高层IR表现，把前端具体实现和后者优化隔离。\n计算图的优化是编译器做的：\n常量折叠：有些常量计算比如1+1可以在编译期就算出来，没必要在运行时计算 常量传播：常量传播，顾名思义，就是把常量传播到使用了这个常量的地方去，用常量替换原来的变量。https://www.modb.pro/db/524829 https://blog.csdn.net/qq_36287943/article/details/104974597 算子融合：小算子变成大算子 7 是一些反向的操作。。。（如下图显示）\n他的计算时根据依赖关系丢到一个算子列表，然后计算单元根据我们的算子列表计算出结果。\n4.2 算子调度 在不同的线程池并行（多计算核）可以提高我们的算子计算速度。 假设我们有四台计算设备，对于Inception模块，我们可能不同的算子模块会放到不同的计算设备中运行（下图左侧）\n一旦放在不同设备就有多种调度模式，这里没那么简单，我们还要看看如何处理信息的切分（数据是怎么切分的？怎么分到不同的设备的？）\n切分后可能通过send算子也可能是通讯原语进行传输。\n有关通讯原语可参考openmmlab 的相关推文：\nAI框架基础技术之深度学习中的通信优化\nhttps://zhuanlan.zhihu.com/p/348982652\n或本视频作者的文章：分布式训练硬核技术——通信原语https://zhuanlan.zhihu.com/p/465967735\n实际上这个是非常困难的问题，因为我要考虑计算图怎么切分，怎么切分可以让我的组合优化问题效率更高（对算子进行分发和通讯的手段）\n第五节 AI框架如何表示控制流 AI框架在设计的时候就像做到前后端分离，为了解决这个问题提出了统一标识计算图，通过统一描述可以帮助前端用户更灵活编写算法；计算图也影响了后续优化方式和系统拓展；\n5.1 控制流 以transformer为例：除了if还有很多for循环。\n现在主流有了三种解决方案：（分别是ten py mindspore)\nten和torch最新版本也开始引入第三种方案。\n5.2 tensorflow静态图控制流实现 静态图的控制流原语就是下列图提到的 Enter等那五个，提前声明的好处是可以获得统一描述，不需要反复切换前端语言和运行时，都在runtime解决。\ntf很麻烦要用到各种cond的基础api，虽然封装高层次api比如case之类的还是很难用；torch根据第三种源码转换的方式，可以把前端语句映射到对应的基础控制流api。\n举个例子，一起看看tensorflow里面是怎么添加控制流原语的：\n在tensorflow后面需要调用两个while loop进行嵌套表达。在底层的表达是有一个excution frame帧（里面是一个scope），里面保存了算子的上下文信息；嵌套for就使用了嵌套的执行帧。\ncond是用了 switch和merge原语组成的。实际上还是很难理解使用的\u0026hellip;\u0026hellip;.\n更复杂的操作就是while loop的操作（难怪tf越来越少人用。。）\n接下来看看提供控制流原语的优缺点：（缺点太太太明显了。。需要花时间学习控制流到底是怎么表达和使用的，而且计算图被这么复杂化真的没法看了）\n5.3 pytorch动态图控制流实现 对于torch而言，选择的是复用用户前端api语言控制流语句。\n后端直接选择用库的行为执行算子，如果遇到控制流就在python里面执行。这个最大的好处就是可以灵活使用控制流而且马上输出张量的计算结果。缺点就是可能会带来性能问题，还有runtime开销。。。。无法进行全局计算图优化。\n5.4 mindspore静态图控制流实现 接下来再看看mindspore的做法，源码解析展开和转换计算图。比如可以吧for变成串行的；if和else可以变成两个子图，运行时动态选择子图进行运算。这个好处是用户可以一定程度使用前端宿主控制流语言，同时也可以加速运行时效率，可以全局优化。\n但是算子选择需要硬件支持。。。。部分python控制流代码也不能表示，有一定程度的约束性（并不是完成自由）\n第六节 AI框架如何实现动静统一，torch和mindspore的动静统一现状 6.1动态图转换为静态图的方法 （paddle也有，然后mindspore说是第一次提出的）\n接下来看看具体是怎么实现的 ,先看下trace\nTrace的坏处是因为基于用户代码进行追踪，但这个覆盖率不一定全；所以遍历后变成静态图可能会造成图损失，实际上这个在实际框架比较少。。。。\n以JIT（Just In Time）为例，其实是基于源代码解析。jit是运行时动态编译，在内存里生成和运行一段代码，一边编译一边执行。\n基于源码解析的JIT方式如下：\n4 是一种对于123的解决方式。\n第七节 计算图的挑战与未来 首先回顾一下计算图的基础数据结构：首先是用正向DAG构建反向DAG，计算图主要由节点和边构成的，所以可以叫做数据流图。计算图出现的好处是有了一个统一的表示，做到了分层解耦。\n重要的就是三个优化层！\n作者给出的思考：\n一定需要明确的分层解耦?\npytorch没那么多层为什么这么成功？\n新的diffusion和transform底层优化如何改变？\n计算图不能解决AI 业务的哪些问题？\n再来看更多：\n","date":"2023-01-02T11:14:16+08:00","permalink":"https://sanbuphy.github.io/p/ai%E6%A1%86%E6%9E%B6%E4%B9%8B%E8%AE%A1%E7%AE%97%E5%9B%BE%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%E7%AC%94%E8%AE%B0/","title":"AI框架之计算图的前世今生（笔记）"},{"content":"基础 top 不多说 （我更喜欢htop有时候）\nps 进程信息\nfree 系统内存整体使用率\nldd 动态链接信息\nnm 二进制符号表信息\nobjdump 不多说\nreadelf 不多说\nsysstat工具介绍 sysstat主要作用是观察服务负载，比如cpu\\内存的占用率，网络的使用率以及磁盘写入和读取的速度等。。。\nsudo apt install sysstat\nsysstat工具包含\niostat工具提供cpu使用率以及硬盘吞吐效率 mpstat提供单个或多个处理器相关数据 pidstat 关于运行中的进程 任务 cpu 内存统计等信息 sar工具负责收集，报告并存储系统活跃信息（我感觉这个比较厉害） sar 常见问题：\n没有统计权限，参考：https://blog.csdn.net/lord_y/article/details/100139049 无法打开/sysstat/sa02 没有那个文件或目录：https://blog.csdn.net/lord_y/article/details/100139049 刚开统计权限后，要过一会儿才能在sar -u 看到具体的信息 sar -u 回显说明\n主要看下面两条：\n若iowait过高表示存在I/O 瓶颈，即磁盘I/O无法满足业务需求\n若idle过低持续低于10，表示cpu使用率比较严重，最需要解决的资源是cpu，需要结合内存使用情况判断cpu是否瓶颈，若idle过高但系统响应慢，有可能是cpu等待分配内存，此时应加大内存容量。\n%user 用户模式下消耗的CPU时间的比例； %nice 通过nice改变了进程调度优先级的进程，在用户模式下消耗的CPU时间的比例 %system 系统模式下消耗的CPU时间的比例； %iowait CPU等待磁盘I/O导致空闲状态消耗的时间比例；（即cpu等待io的百分比） %steal 利用Xen等操作系统虚拟化技术，等待其它虚拟CPU计算占用的时间比例； %idle CPU空闲时间比例； 如果想要看实时的10条，可以使用sar -u ALL 1 10\nsar -I 3 1 统计某个硬中断频率 可以用来看是否有异常的硬终端频率。\n比如硬盘中断过高有时候是内存炸了，swap过度。一直在硬盘中断。\n（Q：swap一般什么时候满了？ A:网络卡了发不出信息塞满缓存，一直在交换。。。或者空间碎片过多不连续导致卡爆，可能造成重启事故）\n系统瓶颈判断方法： 除了常见的top和free\n1-怀疑cpu存在瓶颈 可用两个指令查看：\nsar -u sar -q\n2-怀疑内存存在瓶颈可用 sar -B\nsar -r\nsar -w\n3-怀疑I/O存在瓶颈，可用 sar -b\nsar -u\nsar -d\npidstat 查看cpu的使用情况，每秒统计一次\n查看进程的线程运行在那个cpu上，随便找了一个进程为例： pidstat -u -p 587990 -t 查看内存使用情况，每秒统计一次 统计三次\npidstat -r -p 587990 1 3\nRSS 物理内存 VSZ 虚拟内存 majflt/s 大缺页次数，需要读磁盘 minflt/s 小缺页次数，需要读内存 mpstat linux cpu实时监控，每秒显示一次cpu使用状态（类似top）\nmpstat -P ALL 1\nperf 系统性能分析工具，返回cpu正在执行的函数名以及调用栈。\nperf能做什么\n提供各种角度的系统性能分析，cpu/内存 磁盘 网络等等 定位性能异常，辅助性能优化 需要掌握的部分\n性能数据收集 perf stat perf recordf 火焰图的生成 基于perf生成的svg图片，用于展示cpu调用栈 strace 跟踪系统调用与信号（syscall等。。）\n比如跟踪一号进程（init）\nsudo strace -p 1\n统计系统函数调用次数：\n查看系统调用的时间\nsudo strace -p 1 -t 精确到秒 -tt精确到微妙\nstrace能做的事情 判断线程是否卡死 观察耗时操作有哪些 观察加载了那些动态库 观察打开了那些文件 lsof 查看进程打开文件信息，查看某个文件是否被打开\nlsof | grep deleted 处理磁盘已满但是找不到对应大文件的问题。 一种方法是kill相应进程，或者停掉这个文件的应用，让os自动回收磁盘空间。 dmesg【注意 只最近1小时的信息！！！！！！！】 查看内核日志，内核日志也会被syslogd同步转储，转储位置取决于syslogd启动参数。 可以根据dmesg查询指定进程ID是否被系统杀掉 dmesg | grep 进程id 注意 只最近1小时的信息！！！！！！！ 比如linux的oom机制，某个进程占用很大的内存，会导致进程被kill了。。。。cat /var/log/messages | grep Kill是否查到了 Out of memory: Kill process、可以结合more less grep tail查看 /proc 通过虚拟文件（内核数据结构可视化接口）获得内核信息，主要有：\n进程信息 内存资源信息 磁盘分区信息（proc只读，/sys 可以读写） 利用gdb查看死锁问题 gdb attach查看死锁问题\n结论：锁的范围一定要控制好，在复杂的嵌套逻辑中更加需要谨慎。\n再调策过程中，碰到线程不运转的情况，猜测线程已经死锁僵死了，\n定位思路1：\n构造线程，gdb attach $(pid)进入线程 info threads直接查看线程堆栈，查看是否有线程一直在等待锁。 thread $(gdb id)查看线程堆栈 定位思路2：\ntop 查看要调试的进程id gdb pstack pid进入trace模式 thread apply all bt查看所有线程的 back trace信息； 查看所有等待锁的线程，找到最早的一个线程，在代码中找到对应的位置，对应锁的函数，具体锁在哪个线程。 thread 定位锁线程id bt查看bt信息 使用f7进入然后 p lockName查看锁被哪个线程所拥有 taskset busybox工具中的命令，可以将进程放到指定的cpu核上运行，绑核（亲和力）。\npstree 进程树父子关系\nnetstat 监控tcp/ip网络。显示路由表，实际网络连接和每一个网络接口设备的状态信息。\nnetstat -tunlp用于显示tcp udp 的端口和进程的相关情况\nnetstat -tunlp | grep 端口号\nvmstat 属于sysstat包，可以展示给定时间间隔的服务器的状态值（CPU使用率，内存使用，虚拟内存交换情况）\n相比top，可以看到整个机器的cpu 内存 io使用情况，而不是各个进程的cpu 内存使用率。\npidof 快速找到应用的pid，相当于 ps -ef | grep lscpu 不解释\nvalgrind 用于linux程序的内存调试和代码剖析\n用于内存泄漏检测调试。（申请释放不匹配，二次释放，使用释放后内存，使用未初始化内存）\niotop 类似top ，更方便监控进程对磁盘读取情况\nsudo apt install iotop\niostat 对系统的磁盘操作活动进行监视（监视网卡、cpu、tty、磁盘的io负载情况）\nclockdiff 测算设备间系统时间差\nfuser 显示所有正在使用指定的file，file system或者sockets的进程信息。\nlinux情况下，当用umount卸载挂载点会遇到device is busy提示，用fuser就可以查到谁在使用这个资源。当然使用umount -lf [挂载点] 也可以强制卸载\n假设无法卸载的设备为/dev/sdb1\n运行下面命令查看xx用户xx进程正在占用这个设备 fuser -m -v /dev/sdb12 运行命令沙了对应进程 fuser -m -v -k /dev/sdb1 或者fuser -m -v -k -i /dev/sdb1这个会在杀掉进程前进行确认！ 重新umount 查看哪些程序使用tcp的80端口：\nfuser -n tcp 80或者fuser -v -n tcp 80或者fuser -v 80/tcp\ndd 用指定大小块拷贝文件，拷贝同时进行指定的转换（用于备份）\nuptime 系统运行了多长时间。。。。查看多少个用户连接。。。以及平均负载值\nReference 嵌入式无人驾驶系统进阶与调测（本文主要参考）\nhttps://www.bilibili.com/video/BV1MA4y1S7zu/?spm_id_from=333.337.search-card.all.click\nsar —— Linux 上最为全面的系统性能分析工具之一\nhttps://shockerli.net/post/linux-tool-sar/\n","date":"2022-12-31T12:14:16+08:00","permalink":"https://sanbuphy.github.io/p/linux%E5%B8%B8%E8%A7%81%E6%80%A7%E8%83%BD%E4%B8%8E%E7%93%B6%E9%A2%88%E7%AD%89%E7%BB%B4%E6%8A%A4%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%E5%90%88%E9%9B%86/","title":"Linux常见性能与瓶颈等维护监控工具合集"},{"content":"开头安利了一下各种有趣的库（nihui姐姐的知乎也可以看看\n这里面有很多不错的项目实现。\n关于ncnn的所有资料\nhttps://github.com/zchrissirhcz/awesome-ncnn\nncnn源码解析相关资料推荐：\nhttps://blog.csdn.net/just_sort/article/details/111403398\nhttps://www.zhihu.com/column/c_1320446932913762304\nZen（设计理念） ncnn内针对arm的优化代码都是可选的——整个框架并不依赖优化代码，增加了可移植性和兼容性。\nncnn项目使用了Vulkan的API，让一套代码可以在诸如安卓、IOS等任意平台上实现。\n维护性也是ncnn项目的设计理念之一， 为方便开发者阅读，降低阅读成本，ncnn中的优化代码都是可选的，这就相当于整个框架不依赖于优化代码，有利于分离。最后，ncnn作为底层推理框架要考虑兼容性，底层赋能后，开发者就算换代码，也能适用最新框架。\nTHE MAT——ncnn的数据结构 ncnn不需要batchsize。自己加个for循环实现即可。（因为nihui觉得这个只有训练框架才需要拥有）\n所以我只要focus于算子本身要实现的功能，代码少，维护性高。\n最早ncnn用的是opencv的mat，可以支持任意维度batchsize。后来nihui自己写了一个mat，包括浅拷贝，whc基本的东西就固定了。（主要的考虑是性能，以及数据结构的连续性，有没有进行对齐。对于某些arm上没对齐性能差很多）\nMat中加了cstep属性，可以让每一个channel都做一个数据对齐，访问、储存等操作都可以在对齐内存上进行，效率更高。举例来说，如果不加cstep，像armV7就有很多对齐和不对齐的数据，访问速度会存在差异。\n如果channel不对齐，多线程可能出问题，每个线程访问数据的时候cache会跳到别的上面。\n此外，ncnn的数据结构还做了Type-less，起初Mat只能放float数据类型，但int8需要放其他类型的数据，出于兼容性的考虑，Mat在尽量不改变数据结构的基础上，通过层实现的自我约定来实现数据类型解读，降低复杂性，按软件工程中的一句话说就是“约定优于配置”。\n软件工程有一句话：约定优于配置。\n就是在开发中，如果有些值你没有配置的话，那程序会取一个默认值，换句话说，能取默认值的配置，就不需要配置了，这个默认值就是约定。 约定可以减少很多配置 比如说在maven的结构中:（java程序为例）\n/src/main/java目录用来存放java源文件 src/main/resources目录用来存放资源文件，如application.yml文件，mybatis的*mapper.xml文件 /src/test/java目录用来存放java测试文件 /src/test/resources目录用来存放测试资源文件 /target目录为项目的输出位置\n权重相关——为什么分两个文件？ 我们会有个问题：ncnn的模型为什么有两个文件？既然我的结构和权重是成套使用的，为什么两个文件？\n原因是可用性的考虑。AI推理部署有一个很难的环节是模型转换（可能因为某个算子没实现，或者没写好或者参数配置出错or转换失败会导致整个模型都用不了）当遇到这种情况可能会出现 nonsupport layer\u0026hellip;.\n主流遇到这个问题的方法：\n手工用编辑器打开param删除对应的图（直接把我不要的层干掉），ncnn为了能支持这个操作所以留着了。如果其他转换后很难去处理对应的op。如果是人可以编辑的话就可以人工处理这个模型（纯纯二进制文件的话旧旧白给了）\n但是有个设计的遗憾，在ncnn 的param如果要写个数组【 5 = [0,2,3]】，必须写一个-23305(05是id) = 3,0,1,2 （3是个数，我有3个个数） 最后说下bin，就是纯粹放权重的文件（存在的目的），没有任何结构化信息。不知道哪个权重对应xxx。这个bin不能知道任何权重相关信息。\n它的好处是，我可以把其他的模型的bin都合成到一起（比如我you两个模型，我可以直接用concat把他们组合为一个bin）部署起来很方便。\nDynamic——完全动态图 ncnn是非常动态图的推理框架，输入尺寸可以任意大小。ncnn天生适合动态尺寸，在2017年发布时就已具备三种dynamic。\n一是尺寸， ncnn可以任意输入尺寸，一般其他推理加载模型时会需要指定最大尺寸，但ncnn不需要，开发者给它多少它就能算多少。\n二是维度， 动态shape分为两种：知道输入维度和不确定维度，ncnn的算子是直接支持不确定维度操作的，比如BinaryOp运行时接受两维数据，也接受一维和三维数据。\n三是推理图， 在ncnn中，可以在同一模型中实现任意节点到节点的推理路径，像条件判断和循环也可以通过不同子图，换来换去，在运行时判断和调度哪部分需要计算，哪部分不需要计算，这样的动态推理路径可以提升效率。\nnihui怀疑很多框架是因为和训练框架对齐的，因为要考虑batchsize所以才要考虑到静态图。\n举个例子：这里表达的就是c=a+b 但这里不需要考虑到channel，因为是动态的（支持动态的size和channel）。\nncnn的图也是可以动态改变的，比如有这么一个图：a——b——c\n静态图必须固定比如a进，c出；而ncnn可以a进b出或者b进c出等等。。。\n比如d表示是不是人脸，e负责人脸画框；如果d已经不是人脸了，那就可以跳过c到e的计算，相当于节省了计算速度。（动态子图推理）\n对于普通的静态框架e每一次都会得到结果（不管d置信度高不高）\n同样的道理，我们可以针对不同配置的手机设计不同的出口比如X和Y。比如b输出到X，c输出到Y，可以根据不同手机性能配置选择走X还是走Y。\nIs-A——ncnn的纯继承关系设计layer Is-A v.s. Has-A 注意到这里的调用基类操作。我们走算子优化可能做特定参数、size下的优化（只改编部分参数）\nncnn采用了一个纯粹的继承关系去做的架构设计，精心优化的架构代码， 比如：x86、arm、vulkan等都是继承自cpu的一个最基础实践的，当遇到没有优化的参数组合时能方便的回退到cpu基础实现。\n很多框架是在pooling里面加了个kernel，和op分开。这么设计的好处是kernel可以被很多算子用到（比如gemm的kernel可以被卷积、反卷积的算子等等用到）；ncnn不这么做的原因是：kernel和op分离需要两份代码， 这样复杂度就提升了也不方便让你自己写新的实现。方便凝聚算子自身的模块性，减少算子之间的耦合。\n不过很多时候kernel共用性可能并不大，因为很多时候优化是对算子整体的优化，这个是结构特有不可复用。\nCI——代码健壮性检查 使用奇怪的不常见的参数组合进行暴力测试，消除了很多bug。\n强迫症提高覆盖率。\ncodecov无法提供gpu的测试，所以用swiftshader做了gpu相关的测试。\n对于一些奇葩的架构无法跑ci，用qemu直接模拟测试即可。\n对于ncnn有些看上去很简单的单元测试语句，实际上背后包含了各种数据结构和硬件的测试。。。。。\nreference 讲座地址：\nhttps://cloud.tencent.com/developer/salon/live-1346\n优图官方笔记\nhttps://zhuanlan.zhihu.com/p/348587668\n","date":"2022-12-30T17:14:16+08:00","permalink":"https://sanbuphy.github.io/p/ncnn%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5%E4%B8%8E%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%90%AC%E8%AF%BE%E7%AC%94%E8%AE%B0/","title":"ncnn设计理念与软件工程（听课笔记）"},{"content":"前言 最近在接触部分paddle源码，但由于本地搭建特容易出现环境依赖问题和其他奇怪的问题，故选择了docker编译。有很多朋友遇到这类问题第一想法便是：\n直接用vscode gnu global凑合就完事了 （缺点：符号信息缺失） 找个其他可以的服务器编译 （缺点：需要钱） 其他codespace之类的东西 （缺点：速度慢） 直接用 vscode attach docker就完事了（缺点：想要用到clangd配合cmake的compile的json生成完整符号信息，但是attach后我发现我不能给它安装vscode的clangd插件） 综上所述，我们需要一个强大的统一开发环境使用，这时候最好的选择就是docker了，clion可以完美支持c++项目的跳转以及cmake的调试以及符号信息的获取，所以我们使用clion进行符号跳转的查看。\n但clion不像vscode可以很方便的attach，我们需要远程ssh进行处理\n具体编译细节和各平台的编译过程可参考paddle官方手册：https://www.paddlepaddle.org.cn/documentation/docs/zh/develop/install/compile/linux-compile.html#paddlepaddle-paddlepaddle-github-paddle\n一、docker基础依赖安装 如果没有pull docker，先使用：nvidia-docker pull paddlepaddle/paddle:latest-gpu-cuda10.2-cudnn7-dev\n因为我的是11.5的cuda，所以使用nvidia-docker pull paddlepaddle/paddle:latest-dev-cuda11.2-cudnn8-gcc82\npull之后直接run：\n注意！【这里和官方建议不同的是我没有用--network=host而是用-p 50003:22为了ssh的端口映射】\nnvidia-docker run --name paddle-test -v $PWD:/paddle -p 50003:22 -it registry.baidubce.com/paddlepaddle/paddle:latest-dev-cuda11.2-cudnn8-gcc82 /bin/bash 如果你已经run了，直接docker exec -it即可，或者在vscode或clion中直接attach到终端。\n二、换源 进入docker终端后首先对docker内进行一波换源：vim 修改 /etc/apt/sources.list 全部替换为：\ndeb https://mirrors.ustc.edu.cn/ubuntu/ focal main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ focal-security main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-security main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse 三、ssh依赖安装与启动 接下来的操作大体参考：https://www.anquanclub.cn/6674.html\n第一步：安装依赖\napt-get update apt-get install passwd apt-get install openssh-server apt-get install rsync #后续clion同步文件需要用到 第二步：设置登录名密码：通过passwd命令来设置root的密码，比如123456\n第三步：启动ssh服务\nservice ssh start 可以通过ps -e |grep ssh查看服务是否启动\n第四步：修改配置文件，通过vim编辑器打开配置文件 vim /etc/ssh/sshd_config\n在配置文件中随便找个地方写入以下内容(#号后是注释)\nPubkeyAuthentication yes #启用公钥私钥配对认证方式 AuthorizedKeysFile .ssh/authorized_keys #公钥文件路径 PermitRootLogin yes #root能使用ssh登录\n第五步：重启服务\nservice ssh restart 这时候就可以愉快的ssh操作docker了！\n你可以在终端中进行测试，使用：\nssh -p 50003 root@127.0.0.1 输入123456密码发现可以成功进入，这时候已经基本成功，接下来进入到clion配置的环节\n四、Clion配置 接下来进入到clion配置的环节，只要处理好这几个部分就可以完美体验！\n主要参考：https://imhuwq.com/2018/12/02/Clion 使用 Docker 作为开发环境/\n一、工具链设置 在 Clion Settings-Build,Execution,Deployment-Toolchains 页面先新建一个 Toolchains 设置，名字叫 my-project 吧，类型选 Remote Host。 Credential 设置里面填入 Container 的 IP。端口、用户名和密码按自己创建 Docker 镜像的时候来设置。由于我是从源码编译的 Cmake，所以需要变更一下 Cmake 地址为 /usr/local/bin/cmake。大家自己会意，按情况来改就好:\n我的参考实现：（点+号选择远程主机）【如果没有检测到，到cmake或者其他东西，在docker内apt安装一下就好；g++编译器可能自动搜索不到，所以whereis g++看一下地址，然后填入即可】\n二、CMAKE设定 创建 Toolchains 配置后，在 Settings-Build,Execution,Deployment-CMake 页面的 Toolchain 下拉菜单里面选择刚才创建的 my-project。 然后点击 Apply 保存到目前为止的配置:\n我的实现参考：（工具链选择第一步设定的）\ncmake选项中需要加入-DPY_VERSION=3.7 -DWITH_GPU=ON 这是我们需要的cmake参数\n环境处需要带上PATH=/usr/local/cuda/bin/nvcc是因为有可能cmake过程中（我遇到了）遇到了这个提示\nNo CMAKE_CUDA_COMPILER could be found. Tell CMake where to find the compiler by setting either the environment variable \u0026#34;CUDACXX\u0026#34; or the CMake cache entry CMAKE_CUDA_COMPILER to the full path to the compiler, or to the compiler name if it is in the PATH. 你可以把export PATH=/usr/local/cuda/bin:$PATH直接附加到终端或者是加入到环境变量中。\n三、管理同步 其实他的用法就是创建一个tmp（你可以在映射中看到）\n然后把文件拷贝进去编译后再把信息拿回来。\n记得测试连接，根路径自动检测即可\n五、快乐体验 注释：每次重启docker后的操作 需要注意的是，每次重启后我们都需要在docker终端内启动一下ssh服务否则不能使用：\nservice ssh start 这时候已经大功告成，我们可以在下面选择对应的开发环境（如果它没有自动切换的话）\n这时候你会看到它正在传输文件，并且开始有个漫长的符号表加载过程（需要一点点时间，但重复打开后就不需要时间了！）\n如果出现问题可以修改后（大部分是环境变量的问题，根据上面的第二步骤进行修改即可）\n经过漫长的等待我们就可以看到结果了。\ncmake过程坑点注意 cmake过程中可能需要下载一些仓库，但无法成功下载（网络原因），你可以bind 172.17.0.1 走proxy，或者使用这个方法：参考自https://www.cnblogs.com/isLinXu/p/16693491.html\n由于在paddle源码编译过程中，需要安装相应的依赖库，这些依赖库是通过github仓库拉取源码的形式下载下来的。 若docker环境下能够网络通畅的使用github，可跳过此项。 若网络情况不稳定，那么这里建议参考下面，分别将这些仓库手动clone下来，同时要注意当前的目录（放在根目录）。（因为是映射目录，你可以找各种方法在本地下载后放到目标位置即可，有必要的话弄一下DNS）\nextern_gflags https://github.com/gflags/gflags.git extern_cryptopp https://github.com/weidai11/cryptopp.git extern_mkldnn https://github.com/oneapi-src/oneDNN extern_warpctc git clone https://github.com/espnet/warp-ctc.git extern_protobuf https://github.com/protocolbuffers/protobuf.git 虽然有些符号还是不能看到定义和实现，但已经足够看代码了（支持绝大部分，而且可以自由跳转）！（有些是cuda调用so本来就不能看到）\n享受符号跳转带来的遍历把。（有了那个小标志就说明全部加载完成，如果加载符号表过程中卡住了卡了非常久，可以尝试重启clion）\nTensorrt扩展解析 此时有些跳转还是失效的，因为根本没有选择对应编译选项与库，所以我们需要做两步操作：\n增加cmake 选项 -DWITH_TENSORRT=ON 在docker中根据 nvidia 官方教程安装 tensorrt： https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html#installing-debian\n重新启动clion即可成功~（所有nvinfer1相关都点亮了）如果还出现不可跳转的情况，可以点击设置菜单中的 工具——与远程主机重新同步，然后符号加载完后就可以了，实在不行重启clion解决一切问题。\n外传——没clion但用vscode凑合 “放过vscode吧！他只是一个编辑器，不是IDE！”——沃兹季硕德\nvscode下我们可以使用clangd+cmake插件实现一定的跳转功能，之前我们知道了用docker直接attach到vscode是失败的，不能安装插件。\n但clion展示了他的强大功力（可以ssh后使用目标编译链进行编译和符号表的导入操作），那我们可以大胆猜想可以用vscode也直接ssh到docker然后看下是否可以安装插件。\n幸运的是，vscode 在ssh链接docker后是可以安装clangd和cmake插件的，我们只需安装好插件然后配置好下方的build的相关参数，等他自己构建即可。\n我的话是生成了clangd需要使用的compile_commands.json 文件。在paddle的根目录下使用这个即可成功！（CMAKE_EXPORT_COMPILE_COMMANDS为了生成json）\ncmake . -B build -DPY_VERSION=3.7 -DWITH_GPU=ON -DCMAKE_EXPORT_COMPILE_COMMANDS=1 安装生成完后重启vscode即可看到一个index加载过程，等待全部完成后就可以体验基本功能的跳转了（虽然肯定还是没有clion强大，但是对于没有clion的情况下还需要什么自行车呢？而且比GNU global的提示肯定是更全更舒适的）\n如果你想要vscode识别cmake参数，可以在.vscode的settings中添加：\n\u0026#34;cmake.configureArgs\u0026#34;: [ \u0026#34;-DPY_VERSION=3.7\u0026#34;, \u0026#34;-DWITH_GPU=ON\u0026#34;, \u0026#34;-DWITH_TENSORRT=ON\u0026#34;, ], reference 使用ssh连接docker服务器的方法_docker\nhttps://www.anquanclub.cn/6674.html\n【健忘笔记】Clion连接docker远程开发\nhttps://zhuanlan.zhihu.com/p/429270402\n备忘-Docker常用命令 参考：https://zhuanlan.zhihu.com/p/410056073 ","date":"2022-12-24T17:18:16+08:00","permalink":"https://sanbuphy.github.io/p/ubuntu%E4%B8%8Bclion%E5%88%A9%E7%94%A8%E8%BF%9C%E7%A8%8Bdocker%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/","title":"Ubuntu下Clion利用远程Docker开发环境"},{"content":"全文经过各类参考的整理与摘抄（若有错误欢迎邮件告知，感谢。）\n什么是虚函数 为什么需要虚函数？什么时候使用了虚函数？\n比如你有个游戏，游戏里有个虚基类叫「怪物」，有纯虚函数 「攻击」。然后派生出了三个子类「狼」「蜘蛛」「蟒蛇」，都实现了自己不同的「攻击」函数，比如狼是咬人，蜘蛛是吐丝，蟒蛇把你缠起来～～\n然后出现好多怪物的时候就可以定义一个 虚基类指针数组，把各种怪物的指针给它，然后迭代循环的时候直接 monster[i]-\u0026gt;attack() 攻击玩家就行了，大概见下图：\n如果没有虚函数的话，管理一堆差不多但是类型又不一样的对象的时候就比较麻烦了。\n虚函数需要注意的细节 只有成员函数才可定义为虚函数，友元/全局/static/构造函数都不可以 构造函数不可以是虚函数，而析构函数可以且常常是虚函数。 记得加上关键字virtual 成员函数如果不是虚函数，其解析过程发生在编译时而非运行时 派生类可以不覆盖（重写）它继承的虚函数 派生类重写（覆盖）基类中的函数，其中函数名，参数列表，返回值类型都必须一致，并且重写（覆盖）的函数是virtual函数 虚函数在子类和父类中的访问权限可以不同 相关规则： ①如果虚函数的返回值类型是基本数据类型：返回值类型必须相同 ②如果虚函数的返回值类型是类本身的指针或引用：返回值类型可以不同，但派生类的返回值类型小于基类返回值类型 基类与派生类的虚函数名与参数列表相同，至于参数列表为什么一致是为了避免虚函数被隐藏 定义他为虚函数是为了允许用基类的指针来调用子类的这个函数，不代表没有实现。\n定义一个函数为纯虚函数，才代表函数没有被实现。定义纯虚函数是为了实现一个接口，起到一个规范的作用，规范继承这个类的程序员必须实现这个函数。（抽象类多用）\n基类通常都应该定义一个虚析构函数。即使该函数不执行任何实际操作！ 构造函数不能是虚函数 从vptr角度解释\nvtable: 记录函数指针的一张表。 每个类维护一个虚表。 vptr: 指向虚表vtable的指针。 每个对象拥有一个vptr。\nC++标准并没有明确要求如何实现运行时多态，但是各编译器基本上都基于这种机制，加入小的修改。\n现代的C++编译器对于每一个多态类型，其所有的虚函数的地址都以一个表V-Table的方式存放在一起，虚函数表的首地址储存在每一个对象之中，称为虚表指针vptr，这个虚指针一般位于对象的起始地址。通过虚指针和偏移量计算出虚函数的真实地址实现调用。\n虚函数的调用是通过虚函数表来查找的，而虚函数表由类的实例化对象的vptr指针(vptr可以参考C++的虚函数表指针vptr)指向，该指针存放在对象的内部空间中，需要调用构造函数完成初始化。如果构造函数是虚函数，那么调用构造函数就需要去找vptr，但此时vptr还没有初始化！\n从多态角度解释\n虚函数主要是实现多态，在运行时才可以明确调用对象，根据传入的对象类型来调用函数，例如通过父类的指针或者引用来调用它的时候可以变成调用子类的那个成员函数。而构造函数是在创建对象时自己主动调用的，不可能通过父类的指针或者引用去调用。那使用虚函数也没有实际意义。\n在调用构造函数时还不能确定对象的真实类型（由于子类会调父类的构造函数）；并且构造函数的作用是提供初始化，在对象生命期仅仅运行一次，不是对象的动态行为，没有必要成为虚函数。\n构造对象时需要知道对象的实际类型，而虚函数行为是在运行期间才能确定实际类型的，由于对象还未构造成功，编译器无法知道对象的实际类型，俨然是个鸡和蛋的问题。 如果构造函数是虚函数，那么构造函数的执行将依赖虚函数表，而虚函数表又是在构造函数中初始化的，而在构造对象期间，虚函数表又还没有被初始化，又是个死循环问题。 从编译器的角度去看，构造函数就是为了在编译阶段确定对象类型、分配空间等工作，虚函数为了实现动态多态需要在运行期间才能确定具体的行为，显然构造函数不可能同时具备静态特性和动态特性。\n析构函数可以且常是虚函数 这个原理上就很好理解啦，因为此时 vtable 已经初始化了，完全可以把析构函数放在虚函数表里面来调用。\nC++类有继承时，析构函数必须为虚函数。如果不是虚函数，则使用时可能存在内存泄漏的问题。\n假设我们有这样一种继承关系： 如果我们以这种方式创建对象： SubClass* pObj = new SubClass(); delete pObj; 不管析构函数是否是虚函数(即是否加virtual关键词)，delete时基类和子类都会被释放；\n如果我们以这种方式创建对象： BaseClass* pObj = new SubClass(); delete pObj; 若析构函数是虚函数(即加上virtual关键词)，delete时基类和子类都会被释放； 若析构函数不是虚函数(即不加virtual关键词)，delete时只释放基类，不释放子类； （1）基类的析构函数不是虚函数的话，删除指针时，只有基类的内存被释放，派生类的没有。这样就内存泄漏了。\n（2）析构函数不是虚函数的话，直接按指针类型调用该类型的析构函数代码，因为指针类型是基类，所以直接调用基类析构函数代码。\n（3）养成习惯：基类的析构一定virtual。但如果某个类不包含虚函数，一般表示它将不作为一个基类来使用，因此不使虚析构函数，否则增加一个虚函数表和虚指针，使得对象的体积增大。如果某个类将作为基类那么建议使用虚析构，包含虚函数则这条要求成为必然。无故使用虚析构函数和永远不使用一样是错误的。\n代码测试：\n#include \u0026lt;iostream\u0026gt; using namespace std; class Father { public: Father(){cout\u0026lt;\u0026lt;\u0026#34;contructor Father!\u0026#34;\u0026lt;\u0026lt;endl;}; ~Father(){cout\u0026lt;\u0026lt;\u0026#34;destructor Father!\u0026#34;\u0026lt;\u0026lt;endl;}; }; class Son:public Father { public: Son(){cout\u0026lt;\u0026lt;\u0026#34;contructor Son!\u0026#34;\u0026lt;\u0026lt;endl;}; ~Son(){cout\u0026lt;\u0026lt;\u0026#34;destructor Son!\u0026#34;\u0026lt;\u0026lt;endl;}; }; int main() { Father *pfather=new Son; delete pfather; pfather=NULL; return 0; } /*输出结果为： contructor Father! contructor Son! destructor Father! */ 函数重载、函数隐藏、函数覆盖和函数重写 牢记以下几点，就可区分函数重载、函数隐藏、函数覆盖和函数重写的区别： （1）函数重载发生在相同作用域； （2）函数隐藏发生在不同作用域； （3）函数覆盖就是函数重写。准确地叫作虚函数覆盖和虚函数重写，也是函数隐藏的特例。\n关于三者的对比，李健老师在《编写高质量代码：改善C++程序的150个建议》给出了较为详细的总结，如下表所示：\n三者 作用域 有无virtual 函数名 形参列表 返回值类型 重载 相同 可有可无 相同 不同 可同可不同 隐藏 不同 可有可无 相同 可同可不同 可同可不同 重写 不同 有 相同 相同 相同（协变） 动态绑定 首先知道什么是静态什么是动态：\n静态绑定：程序编译过程中把函数调用与执行调用所需的代码相关联，这种绑定发生在编译期，程序未运行就已确定，也称为前期绑定。 动态绑定：当某个虚函数通过指针或引用调用时，编译器产生的代码直到运行时才能确定到该调用哪个版本的函数（根据该指针所绑定的对象），这种发生于运行期，程序运行时才确定响应调用的方法，也称为后期绑定。 动态绑定只有当我们通过指针或引用调用“虚函数”时才会发生，如果通过对象进行的函数调用，那么在编译阶段就确定该调用哪个版本的函数了（比如基函数的某个方法打印A，继承后改写打印的是B，同时运行基类和继承类的同样方法会发现打印出了AB而不是B，说明运行时才绑定。） 如果派生类没有重写基类的虚函数，那么通过基类指针指向于派生类时，调用虚函数还是调用的基类的虚函数（因为派生类没有重写） 动态绑定与“派生类对象转换为基类对象”是相似的，原理相同 虚函数一定是运行期才绑定么？ - 知乎用户的回答 - 知乎 https://www.zhihu.com/question/491602524/answer/2165605549\n虚函数与多态 在C++泛型编程中可以基于模板template和重载override两种形式来实现静态多态。\n动态多态主要依赖于虚函数机制来实现，不同的编译器对虚函数机制的实现也有一些差异，本文主要介绍Linux环境下gcc/g++编译器的实现方法。\n多态本质上是一种泛型技术，说白了就是试图使用不变的代码来实现可变的算法，要么试图在编译时决定，要么试图在运行时决定。 ——左耳朵耗子-陈皓\n我们知道C++三大特征：继承、多态、封装。\n虚函数为多态提供了基础，并且借助于继承来发挥多态的优势，从而完善了语言设计的封装。\n下面就是运行时多态的简单例子。\n#include\u0026lt;iostream\u0026gt; using namespace std; class Base { public: virtual void show() { cout\u0026lt;\u0026lt;\u0026#34; In Base \\n\u0026#34;; } }; class Derived: public Base { public: void show() { cout\u0026lt;\u0026lt;\u0026#34;In Derived \\n\u0026#34;; } }; int main(void) { Base *bp = new Derived; bp-\u0026gt;show(); // 运行时多态 return 0; } 运行结果：\nIn Derived\n上面程序中最主要的一点是，使用了一个基类指针来调用子类的成员函数。虚函数的调用不依赖调用它的指针或引用本身的类型，而取决于引用或指针所指向的对象类型。\n纯虚函数（抽象类） 虚函数的声明以=0结束，便可将它声明为纯虚函数，包含纯虚函数的类不允许实例化，称为抽象类，但是纯虚函数也可以有函数体，纯虚函数提供了面向对象中接口的功能，类似于Java中的接口。\n语法格式为：virtual 返回值类型 函数名(函数参数) = 0;\n需要抽象类的场景：\n功能不应由基类去完成 无法确认如何写基类的函数 基类本身不应被实例化 就像虽然有Animal类，但是并不能生成一个动物实例，并且Animal的类的成员函数无法定义，需要其派生类Tiger类、Fish类来具体实现\n虚继承 看这样一个例子：\nB和C从A中继承，而D多重继承于B，C。那就意味着D中会有A中的两个拷贝。因为成员函数不体现在类的内存大小上，所以实际上可以看到的情况是D的内存分布中含有2组A的成员变量。如下代码：\nclass A { public: A():a(1){}; void printA(){cout\u0026lt;\u0026lt;a\u0026lt;\u0026lt;endl;} int a; }; class B : public A { }; class C : public A { }; class D: public B , public C { }; int _tmain(int argc, _TCHAR* argv[]) { D d; cout\u0026lt;\u0026lt;sizeof(d); } 输出d的大小为8。也就是d中有2个a成员变量。这样一来如果要使用a就报错了。谁知道你要用哪一个？同样的访问成员函数也会出现“二义性”这个问题。\nd.a=10;//error C2385: 对“a”的访问不明确 d.printA();//error C2385: 对“printA”的访问不明确 即使成员函数有不同的形参表也不行，如下。\nclass A { public: A():a(1){}; void printA(){cout\u0026lt;\u0026lt;a\u0026lt;\u0026lt;endl;} int a; }; class B : public A { public: void printB(){cout\u0026lt;\u0026lt;\u0026#34;from B\u0026#34;\u0026lt;\u0026lt;endl;} }; class C : public A { public: void printB(int v){cout\u0026lt;\u0026lt;\u0026#34;from C\u0026#34;\u0026lt;\u0026lt;endl;} }; class D: public B , public C { }; int _tmain(int argc, _TCHAR* argv[]) { D d; cout\u0026lt;\u0026lt;sizeof(d); d.printB(); } 当然你可以无耻地使用作用域来规避这个问题。但这并不是一个好主意。\nd.B::a=10; d.C::printB(1); 这时候虚继承就挺身而出，扛下搞定此问题的重担了。虚继承是一种机制，类通过虚继承指出它希望共享虚基类的状态。对给定的虚基类，无论该类在派生层次中作为虚基类出现多少次，只继承一个共享的基类子对象，共享基类子对象称为虚基类。虚基类用virtual声明继承关系就行了。这样一来，D就只有A的一份拷贝。\nclass A { public: A():a(1){}; void printA(){cout\u0026lt;\u0026lt;a\u0026lt;\u0026lt;endl;} int a; }; class B : virtual public A { }; class C : virtual public A { }; class D: public B , public C { }; int _tmain(int argc, _TCHAR* argv[]) { D d; cout\u0026lt;\u0026lt;sizeof(d); d.a=10; d.printA(); } 输出d的大小是12（包含了2个4字节的D类虚基指针和1个4字节的int型整数）。而a和printA()都可以正常访问。最典型的应用就是iostream继承于istream和ostream，而istream和ostream虚继承于ios。\nclass istream : virtual public ios{...}; class ostream : virtual public ios{...}; class iostream : public istream, public ostream{...}; 构造和析构顺序 以本图为例\nC() E() A() B() D() F() ~F() ~D() ~B() ~A() ~E() ~C() 可以看出，首先按声明顺序检查直接基类（包括其子树），看是否有虚基类，先初始化虚基类（例中首先初始化C和E）。一旦虚基类构造完毕，就按声明顺序调用非虚基类的构造函数（例中ABDF），析构的调用次序和构造调用次序相反。\n常见关键字 virtual 放在函数的返回值前面，用于表示该成员函数为虚函数 父类虚函数前必须写；子类虚函数前可以省略（不困省不省略，该函数在子类中也是虚函数类型） virtual只能出现在类内部的声明语句之前而不能用于类外部的函数定义 override 一旦类中的某个函数被声明为虚函数，那么在所有的派生类中它都是虚函数。一个派生类的函数如果覆盖了某个继承而来的虚函数，那么它的形参类型必须与基类函数完全一致。\n派生类中如果定义了一个函数与基类中虚函数的名字相同但是形参列表不同，编译器会认为新定义的函数与基类中原有的函数是相互独立的。这会带来一个问题：如果我们本来希望派生类可以覆盖掉基类中的虚函数，但是一不小心把形参列表写错了，这可能与我们的本意不符。\nC++11新标准提供了override关键字来显式地告知虚拟器进行重载，编译器将检查基类是否存在这样的虚函数，否则将无法通过编译。 这样的好处是使得程序员的意图更加清晰（覆盖基类中的虚函数），如果我们使用override关键字标记了某个函数但是该函数没有覆盖已有的虚函数，此时编译器会报错。\n他可以拦截以下错误：\nclass A{ virtual void f1(int) const; virtual void f2(); void f3(); }; calss B:public A{ void f1(int)const override; //正确 void f2(int)override; //错误，参数不一致 void f3()override; //错误，f3不是虚函数 void f4()override; //错误，B没有名为f4的函数 }; final 如果我们定义的一个虚函数不想被派生类覆盖（重写），那么可以在虚函数之后添加一个final关键字，声明这个虚函数不可以被派生类所覆盖（重写） 如果函数有尾指返回类型，那么要放在尾指返回类型后 (since C++11) final 对虚函数的多态性具有向下阻断作用。经 final 修饰的虚函数或经 final 修饰的类的所有虚函数，自该级起，不再具有多态性。 因此，此处一定是编译时绑定，而不是运行时绑定。\n业务代码中，对于多态类，如果确定一个虚函数不会再被覆盖，或者该类不会再被继承，则推荐标上 final。这可以为编译器提供非常有价值的编译优化信息，总而将原本需要推迟到运行期才能确定的虚函数调用提前在编译期就已确定。 如被调用的函数能与上层调用方一起进一步地做函数内联、常量折叠、无用代码消除等优化，则可以压榨出非常可观的性能提升。\n其他 C++20里面解除了虚函数不能是 constexpr的限制，虚函数完全可以在编译期绑定，\n虚函数的话，不是“只能”在运行时动态绑定，也存在可以静态绑定的情况。你能看出来实际调用函数的场合，编译器也有一定可能看出来。这时函数去虚化作为一种优化存在。\n模拟虚函数表技术可参考：\n虚函数技术：多态的上下文+运行时动态类型识别+虚函数表及指针 https://www.toutiao.com/article/7006183609581257228/?wid=1671356502138\nC++中虚函数、虚继承内存模型\nhttps://zhuanlan.zhihu.com/p/41309205\nC++类的3种继承方式，分别是public继承，protected继承，private继承:\nhttps://www.wuyuze.vip/2019/09/06/C-继承关系/\nreference c++虚函数的作用是什么？\nhttps://www.zhihu.com/question/23971699\nC++:44\u0026mdash;关键字virtual、override、final\nhttps://cloud.tencent.com/developer/article/1784495\n虚函数一定是运行期才绑定么？\nhttps://www.zhihu.com/question/491602524\nC++继承(2) - 虚函数与运行时多态\nhttps://blog.csdn.net/shltsh/article/details/45960377\n虚函数技术：多态的上下文+运行时动态类型识别+虚函数表及指针\nhttps://www.toutiao.com/article/7006183609581257228/?wid=1671356502138\n面试必知必会：理解 C++ 虚函数\nhttps://toutiao.io/posts/zaxcvwp/preview\nC++中函数重载、隐藏、覆盖和重写的区别\nhttps://cloud.tencent.com/developer/article/1177174\nC++ 构造函数和析构函数可以是虚函数嘛？\nhttps://blog.csdn.net/qq_28584889/article/details/88749862\n菱形继承和虚继承\nhttps://blog.csdn.net/jackystudio/article/details/17877219\n","date":"2022-12-24T17:14:16+08:00","permalink":"https://sanbuphy.github.io/p/%E8%99%9A%E5%87%BD%E6%95%B0%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%85%B3%E9%94%AE%E5%AD%97virtualoverridefinal/","title":"虚函数基础与关键字virtual、override、final"},{"content":"写在前面 收录了个人喜好觉得品味好的网站（也有一些小工具），\n如果有其他好的建议也欢迎提出，非常感谢。\n不定期更新\n带目录边栏（电脑上可看）：https://sanbuphy.github.io/p/我的计算机学习网站集合/\ngithub开源仓库地址： https://github.com/sanbuphy/my-awesome-cs\n基础素质要求（自勉用，参考NJUPA内的要求）\n提问的艺术\nhttps://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way/blob/main/README-zh_CN.md\n不像弱智一样提问\nhttps://github.com/tangx/Stop-Ask-Questions-The-Stupid-Ways/blob/master/README.md\n部分内容出自以下参考网站，也欢迎关注他们\nPPRP：\nhttps://www.cnblogs.com/pprp/p/8880493.html\n如需转载请注释原出处即可，谢谢\n数学 机器学习相关数学基础\n直观理解机器学习的数学过程\n矩阵求导入门 或者你也可以参考我整理的文章：\nhttps://sanbuphy.github.io/p/矩阵求导简易入门手册/\n李航统计学习基础第一章补数学基础 只需要第一张 补基础，其他有问题再找\nDeep Learning An MIT Press book参考第一章即可，中文版在这或者直接下载附件中dlbook_cn_v0.5-beta。\n概率论与数理统计 陈希孺 概率论与数理统计基础 参考课程视频地址\n【概率统计课程学习总结】1. 台大概率与台湾交通大学统计课 - 奶油煎蛋红烧肉的文章 - 知乎 https://zhuanlan.zhihu.com/p/86071634\n台湾大学 - 頑想學概率：機率一 (Probability (1))\n台湾大学 - 頑想學概率：機率二 (Probability (2))\n台湾交通大学 - 統計學 Statistics\n台湾交通大学 - 高等統計學 Advanced Statistics\n其他\n线代启示录（一位掌握了线代灵魂的老师）\nhttps://ccjou.wordpress.com/\nimmersive linear algebra 线性代数可视化\nhttp://immersivemath.com/ila/index.html\nCS大类 CS自学指南【必看】\nhttps://csdiy.wiki/\n【北美名校CS课程集锦】2.加州大学伯克利分校CS课程全集 - 文兄的文章 - 知乎 https://zhuanlan.zhihu.com/p/102083014\n基本操作 GDB、VIM、GIT、SHELL等常见linux操作基础（慢慢来，在使用中学\nThe Missing Semester of Your CS Education 中文版（强烈推荐） 官方中文站点：https://missing-semester-cn.github.io/ B站：https://www.bilibili.com/video/BV1x7411H7wa?t=2829 南大PA教程最下面的一些简单入门和材料 https://nju-projectn.github.io/ics-pa-gitbook/ics2021/index.html\n命令行的艺术（总结了各种命令行下相关好物） https://github.com/jlevy/the-art-of-command-line git相关\ngit常见操作整理 https://www.ruanyifeng.com/blog/2015/12/git-cheat-sheet.html\n简单的git ssh秘钥教程 https://blog.csdn.net/helloasimo/article/details/123778112\n简单的pr教程 https://mmcv.readthedocs.io/zh_CN/latest/community/pr.html\ngithub linux下的desktop版 https://github.com/shiftkey/desktop/releases\nubuntu常见疑难解答\n快速下载ubuntu镜像: 找到官网下载链接后使用wget下载\n简单安装双系统\n1、安装windows（因为windows的boot优先级比较高）\n2、安装ubuntu，他能检测到和windows并存的状态，选择那个安装即可\n简单更换ubuntu镜像源\nSettings→About→Software Updates→Download from 选择其他服务器，然后找到中国，选择进行测试以便找到最快的站点。 sudo apt-get update: 0% [正在等待报头]问题的解决（参考https://article.itxueyuan.com/XP2rn）\n先断网然后找到Settings→About→Software Updates关闭所有下载 sudo apt-get clean 接下来将/etc/apt/source.list文件内容清空并保存 恢复网络，将第一步中取消掉的四个选项重新点选然后在最佳国内服务器更新即可。 windows常见工具箱\n有关win家的镜像源以及VS等的纯净安装文件，以及各种网络工程师能用到的软件程序安装包 https://msdn.itellyou.cn/\n图吧工具箱（给自己电脑做硬件分析等等 http://www.tbtool.cn/\nDISM++ 最好用的windows控制面板工具箱（直接看release部分下载 https://github.com/Chuyu-Team/Dism-Multi-language\nwindows上安装ubuntu(WSL2)： 1、在microsoft下载ubuntu 2、根据下列方式导出并导入镜像，防止占用C盘空间（默认安装在C盘）http://t.zoukankan.com/davidchild-p-15606786.html （用这个方法还可以及时快照保存~ WSL中如何使用win v2ray的proxy：（直接在wsl里面跑即可） 第一步 安装：https://github.com/v2fly/fhs-install-v2ray（安装后其他步骤参考https://gukaifeng.cn/posts/linux-pei-zhi-v2ray-he-proxychains-shi-xian-ming-ling-xing-dai-li-wu-tu-xing-jie-mian/#1-3-启动-V2Ray 第二步 启动：（因为WSL无法用systemctl，所以直接运行即可，你可以后台运行，也可以在一个终端中运行起来，然后新开一个终端去export ALLproxy之类的就好，参考docker的做法，或者使用proxychains4也可以。）在终端中运行/usr/local/bin/v2ray run -config /usr/local/etc/v2ray/config.json 即可启动！ 第三步 使用：就当作一个已经监听了某个端口的proxy使用即可 正则表达式相关\n正则表达式入门与练习 https://github.com/ziishaned/learn-regex/blob/master/translations/README-cn.md\n正则表达式可视化浏览 https://regexr.com/\n长正则表达式结构可视化 https://regexper.com/\n常用正则表达式汇总（车牌号手机号姓名IP等等） http://obkoro1.com/web_accumulate/codeBlack/正则表达式收集.html\ndocker相关:\ndocker的一切： https://yeasy.gitbook.io/docker_practice/\nNVIDIA docker https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker\ndocker换源（拉镜像极大加速） https://blog.51cto.com/u_13281972/2997681\ndocker pull images — use proxy https://www.lfhacks.com/tech/pull-docker-images-behind-proxy/\ndocker — use proxy（在容器内）\n方法一： -it 以及加上了host命令进入docker后（比如：）\nnvidia-docker run --name paddle-test -v $PWD:/paddle --network=host -it [registry.baidubce.com/paddlepaddle/paddle:latest-gpu-cuda10.2-cudnn7-dev](http://registry.baidubce.com/paddlepaddle/paddle:latest-gpu-cuda10.2-cudnn7-dev) /bin/bash 此时在内部可以看到两个网卡，我们可以监听172ip的某个端口，然后使用\r`export ALL_PROXY=socks5://172.17.0.1:1088` 即可使用proxy。（有时候还不够用，可以加上https的）（不需要host network 只需要bind 172即可使用）\rexport http_proxy=\u0026#34;http://172.17.0.1:8888/\u0026#34; export HTTP_PROXY=\u0026#34;http://172.17.0.1:8888/\u0026#34; export https_proxy=\u0026#34;http://172.17.0.1:8888/\u0026#34; export HTTPS_PROXY=\u0026#34;http://172.17.0.1:8888/\u0026#34; - 方法二：\r1. make sure your proxy bind 172.17.0.1 and port (e.g. 8888)\r2. add that in dockerfile\rENV http_proxy \u0026#34;http://172.17.0.1:8888/\u0026#34; ENV HTTP_PROXY \u0026#34;http://172.17.0.1:8888/\u0026#34; ENV https_proxy \u0026#34;http://172.17.0.1:8888/\u0026#34; ENV HTTPS_PROXY \u0026#34;http://172.17.0.1:8888/\u0026#34; 3. run it 注释：如果遇到curl之类的奇怪的http问题，请env|grep查看有无奇怪的环境变量或者关闭proxy的系统proxy功能。因为无需开启也可以操作。\ndocker磁盘占用查看与缓存清理 https://blog.csdn.net/m0_67390963/article/details/126327604\n利用docker调试代码，以apollo为例： https://zhuanlan.zhihu.com/p/468146522\n不知道变量怎么命名就可以看看：\nhttps://unbug.github.io/codelf/\n其他有趣的文章 有关linux的基础讲解，有配图和自己的理解，推荐一读。\nhttps://segmentfault.com/u/public0821\n一个对cpu和网络了解都非常深入的工程师\nhttps://plantegg.github.io/\n其中最好的一类文章（有关cpu的讲解）https://plantegg.github.io/2021/06/01/CPU的制造和概念/\n一个关于各种生成网络和编码器小论文通读的博主，有些写的还可以（比较基础入门）\nhttps://medium.com/@falconives\njava相关技术栈资料大全博主（还有一些三大件相关的资料，还挺多\nhttp://learn.lianglianglee.com/\nLinux性能分析工具大全（Linux/BSD性能专家Brendan Gregg）\nhttps://www.brendangregg.com/linuxperf.html\n面向程序员的各类调用库清单（主要是C/C++ PYTHON)\nhttps://github.com/programthink/opensource\nGitHub中文排行榜\nhttps://github.com/GrowingGit/GitHub-Chinese-Top-Charts\nGitHub 上有趣、入门级的开源项目\nhttps://github.com/521xueweihan/HelloGitHub\n美化自己的github界面\nhttps://zhuanlan.zhihu.com/p/454597068\ngithub.com/rzashakeri/beautify-github-profile\nhttps://bowenyoung.cn/posts/githubBeautify\n社区制作的一键生成界面：https://rahuldkjain.github.io/gh-profile-readme-generator/\n公众号 / 真没什么逻辑的作者（为什么这么设计系列文章）涉及网络、数据库、操作系统等\nhttps://draveness.me/whys-the-design/\nRoadmap to becoming a developer\nhttps://github.com/kamranahmedse/developer-roadmap\n小林 x 图解计算机基础（国内最好的八股文整理之一）（图解网络和操作系统）\nhttps://xiaolincoding.com/\n操作系统与体系结构 南京大学计算机基础（袁春风）CSAPP的青春版，但比csapp好懂得多（强烈不建议一开始就读csapp\n赶时间可以直接看配套书。\nhttps://www.icourse163.org/course/nju-1001625001#/info\n前置：南京大学计算机基础实验（做了能让你真的变强）https://nju-projectn.github.io/ics-pa-gitbook/ics2021/index.html\n2022 南京大学拔尖计划《操作系统：设计与实现》\n(蒋炎岩 我永远的超级无敌酷炫宝藏男神，还有什么好说的呢？没有他我就永远不懂计算机的美丽\n当然包云岗老师也是我的男神哈哈哈哈哈哈)\n课程主页：http://jyywiki.cn/OS/2022/ (slides、示例代码)\n视频地址： https://www.bilibili.com/video/BV1Cm4y1d7Ur/\n操作系统（哈工大李治军老师）课件可在下方链接获取。\n慕课网: http://www.feemic.cn/mooc/icourse163/1002692015#。 百度云链接：https://pan.baidu.com/s/1h2aEk6A_DGpXkZvRtNmeUw 提取码：qoll 配套实验课：https://www.shiyanlou.com/courses/115 MIT 6.S081: Operating System Engineering\nhttps://csdiy.wiki/操作系统/MIT6.S081/\n浙江大学周亚金老师的操作系统课课件（写的很好，有操作和现代的一些规范备注，我很喜欢）\n在Schedule中可以获取到全部课件\nhttps://yajin.org/os2018fall/\n南京大学软件分析课程：\nhttps://tai-e.pascal-lab.net/pa1.html#_1-作业导览\nhttps://space.bilibili.com/2919428/channel/series\n教科书《计算机体系结构基础》（胡伟武等，第三版）的开源版本\nhttps://github.com/foxsen/archbase\n其他有趣文章:\n如何实现一个elf的loader：https://blog.csdn.net/GoolyOh/article/details/119801160\n从一个ELF程序的加载窥探操作系统内核:\nhttps://blog.csdn.net/goolyoh/category_11298420.html\n如何实现最小的hello world?\nhttps://cjting.me/2020/12/10/tiny-x64-helloworld/\n计算机网络学习 课程类待补充\n其他文章：\ntcp高级疑难汇总案例分析：plantegg.github.io/2021/02/14/TCP疑难问题案例汇总/\n这个博主写了网络编程相关的一系列文章：https://juejin.cn/user/862486453028888/posts\n其中我最喜欢：Nginx一网打尽：动静分离、压缩、缓存、黑白名单、跨域、高可用、性能优化：\nhttps://juejin.cn/post/7112826654291918855\n有前端Nginx服务器在线配置，及大改善修改nginx的配置体验\nhttps://www.digitalocean.com/community/tools/nginx?global.app.lang=zhCN\n项目来源：https://github.com/digitalocean/nginxconfig.io\n数据结构与算法 程序员如何准备面试中的算法\nhttps://wizardforcel.gitbooks.io/the-art-of-programming-by-july/content/00.01.html\nlabuladong 的算法小抄\nhttps://github.com/labuladong/fucking-algorithm\nACWING的课\nhttps://www.acwing.com/activity/\nGitHub\u0026rsquo;s largest open-source algorithm library\nhttps://the-algorithms.com/\n深度学习大类 有关理论基础（但我还是建议直接看李宏毅） 周志华\n南瓜书主页\nhttps://datawhalechina.github.io/pumpkin-book/#/\n周志华《机器学习》手推笔记 by Sophia-11\nhttps://github.com/Sophia-11/Machine-Learning-Notes\n周志华《机器学习》笔记（主要是文本） by yv.l1.pnn\nhttps://zhuanlan.zhihu.com/p/134089340\n李宏毅相关课程\n李宏毅老师的课程主页： https://speech.ee.ntu.edu.tw/~hylee/index.php 这是李老师的个人主页，可以找到每年ML的课程主页，然后获取作业代码和Kaggle链接\n李宏毅《机器学习》： https://www.bilibili.com/video/BV1Ht411g7Ef\n李宏毅机器学习笔记： https://gitee.com/datawhalechina/leeml-notes\n李宏毅《机器学习/深度学习》2021课程： https://www.bilibili.com/video/BV1JA411c7VT?p=34\n李宏毅2022课程： https://www.bilibili.com/video/BV1JK4y1D7Wb/\n李沐动手学深度学习（适合速成，打基础建议李宏毅）\nhttps://zh.d2l.ai/index.html\n李沐深度学习精读\nhttps://github.com/mli/paper-reading\n这个网站给出了不同模型的排名及其开源代码\nhttps://paperswithcode.com/\n开源库/项目 OpenMMLab\nhttps://openmmlab.com/\nhttps://github.com/open-mmlab\npaddle\nhttps://github.com/PaddlePaddle\nDeep Learning Paper Implementations\nhttps://github.com/labmlai/annotated_deep_learning_paper_implementations\nAwesome Machine Learning\nhttps://github.com/josephmisiti/awesome-machine-learning\nAwesome Deep Learning\nhttps://github.com/ChristosChristofidis/awesome-deep-learning\n【杂谈】GitHub上的机器学习/深度学习综述项目合集 - 言有三的文章 - 知乎 https://zhuanlan.zhihu.com/p/60245227\n手写深度学习项目 小土堆 pytorch学习\nhttps://space.bilibili.com/203989554\n霹雳吧啦Wz 图像分类篇章 以及目标检测\nhttps://space.bilibili.com/18161609/channel/collectiondetail?sid=48290\n手写YOLO系列和fast rcnn系列：\nhttps://www.bilibili.com/video/BV1JR4y1g77H\nhttps://space.bilibili.com/472467171\n在线数据集网站 https://universe.roboflow.com/\n3D感知相关 从零开始搭一套激光SLAM出来, 通过代码的角度一点一点地深入学习激光SLAM.\nhttps://github.com/xiangli0608/Creating-2D-laser-slam-from-scratch\n深度学习的杂物间 快速下载torch安装包（wget下载然后直接pip install）\nhttps://download.pytorch.org/whl/torch/\n显卡驱动安装快速方法：\nubuntu-drivers devices\nsudo apt install 输入显示的推荐版本\nCUDA与cuDNN的安装：（直接官网选择）\n注意：a100和3090ti不支持cuda11以下，请装113以上的版本。\n推荐装cuda的时候可以用sh的模式，然后顺带安装了驱动（之前就不用装了）对动态库的默认支持更好\n教程可参考：https://blog.csdn.net/tangjiahao10/article/details/125227005\nhttps://blog.csdn.net/weixin_37926734/article/details/123033286\n(注意，这里默认是最新版本的，你需要在右下角进入档案选择对应版本安装）\nArchive of Previous CUDA Releases https://developer.nvidia.com/cuda-downloads\nhttps://developer.nvidia.com/rdp/cudnn-archive\n注，有时候cudnn自带的deb安装不好用，可以用tar的自己cp代替。\n安装cuda结束后记得把这两个命令加入到~/.bashrc 然后source，且记得修改对应版本（如cuda-11.5）\n（具体的安装和卸载也可以参考https://flywine.blog.csdn.net/article/details/81879514）\nexport PATH=\u0026#34;/usr/local/cuda-11.5/bin:$PATH\u0026#34; export LD_LIBRARY_PATH=\u0026#34;/usr/local/cuda-11.5/lib64:$LD_LIBRARY_PATH\u0026#34; 解决nvcc版本不一致问题（可能的方法，更换runtime映射\nhttps://qiyuan-z.github.io/2022/01/06/解决nvidia-smi和nvcc显示信息与所安装CUDA版本不一致问题/\n解决cudnn找不到 问题（软连接到系统库）\nhttps://blog.csdn.net/qq451882471/article/details/106967942\nCUDA GPG Repository Key\nhttps://forums.developer.nvidia.com/t/notice-cuda-linux-repository-key-rotation/212772\n孪生神经网络的相关实现：\nhttps://blog.csdn.net/weixin_44791964/article/details/107406072\nhttps://blog.csdn.net/lx_ros/article/details/124439120\n深度学习500问\nhttps://github.com/shliang0603/Awesome-DeepLearning-500FAQ\n深度学习部署 GiantPandaCV\n国内最好的部署相关公众平台之一，涉及部署的内容比较多且硬核，五星推荐。\nhttp://giantpandacv.com/resources/\nhttp://giantpandacv.com/project/部署优化/\nncnn推理框架开发版测试\nhttps://zhuanlan.zhihu.com/p/458139435\nBuild \u0026amp; Share Delightful Machine Learning Apps\nhttps://gradio.app/\nCUDA C++ Programming Guide\nhttps://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html\n推理\u0026amp;加速框架 ncnn\nhttps://github.com/Tencent/ncnn\nncnn源码阅读学习\nhttps://blog.csdn.net/sinat_31425585/category_9312419.html\nopenvino\nhttps://space.bilibili.com/38566875\nbbuf老师的onnx学习笔记\nONNX学习笔记 - 知乎 (zhihu.com)\nTVM官方中文手册\nhttps://tvm.hyper.ai/docs/\n实例参考 各种开发版的基础功能调通\nhttps://blog.csdn.net/sxj731533730\n待测试\n成蹊 - 知乎 (zhihu.com)\n有趣的深度学习小程序与应用 比disco diffusion更强大的绘制工具SD：\n在自己电脑运行Stable Diffusion和完整项目下载\nhttps://mp.weixin.qq.com/s/syEkqbBSmTwdi_cPB6Kd3g\nStableDiffusion Int8量化教程与ONNX导出推理\nhttps://mp.weixin.qq.com/s/18EIga7w9y1FG0oWcnysIw\nC与汇编 翁恺的相关视频(入门和进阶)\nhttps://www.icourse163.org/u/wengkai?userId=318013\n100个GDB小技巧：\nhttps://wizardforcel.gitbooks.io/100-gdb-tips/content/part1.html\n标准库收录网站\nhttps://www.cplusplus.com/reference/\n汇编语言在线解析网站\nhttps://godbolt.org/\n内联汇编学习\nhttps://baijiahao.baidu.com/s?id=1722268508697136684\nhttps://www.jianshu.com/p/1782e14a0766\n\u0026ldquo;undefined reference to XXX\u0026quot;问题总结\nhttps://github.com/Captain1986/CaptainBlackboard/blob/master/D%230001-undefined_reference_to_XXX/D%230001.md\n有关硬件开发（嵌入式）的推荐个人博客列表\nhttps://github.com/JesseGuoX/DoHard\nA curated list of C good stuff.\nThis project does not index anything C++-related; only pure C stuff is considered.\nhttps://github.com/sanbuphy/awesome-c\nLLVM编译过程\nwget https://github.com/llvm/llvm-project/releases/download/llvmorg-10.0.0/llvm-10.0.0.src.tar.xz tar xvJf llvm-10.0.0.src.tar.xz cd llvm-10.0.0.src mkdir build cd build cmake .. -DLLVM_ENABLE_RTTI:BOOL=ON -DBUILD_SHARED_LIBS:BOOL=OFF -DCMAKE_BUILD_TYPE=Release -DLLVM_TARGETS_TO_BUILD=“X86;NVPTX” -DLLVM_ENABLE_ASSERTIONS=ON # 如果你想在 NVIDIA Jetson TX2 上进行构建, 请使用 -DLLVM_TARGETS_TO_BUILD=\u0026#34;ARM;NVPTX\u0026#34; make -j 8 sudo make install # 检查你安装的 LLVM 版本 llvm-config —version # 应该是 10.0.0 python anaconda基础\n国内的anaconda镜像下载 https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/\n(windows)anaconda与Jupyter notebook安装教程 https://zhuanlan.zhihu.com/p/37093476\n(linux)anaconda安装教程 下载deb格式的anaconda安装包 安装后在终端使用source ~/.bashrc即可在终端看到(base)标识（不要在管理员模式下运行） anaconda 换源(记得更换源的时候删去default 以及备份原来的） https://blog.csdn.net/qq_33590958/article/details/103291206\npip -i镜像源合集（个人喜欢用百度的） https://www.cnblogs.com/sunnydou/p/5801760.html\n非conda pip直接换源（conf） https://www.runoob.com/w3cnote/pip-cn-mirror.html\nrequirements.txt的生成教程 https://www.cnblogs.com/lvjinfeng/articles/16333180.html\nconda与pip虚拟环境导出与转移（方便移植） https://blog.csdn.net/weixin_42272869/article/details/122471357\nawesome项目（包含了绝大部分的python相关资源）\nhttps://github.com/vinta/awesome-python\nhttp://jobbole.github.io/awesome-python-cn/\nPython Cookbook 3rd Edition\nhttps://python3-cookbook.readthedocs.io/zh_CN/latest/index.html\nPython并行编程\nhttps://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/index.html\nPython 3 标准库实例教程(真正现代、进阶的python教程\nhttps://learnku.com/docs/pymotw\npandas教程\nhttps://pandas.pydata.org/docs/getting_started/install.html\n或者可以看看datawhale的教程\nScipy Lecture Notes//Advanced Python Constructs//Advanced NumP\nhttp://scipy-lectures.org/index.html\nSICP Python 描述 中文版\nhttps://wizardforcel.gitbooks.io/sicp-py/content/\nopencv图像处理100问，可用来查缺补漏（有些格式问题但不影响\nhttps://github.com/gzr2017/ImageProcessing100Wen\n有趣的Python爬虫和Python数据分析小项目（有些方法可能因为是3年前的东西会失效\nhttps://github.com/Alfred1984/interesting-python\nrequests库官方手册（交互常用，主要需理解请求头等）\nhttps://requests.readthedocs.io/en/latest/user/quickstart/#make-a-request\n实例项目等 supervisor + gunicorn + flask 高并发的接口 + 完整（标准）的日志部署\nhttps://zhuanlan.zhihu.com/p/79227989\n教你阅读 Python 开源项目代码（里面有一些基础开源项目可以参考）\nhttps://learnku.com/articles/23010/teach-you-to-read-the-python-open-source-project-code\n很不错的python状态机（可以画成图）展示工具：\nhttps://github.com/laike9m/Cyberbrain\nC++ c++入门学习（看自己兴趣按需索取）\n浙大翁恺（简单，适合快速过一遍）：https://www.bilibili.com/video/BV1dE41167hJ?p=34 南科大于仕琪（现代化，十分推荐）https://www.bilibili.com/video/BV1Vf4y1P7pq?p=1 侯捷老师视频（看完于老师可以无缝衔接，资源就不公开了，推荐看完1、2、3） awesome项目（包含了绝大部分的c++相关资源）\nhttps://github.com/fffaraz/awesome-cpp\nhttp://jobbole.github.io/awesome-python-cn/\nModern CMake 简体中文版\nhttps://modern-cmake-cn.github.io/Modern-CMake-zh_CN/\ncmakelist生成的makefile调试用make VERBOSE=1 而不是 make -nb\ncmake快速入门\nhttps://juejin.cn/post/6844903557183832078\nC++ reference（字典）\nhttps://en.cppreference.com/w/\nc++并发编程\nhttps://paul.pub/cpp-concurrency/\n双笙子佯谬 图形学大佬，Zeno和Taichi Blend的作者\nhttps://space.bilibili.com/263032155\nC++ Core Guidelines\nhttps://github.com/isocpp/CppCoreGuidelines\nGoogle C++ Style Guide\nhttps://google.github.io/styleguide/cppguide.html\nc++手写数据库练习 CMU 15-445: Database Systems\nhttps://csdiy.wiki/数据库系统/15445/\nC++ Standard Draft Sources（一起成为语言律师）\nhttps://github.com/cplusplus/draft\nC++的杂物间 DJI thermal analysis tool 相关教程（日文\nhttps://qiita.com/tutu/items/b5cf2b39dd30786d9064\n音视频相关 音视频原理必看国内大神-雷神\nhttps://blog.csdn.net/leixiaohua1020/article/details/18893769\nffmpeg原理 罗上文\nhttps://ffmpeg.xianwaizhiyin.net/cover.html\n学术论文 查询接受率的网站:\nhttps://www.openresearch.org/wiki/Main_Page\nLaTeX 图片转代码\n点这里mathF\nhttps://web.baimiaoapp.com/image-to-latex\nLaTeX手写字符识别（不知道字符的代码是什么的时候）\nhttp://detexify.kirelabs.org/classify.html\nLaTeX开源OCR方案\nhttps://github.com/lukas-blecher/LaTeX-OCR\n论文翻译\nhttps://tongtianta.site/\n一文网尽CV/Robotics顶会论文常用高级词汇/句式！ by 叶小飞（推荐关注）\nhttps://zhuanlan.zhihu.com/p/415926905\nAI论文检索\nhttps://elicit.org/\n其他日常使用网站 有关思维导图的代码（类似markdown）生成：\nhttps://xzmind.xuanzi.ltd/apps.html\n流程图绘制：\nhttps://app.diagrams.net/\njson可视化：\nhttps://c.runoob.com/front-end/53/\n快速文件传输（随意分享给人不用网盘）(拷贝兔也可以）\nhttps://www.wenshushu.cn/\n偏极客的新闻网，无广告，而且有一套防刷热度算法，也不搞推荐算法\nhttps://news.ycombinator.com/news\nWhisper AI剪视频小工具\nhttps://www.bilibili.com/video/BV1Pe4y1t7de/\nhttps://github.com/mli/autocut/\n有趣的故事 谷歌背后的数学\nhttps://www.changhai.org/articles/technology/misc/google_math.php\n火光摇曳(数学科普) Rickjin(靳志辉) （非常好传递了统计之美）\nhttps://uploads.cosx.org/2014/07/gamma.pdf\n计算的极限\nhttps://fwjmath.wordpress.com/recommended-list/\n心理健康建设 如何在工作中学习（好的方法论）\nhttps://plantegg.github.io/2018/05/24/如何在工作中学习V1.1/\n2017年买房经历总结出来的买房购房知识\nhttps://github.com/houshanren/hangzhou_house_knowledge\n2022年杭州购房指南\ngithub.com/zkqiang/hangzhou-house-guide\n2020年11月上海购房指南\ngithub.com/ayuer/shanghai_house_knowledge\n英语 英文语法在线修改 https://www.grammarly.com/\nhttps://www.nounplus.net/grammarcheck/\nhttps://virtualwritingtutor.com/\n英文论文好用工具 TextRanch 句子参考\nhttps://textranch.com/\nQuillBot 文段改写\nhttps://quillbot.com/\n","date":"2022-12-23T12:08:27+08:00","permalink":"https://sanbuphy.github.io/p/%E6%88%91%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%AB%99%E9%9B%86%E5%90%88/","title":"我的计算机学习网站集合"},{"content":"首先建议你了解下事件驱动模型：\nhttps://www.cnblogs.com/wdliu/p/6890930.html\nPython线程、协程探究（3）——协程的调度实现大龙\nhttps://zhuanlan.zhihu.com/p/96969508\npython cookbook 11.12 理解事件驱动的IO\nhttps://python3-cookbook.readthedocs.io/zh_CN/latest/c11/p12_understanding_event_driven_io.html\n需要注意的是，协程并不是万能的，由于系统事件循环的限制，所以文件IO一般还是使用多线程来执行，具体见：github.com/python/asyn…\n协程的关键在于future、task。\n与Coroutine只有让步和接收结果不同的是Future除了让步和接收结果功能外，它还是一个只会被动进行事件调用且带有状态的容器，它在初始化时就是Pending状态，这时可以被取消，被设置结果和设置异常。而在被设定对应的操作后，Future会被转化到一个不可逆的对应状态，并通过loop.call_sonn来调用所有注册到本身上的回调函数，同时它带有__iter__和__await__方法使其可以被await和yield from调用。\nTask是Future的子类，除了继承了Future的所有方法，它还多了两个重要的方法__step和__wakeup，通过这两个方法赋予了Task调度能力，这是Coroutine和Future没有的。\n本次调试的问题在于：“为什么当下面的接受代码结束(break)后，发送代码仍然会陷入阻塞？又是为什么可以将他重新唤醒？”\n# socket_start.py import asyncio import websockets import json from loguru import logger async def sen_data(websocket, path): logger.error(\u0026#34;初始化完成\u0026#34;) while 1: data1 = {\u0026#34;value\u0026#34;:1} data1 = json.dumps(data1).encode(\u0026#39;utf-8\u0026#39;) try: await websocket.send(data1) except Exception: logger.debug(\u0026#34;重新启动\u0026#34;) break logger.debug(\u0026#34;结束了！\u0026#34;) start_serve1 = websockets.serve(sen_data, \u0026#34;127.0.0.1\u0026#34;, 1122, ping_interval=None) asyncio.get_event_loop().run_until_complete(start_serve1) asyncio.get_event_loop().run_forever() # socket_get.py import json import asyncio import websockets import time from loguru import logger async def hello(uri): async with websockets.connect(uri, ping_interval=None) as websocket: while True: recv_text = await websocket.recv() print(\u0026#34;\u0026gt; {}\u0026#34;.format(recv_text)) print(time.time()) time.sleep(1) asyncio.get_event_loop().run_until_complete( hello(\u0026#39;ws://127.0.0.1:1122\u0026#39;)) # 地址改为自己的地址 为了搞清楚，需要画一个时序状态机： 时序状态机绘制地址：\nhttps://tooltt.com/sequence/\n时序绘制代码：\nNote right of socket\\_start: -\u0026gt; 开始执行程序 Note right of socket\\_start: self.\\_run\\_once() Note right of socket\\_start: （base\\_events.py）self.\\_selector.select(timeout) Note right of socket\\_start: （[selectors.py](http://selectors.py \u0026#34;selectors.py\u0026#34;)）self.*selector.poll(timeout, max\\_ev) Note right of socket\\_start: 陷入阻塞 Note left of socket\\_get: 开始执行程序 \u0026lt;- Note left of socket\\_get: aenter Note left of socket\\_get: await Note left of socket\\_get: await\\_impl\\_timeout Note left of socket\\_get: await\\_impl Note left of socket\\_get: protocol handshake start Note left of socket\\_get: write\\_http\\_request Note left of socket\\_get: self.transport.write(request.encode()) socket\\_get-\u0026gt;socket\\_start: self.transport.write(request.encode()) socket\\_get-\u0026gt;socket\\_start: asyncio/selector\\_events.py socket\\_get-\u0026gt;socket\\_start: self.* sock.send(data) Note right of socket\\_start: 跳出阻塞 Note right of socket\\_start: （[selectors.py](http://selectors.py \u0026#34;selectors.py\u0026#34;)）for fd, event in fd\\_event\\_list: Note right of socket\\_start: 之后反复运行self.\\_ context.run(self.\\_callback, \\*self.\\_args) 另外的一些细节：\n启动sen_data函数相关的协程： （【socket_start文件】此时应当在asyncio.get_event_loop().run_forever()）\n【socket_start文件】接收到【socket_get文件的connect后执行如下片段】\nconnection_made await self.handshake start hand shake !!!!!! read_http_request process_request process_origin process_extensions process_subprotocol write_http_response handshake\n此时开始执行协程相关项\nreference Python的可等待对象在Asyncio的作用\nhttps://so1n.me/2022/04/11/python\u0026rsquo;s_waitable_objects_in_asyncio/index.html\nPython Asyncio调度原理（）\nhttps://juejin.cn/post/7108367062463938597\n如何给所有的async函数添加try/catch？（语法分析词法分析）\nhttps://juejin.cn/post/7155434131831128094\n事件循环和协程：从生成器到协程（手写简单的协程实现）\nhttps://zhuanlan.zhihu.com/p/31634491\nHTTP、TCP与UDP、Socket与Websocket之间的联系与区别\nhttps://segmentfault.com/a/1190000037620675\n","date":"2022-12-04T11:23:03+08:00","permalink":"https://sanbuphy.github.io/p/websocket%E4%B8%8E%E5%8D%8F%E7%A8%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%E5%88%9D%E6%AD%A5/","title":"websocket与协程的前世今生（初步）"},{"content":"reference：https://www.bilibili.com/video/BV1oR4y1X7xZ/\n要注意FLOPSs的区别 大S（floating-point operations per second） 小s算法复杂度是复数。\nFLOPs的单位B的意思大部分情况下都是GFLOPs\nNMS应该还是要算的，虽然会降低FPS，但不经过nms结果根本不能用。\n最终结论：(如果感兴趣可以去看下ShuffleNet V2的论文） 1. Parameters低约等于FLOPs低。（FLOPs和输入进来的图片大小有关，等同图片大小下一般可这么认为，因为FLOPs运算一般和卷积相关。）\n2.GFLOPs低 不等于Latency低（GFLOPs低不等于FPS高，有可能网络层多，网络设计不好 )\n3.Parameters低 不等于Latency低（ Parameters低 不等于FPS高)\n网络的运算速度（纯网络，不包含前处理后处理）和很多东西有关 1、显卡：大多数SOTA算法用的都是V100或者A100，\n2、网络结构：不是参数量越低速度越快，不是加两个深度可分离卷积，网络的速度就越快\n有一个MAC的概念（Memory Access Cost），在ShuffleNet V2的论文里提到了。深度可分离卷积便是一个高MAC，低参数量的操作。深度可分离卷积在CPU中表现更好。\n3、网络的并行度：lnception是一个不断增加网络宽度的模型，它使用不同卷积核大小的卷积进行特征提取。但它的工作速度不是特别快。分支分多次就要算多次\n4、网络的层数：额外的操作如Relu，ADD，都是没有参数量，但需要运算时间的操作。\n5、CUDA、cudnn、深度学习算法框架版本影响。1660Ti的机子上，YOLOX-S的FPS在torch1.7里为50多，torch1.2里面为20多。\nShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices reference: https://www.jianshu.com/p/a54cf8147cfc?utm_campaign=maleskine\u0026utm_content=note\u0026utm_medium=seo_notes\u0026utm_source=recommendation\n论文重点摘要\nModel Acceleration（模型加速） 这个方向旨在保留预先训练好的模型精确度的情况下加快速率。在之前训练好的模型中通过修剪网络连接以及减少通道冗余连接从而提升性能。在不改变参数的情况下，最优化卷积算法被应用在快速傅里叶变换以及减少实践生活中时间消耗的理论。提取大模型中的理论，有利于更加简单的训练小的模型。\n模型加速的方法有：（其实都是常识）\n1） 修剪网络，减少分支（pruningnetwork connections）。\n2） 对于一个训练好的网络（pre-trainedmodel），在性能不下降的情况下减少冗余的分支。\n3） 量化（quantization）和因式分解(factorization)加速。\n4） 在不改变参数的情况下，使用FFT算法对卷积进行加速。\n5） 提取网络的精华部分，减小网络模型。\n具体实现: ShuffleNetV2：轻量级CNN网络中的桂冠\n","date":"2022-11-25T15:07:48+08:00","permalink":"https://sanbuphy.github.io/p/%E5%A6%82%E4%BD%95%E8%A1%A1%E9%87%8F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9A%84%E8%AE%A1%E7%AE%97%E9%87%8F%E5%8F%8A%E7%BD%91%E7%BB%9C%E5%8A%A0%E9%80%9F%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"如何衡量深度学习算法的计算量及网络加速空间（学习笔记）"},{"content":"建议使用默认安装cuda（包括驱动）以及ffmpeg的默认安装地址以免出现各种奇怪问题。\ncmake .. -D CMAKE_BUILD_TYPE=RELEASE \\ -D CMAKE_INSTALL_PREFIX=/usr/local \\ -D ENABLE_PRECOMPILED_HEADERS=OFF \\ -D INSTALL_C_EXAMPLES=OFF \\ -D INSTALL_PYTHON_EXAMPLES=OFF \\ -D BUILD_opencv_python2=OFF \\ -D BUILD_opencv_python3=ON \\ -D PYTHON_DEFAULT_EXECUTABLE=$(python3 -c \u0026#34;import sys; print(sys.executable)\u0026#34;) \\ -D PYTHON3_EXECUTABLE=$(python3 -c \u0026#34;import sys; print(sys.executable)\u0026#34;) \\ -D PYTHON3_NUMPY_INCLUDE_DIRS=$(python3 -c \u0026#34;import numpy; print (numpy.get_include())\u0026#34;) \\ -D PYTHON3_PACKAGES_PATH=$(python3 -c \u0026#34;from distutils.sysconfig import get_python_lib; print(get_python_lib())\u0026#34;) \\ -D WITH_TBB=ON \\ -D BUILD_TBB=ON \\ -D ENABLE_FAST_MATH=1 \\ -D CUDA_FAST_MATH=1 \\ -D WITH_CUBLAS=1 \\ -D WITH_V4L=ON \\ -D WITH_LIBV4L=ON \\ -D WITH_CUDA=ON \\ -D WITH_CUDNN=ON \\ -D WITH_GTK_2_X=ON \\ -D WITH_NVCUVID=ON \\ -D WITH_FFMPEG=ON \\ -D CUDA_ARCH_BIN= 8.6 \\ #根据自己的显卡查找CUDA_ARCH_BIN表 -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib/modules . 点亮ffmpeg ffmepg有可能找不到，需要按照正规操作一遍ffmpeg。（记得whereis ffmpeg 删除相关内容）\n点亮nvcuvid相关（在cuda那一行） 在官网申请下载好了sdk后运行：\nsudo cp Interface/* /usr/include sudo cp Lib/linux/stubs/x86_64/* /usr/lib 删除build内内容重新cmake即可得到结果\n如果这么尝试后你还是不能找到，你需要把include和lib的地址换成cuda的，如/usr/local/cuda-11.5/lib64/ 以及 /usr/local/cuda-11.5/include 然后再依次cp，（我怀疑是因为cmake搜索路径和校验逻辑是直接利用cuda），这次你应该可以看见他了！\n注：如果你想要卸载opencv 在原来的build文件中使用 sudo make uninstall即可！\n值得注意的是，这样安装后装了一个python版本的tk2。0什么的（imshow报错的要求）后无法再次createReader。。。也许不能直接把sdk的拿过去?我们可以看看驱动安装的so然后拿到对应cuda的区域或者干脆重装一次驱动。。。。也许这是更好的方法。\n跑samples测试 对于cpp的测试，参考下文\nhttps://zhuanlan.zhihu.com/p/357290528\n对于gpu里面的测试，你需要新建一个build，然后拖进你想要编译的文件，使用\ncmake_minimum_required(VERSION 3.0.2) SET(CMAKE_BUILD_TYPE \u0026#34;Debug\u0026#34;) include_directories(include) find_package( OpenCV REQUIRED ) include_directories( ${OpenCV_INCLUDE_DIRS} ) add_executable( test opencv_test.cpp ) target_link_libraries( test ${OpenCV_LIBS} ) 其中注意add_executable( test opencv_test.cpp )需要修改为拖进来的文件。直接cmake . 即可得到结果。\nReference 推荐阅读教程：\nhttps://blog.csdn.net/jiexijihe945/article/details/125084488\n英文教程（内部有CUDA_ARCH_BIN表）\nhttps://www.nanguoyu.com/opencv4-5-1-gpu\n编译选项中ffmpeg路径修改\nhttps://blog.csdn.net/woainannanta/article/details/78260419\nopencv读取rtsp网络流问题与优化方案\nhttps://blog.csdn.net/submarineas/article/details/110083906\nVPF：Python中的硬件加速视频处理框架\nhttps://blog.csdn.net/submarineas/article/details/111877262\nVPF使用范例\nhttps://blog.csdn.net/kkae8643150/article/details/123307662\n超级大全 实现基于Opencv的GPU视频编解码\nhttps://note.youdao.com/ynoteshare/index.html?id=700052b0a49301059a34f20a00a830ca\u0026amp;type=note\u0026amp;_time=1638503513531\n","date":"2022-11-13T17:45:11+08:00","permalink":"https://sanbuphy.github.io/p/opencv%E6%8B%93%E5%B1%95%E5%8C%85%E7%BC%96%E8%AF%91/","title":"opencv拓展包编译"},{"content":"拉流推流基础知识 直播-拉流和推流概述\nhttps://www.jianshu.com/p/b520c2a9b795\n常见问题 error while decoding MB 0 14, bytestream 104435 相关问题原因\nhttps://blog.csdn.net/puffdoudou/article/details/109779624\nopencv读取网络摄像头的rtsp流时发生断流现象\nhttps://blog.csdn.net/qq_33764934/article/details/103482121\n使用ffmpegGPU相关拓展加速编码解码 一些依赖可选择安装：（最好用系统默认镜像源，否则容易被嵌套依赖问题电脑GG）\nsudo apt-get install autoconf automake build-essential libass-dev libfreetype6-dev libtheora-dev libtool libvorbis-dev pkg-config texinfo zlib1g-dev unzip cmake yasm libx264-dev libmp3lame-dev libopus-dev libsdl1.2-dev libva-dev libvdpau-dev libxcb1-dev libxcb-shm0-dev libxcb-xfixes0-dev libfaac* libopenjpeg * libv4l-dev libvpx-dev libssl-dev\n参考用官方手册：\nUsing_FFmpeg_with_NVIDIA_GPU_Hardware_Acceleration.pdf\nhttps://docs.nvidia.com/video-technologies/video-codec-sdk/pdf/Using_FFmpeg_with_NVIDIA_GPU_Hardware_Acceleration.pdf\n按照分支选择对应版本的nv-codec-headers进行编译安装\nhttps://github.com/FFmpeg/nv-codec-headers\n你可以直接下载别人的docker：\nhttps://yinguobing.com/docker-image-for-nvidia-gpu-accelerated-ffmpeg-opencv/\n下载：\nhttps://ffmpeg.org/download.html\n首先你需要编译H264库 （1）下载X264 : git clone [http://git.videolan.org/git/x264.git](http://git.videolan.org/git/x264.git) （2）安装X264： sudo ./configure –enable-shared –disable-asm sudo make sudo make install 接着重新编译ffmpeg：\n./configure --enable-shared --enable-cuda --enable-cuvid --enable-nvenc --enable-libnpp \\ --enable-nonfree\\ #可选--enable-gpl --enable-libx264 --enable-libx265 --extra-cflags=-I/usr/local/cuda/include --extra-ldflags=-L/usr/local/cuda/lib64 \\ --prefix=/usr/ 注意，这里prefix之所以要指定为/usr/是为了让opencv能找到ffmpeg 如果还是找不到，你可以用cmake-gui 然后打开grouped advanced找到pkgcfg，按照这样类似的命名规则，再找到你现在拥有的相应的so在右上角增加入口添加进去即可。\n你也可以参考：https://www.jianshu.com/p/59da3d350488\n到这里基本上就结束了，为了让命令行可以使用记得在~/.bashrc中添加如下命令： export PATH=/usr/local/ffmpeg/bin/:$PATH 保存后执行 source ~/.bashrc\nReference 利用ffmpeg转接摄像头RTSP流硬解码\nhttps://www.pianshen.com/article/31441500162/\nffmpeg使用硬件加速hwaccel、cuvid、h264_cuvid、h264_nvenc https://blog.csdn.net/zengraoli/article/details/119789655\nNVIDIA FFmpeg 转码指南【非常推荐，英伟达官方良心之作，适合写个笔记】 https://developer.nvidia.com/zh-cn/blog/nvidia-ffmpeg-transcoding-guide/\nffmpeg命令行使用nvidia CUDA scaling高速转分辨率转码(libnpp) https://blog.csdn.net/n66040927/article/details/84525611\nVideo Encoding Sessions并发数目限制(OpenEncodeSessionEx failed: out of memory) https://github.com/keylase/nvidia-patch\nhttps://blog.csdn.net/TracelessLe/article/details/113755792\nhttps://blog.csdn.net/charleslei/article/details/105761627\nhttps://www.cnblogs.com/geoffreyone/p/14715487.html\n","date":"2022-11-13T15:48:48+08:00","permalink":"https://sanbuphy.github.io/p/ffmpeg%E8%A7%86%E9%A2%91%E6%B5%81%E7%A1%AC%E8%A7%A3%E7%A0%81%E5%8A%A0%E9%80%9F/","title":"ffmpeg视频流硬解码加速"},{"content":"简单操作 本文搬运自评论区（但是够用了）\n具体请看视频https://www.bilibili.com/video/BV19e4y1q7JJ/\nhttps://www.bilibili.com/video/BV1ne4y1S7S9/\n1.git clone // 到本地 2.git checkout -b xxx 切换至新分支xxx （相当于复制了remote的仓库到本地的xxx分支上 3.修改或者添加本地代码（部署在硬盘的源文件上） 4.git diff 查看自己对代码做出的改变 5.git add 上传更新后的代码至暂存区 6.git commit 可以将暂存区里更新后的代码更新到本地git 7.git push origin xxx 将本地的xxxgit分支上传至github上的git\n（如果在写自己的代码过程中发现远端GitHub上代码出现改变） 1.git checkout main 切换回main分支 2.git pull origin master(main) 将远端修改过的代码再更新到本地 3.git checkout xxx 回到xxx分支 4.git rebase main 我在xxx分支上，先把main移过来，然后根据我的commit来修改成新的内容 （中途可能会出现，rebase conflict \u0026mdash;\u0026ndash;》手动选择保留哪段代码） 5.git push -f origin xxx 把rebase后并且更新过的代码再push到远端github上 （-f \u0026mdash;》强行）【一定要记得先更新最新的代码分支】 6.原项目主人采用pull request 中的 squash and merge 合并所有不同的commit\n远端完成更新后\n1.git branch -d xxx 删除本地的git分支\n2.git pull origin master 再把远端的最新代码拉至本地\n评论区：说的很好，刚入大厂的我表示就是用的这套流程，刚进来就犯了一次错误，自己的分支上面很多commit然后中间merge了一遍master的代码之后又commit了，结果导致最后PR的时候rebase非常困难，太多冲突了，commit数量太多被diss了。最后还是删除了分支，重新建立一个分支，把所有的改变重新再一个commit上面实现了一遍。后来知道了，千万不要在自己分支没有pr前merge，可以rebase。。。而且每次pr之前我们都要求用rebase -i命令在本地压缩commit到一个，然后再去PR。\ngit checkout -b xxx：git checkout xxx是指切换到xxx（用local区的xxx替换disk区文件），-b意味着branch，即创建新分支，这条指令合起来意思是创建并切换到xxx。 git diff：查看暂存区与disk区文件的差异。 git add xxx：将xxx文件添加到暂存区。 git commit：将暂存区内容添加到local区的当前分支中。 git push ：将local区的LocalBranchName分支推送到RemoteHostName主机的同名分支。（若加-f表示无视本地与远程分支的差异强行push） git pull ：同上，不过改成从远程主机下载远程分支并与本地同名分支合并。 git rebase xxx：假设当前分支与xxx分支存在共同部分common，该指令用xxx分支包括common在内的整体替换当前分支的common部分（原先xxx分支内容为common-\u0026gt;diversityA，当前分支内容为common-\u0026gt;diversityB，执行完该指令后当前分支内容为common-\u0026gt;diversityA-\u0026gt;diversityB）。 git branch -D xxx：不加-D表示创建新local分支xxx，加-D表示强制删除local分支xxx。\n优雅的提交pr到开原仓库 openmmlab的官方pr教程\nhttps://mmcv.readthedocs.io/zh_CN/latest/community/contributing.html\n记得建立新分支，然后push origin 你的新分支从而push代码到你自己的仓库，随后在github上选择对应分支pr，这样不会影响到你fork仓库与上游库的同步状态。（fork后也可以人工选择sysn同步）如果想要新做一个修改就新开一个分支做pr commit，被合并或者取消后就可以删除这个分支，然后记得每次新建分支前要先从上游库拉取更新。\n其他参考：优雅地修改他人贡献的 Pull Request（写的非常好！）\nhttps://liuyib.github.io/2020/09/19/add-commits-to-others-pr/#命令行方式\n","date":"2022-10-30T15:00:59+08:00","permalink":"https://sanbuphy.github.io/p/git%E5%AE%8C%E6%95%B4%E5%B7%A5%E5%85%B7%E6%B5%81%E6%95%99%E7%A8%8B/","title":"Git完整工具流教程"},{"content":"作为一个很多奇怪问题\u0026amp;bug体质的人，此处用于记录平时的奇思妙想。\nhttps://zhuanlan.zhihu.com/p/83454344\n编译与链接相关 windows动态连接库dll居然是用lib导入符号信息（windows专门的编译器）（此时的lib不表示静态连接库），还是linux香啊。。\n【手把手教你编写 年轻人的第一个动态链接库-哔哩哔哩】 https://b23.tv/6pddFSv\nQ：编译器前后端之区别是不是只在中间代码翻译的职责部分？\n比如clang负责转换成机器无关的中间代码。然后llvm后端把它可以转换成机器相关汇编代码\nA：\n操作系统相关 https://yajin.org/os2018fall/\nhttps://yajin.org/os2018fall/02_os_structures.pdf\nQ：用户线程为什么不能独立于内核线程存在？至少要有一个内核线程“与他关联”？\nA：\n群友的看法：\n我的理解是,如果在微内核, 比如fs模块在user层, 用户程序只需要调用fs模块, 那用户程序逻辑上是没有调用内核task, 但是物理上微内核fs模块肯定会调用微内核内核层的vm的task的, 所以用户线程不能独立存在。如果用户程序和操作系统在一个物理机中, 如果用户程序和操作系统要独立, 首先资源要独立, 内存可以协商独立, 比如0x00000a-0x0000fff是操作系统的, 然后0x0001ffff0-0xffffffff是用户程序的. cpu0是给操作系统的, cpu1是给用户程序的. 然后通信用网络, eth0是操作系统的, eth1是用户程序的. 这样的话应该能设计出用户线程是独立的。\n我的看法：\n（不同操作系统实现不同，这里只针对比较现代的linux。)\n首先要注意这东西由于不同操作系统和不同年代的教材众说纷纭，很容易出现概念混淆和理解错误，这里我们以最新的linux手册为准。\n在讨论这个问题之前首先要明确几个概念（什么是线程、什么是用户线程。），我们看到有很多地方说到多对一模型，其实这里的用户线程更应该叫协程（你看到很多地方会说这东西不需要syscall就可以创建，process内负责执行流切换无需os）。而我们常说的用户态创建的线程就是一对一模型（pthreads手册中明确提到Both of these are so-called 1:1 implementations, meaning that each thread maps to a kernel scheduling entity），本身需要和内核线程挂钩（创建过程需要syscall和内核线程绑定），而进程本身的主线程必定是和内核线程挂钩；另外在linux中我们用task去称呼会更加合适，linux系统层面没必要分进程线程只需要task就好。只有在我们执行的程序里有需求开pthread 这里才要强调，它会将对应的函数入口给内核线程以便切换。\n需要注意的是，在xv6，内核初始化完了切换init后就进入了用户态，此后fork、exec的都是子task，但是需要调度流切换得需要和cpu联系，这就需要内核task才能够运作。（其实这里的子task本身就是可以被调度到的，因为就是PCB）\n回答这个问题的关键是理解所谓的线程是怎么拿到cpu资源的，拿到资源意味着被调度器调度。（为什么不讨论进程？因为实际上进程只是一些共享内存的task，而且在linux中PCB就是task_struct）。首先之所以是线程而不是函数是因为他能作为调度单元（可以被调度器切换上下文），在任务调度器（比如pa中的schedule）的眼里，只有task才是调度单元，即处理器上运行的每个任务都是调度器给分配的执行流，只要成为执行流就能够独立上处理器运行了，而内核task可以被内核直接调度，他可以直接做到操作页表，维护cache, 读写系统寄存器等操作。如果用户task（比如协程）不需要内核线程管理，容易出现一些意外现象（虽然还是可以让系统发指令杀死）。这里概念最坑的就是可能混淆协程和在用户态用pthread api 创建的线程以及LWP轻量化进程，实际上前者可以通过是否syscall是否需要和内核互动来区分；而LWP轻量化进程在linux中有时是内核线程的另一种称呼。\n为什么说linux中用户态可以/需要绑定一个内核线程？具体看syscall，我们创建线程的过程会调用clone然后和一个内核线程“绑定”（大概是把上下文存储到内核线程task块中这样可以被os看到和调度。）用户task实际上用的是内核task的pcb块，需要一些高级权限的时候就保存上下文内陷然后在内核中处理即可。\n如果想要最单纯的用户线程也有执行的权限，关键是你能够怎么切换他的执行流，此时应该只有协程能满足这个需求了，否则要提权的话就是内核线程了，因为能被内核直接schedule。所以严格来说独立的用户线程是不存在的，就算是协程也需要进程调度，而进程的cpu资源源于对应内核task的被调度。\n（有趣的是，linux2.6才完全支持了我们现在意义上的用户态线程，linux2.6是2003年的内核版本，由此可见计算机确实是一门很新的学科:) ）\nreference：\n浙大课件Light-Weight Processes: Dissecting Linux Threads：https://yajin.org/os2018fall/04_thread_b.pdf\n深入理解Linux内核之内核线程（上）：https://zhuanlan.zhihu.com/p/364898425\n关于“内核线程”、“用户线程”概念的理解：https://blog.csdn.net/u012927281/article/details/51602898\n图解进程、线程：https://blog.csdn.net/fuzhongmin05/article/details/119448800\nLight-Weight Processes: Dissecting Linux Threads：https://www.opensourceforu.com/2011/08/light-weight-processes-dissecting-linux-threads/\nWhat are Linux Processes, Threads, Light Weight Processes, and Process State:https://www.thegeekstuff.com/2013/11/linux-process-and-threads/\nman pthreads:https://man7.org/linux/man-pages/man7/pthreads.7.html\nQ：linux线程的生命周期是怎么样的？怎么被创建和销毁？内核task能不能被复用？\nA: 这个说的比较清楚：https://xieyu.github.io/blog/pthread/glibc-pthread-implement-thread-life-cycle.html\n如果 pthread_join 发生在结束后不久，资源还未被回收，函数会立即返回。\n如果 pthread_join 发生在结束以后一段时间，可能会得到 ESRCH (no such thread) 错误。\n如果 pthread_join 发生在之后很久很久很久很久，资源被释放又被再次复用 (pthread_t 是一个的确可能被复用的整数)，我不就 join 了另一个线程了吗？这恐怕要出大问题。\n特别的：（其他情况exit后都会被资源回收）\n没有task复用的说法。\nreference:\njyy:http://jyywiki.cn/OS/2022/labs/M2\n网络相关 python相关 Q:为什么开了multiprocessing的pool再开process就不会出现信息？\nA：不知道，但你记住要多次fork只能一直process就对了。\n","date":"2022-10-14T19:48:48+08:00","permalink":"https://sanbuphy.github.io/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%90%84%E7%B1%BB%E7%A5%9E%E5%A5%87%E7%9A%84%E5%B0%8F%E9%97%AE%E9%A2%98%E5%A4%A7%E5%85%A8/","title":"计算机各类神奇的小问题大全"},{"content":"最近在使用python调用pybind11生成的so发现了一个问题，对于一个python环境下生成的so，另一个环境用不了。（刚开始也还没发现是环境的问题）\n一开始发现的现象是能用vscode生成能使用，但在pycharm下使用不能；一开始怀疑的是pycharm配置问题导致库不能被import（import了会提示找不到这个库）。\n后面发现换到某指定环境下就可以成功运行（和python版本有关），再之后发现只有特定python版本用python setup.py build 后产生的so能用特定python进行调用。\n为什么呢？我们仔细观察后发现不同so涉及到python版本的前缀是不一样的（比如3.7生成就是37），在编译过程中我们也能看到setup的编译选项中涉及到了指定的python版本信息；所以我们确定了他就是解释器版本相关的，那为什么版本不同的so不可以被python读取呢？\n在import一个so库里的类或函数时，有时发现so文件分明就在那路径下，可是总是报错ModuleNotFoundError: No module named，这种错误的可能原因有:\n1.首先要确保so所在的路径已经包含在sys.path里了，如果so所在目录已经是在python默认的系统路径里，例如/usr/lib/python3.6/dist-packages/或者/usr/local/lib/python3.6/dist-packages/之下的任何层级的目录，不用做任何设置，如果是其他路径，可以通过设置PYTHONPATH或者程序里使用sys.path.insert()或sys.path.append()把路径添加到sys.path里来。\n2.路径包含正确了，检查so库的命名的前缀和import是否不一致，这种so库的命名是有一定规则的，例如，Linux上一般是\u0026lt;so_name\u0026gt;.cpython---linux-gnu.so，在import时指定的名字需要和\u0026lt;so_name\u0026gt;保持一致。\n3.命名正确了，检查后面的后缀cpython---linux-gnu.so是否在你当前使用的python版本的支持范围内，例如，你的so库是python3的，可你在误操作下在使用python2运行程序，或者你的so库是针对python3.5的(so后缀里的python-version=35m)，但你当前使用的是python3.6，也不行，所以如果不是在只安装了一种版本的python的环境里，运行python程序前，最好检查一下python版本是否是你所希望的，这个是在安装了多个版本的python的环境下或者升级了python版本后经常不经意下易犯的错误，有时还被坑浪费很多时间查找原因，除了so库分明在那里却总是报ModuleNotFoundError，还有其他七七八八奇怪的错误，查找原因最后发现是python版本用错了，气得血冲脑门。\n4.路径存在冲突，so分明在某个已包含的目录下存在，没有其他的错误，可还总是报错ModuleNotFoundError，这种情况也是很坑人的，花费了很久时间想不出原因来，就是没想到可能路径上存在重名的冲突，例如，我第一次使用python代码调用mediapipe时出现报错ModuleNotFoundError: No module named \u0026lsquo;mediapipe.python._framework_bindings\u0026rsquo;，其他什么错误原因都没发现，郁闷地熬夜，最后发现虽然/usr/local/lib/python3.6/site-packages/mediapipe/python/_framework_bindings.cpython-36m-x86_64-linux-gnu.so是存在的，但是在运行程序的工作目录下也有个使用过用来build出meaidpipe的wheel包的源码目录，由于当前工作目录加入了sys.path里最前面，于是python搜索路径时自然是优先找的/workspace/mediapipe/python/\u0026hellip;，这个下面确实是没有那个so文件，于是把这里的mediapipe目录改名或者移走，问题就消失了。\n5.最后，如果是自己实现的so库，要想能被python import，so库的内部实现按规范来。\n怎么确认你当前使用的python版本支持哪些后缀的库能被import呢，很简单，执行下面的代码:\nimport importlib.machinery print(importlib.machinery.all_suffixes()) 此时你就能看到上述so熟悉的身影，这就是为什么有些so能够被import的底层原因。\rReference\nhttps://blog.csdn.net/XCCCCZ/article/details/111089151\n","date":"2022-10-14T19:08:27+08:00","permalink":"https://sanbuphy.github.io/p/pybind11%E7%94%9F%E6%88%90%E7%9A%84so%E6%97%A0%E6%B3%95%E8%A2%ABimport%E9%97%AE%E9%A2%98/","title":"pybind11生成的so无法被import问题"},{"content":"最近遇到要让rtmp在前端展示的问题，我们知道flash已经不再被支持了，现在支持的是http传输协议。\n如果要浏览器前端展示除了异步直接展示的方法就是用http-flv。\n一、安装http-flv版的nginx 参考我之前的文章https://sanbuphy.github.io/p/opencv读取视频图像处理后推流rtmp/\n可以进行基础的配置，唯一的差别就是安装的时候选取的包为：\ngit clone https://github.com/winshining/nginx-http-flv-module.git\n也和我们之前的rtmp包一样放在同级目录，然后进入nginx：\n（注意，不需要带上rtmp的附加模块，因为httpflv模块包含了rtmp包的基础功能）\n./configure --add-module=../nginx-http-flv-module make -j8 sudo make install 安装结束后用同样的方法点亮nginx的初始化\n如果你已经安装了nginx，你只需要whereis nginx，然后rm -rf对应的文件夹即可。\n二、修改nginx配置 按之前文章同样的方法用code或者其他方式进入 /usr/local/nginx/conf/nginx.conf ，按照如下规则修改：\n# 在server内的location /stat.xsl之下加入如下字样，同时别忘了把stat.xsl的root地址改成http-flv的 location /live{ flv_live on; #打开 HTTP 播放 FLV 直播流功能 chunked_transfer_encoding on; #支持 \u0026#39;Transfer-Encoding: chunked\u0026#39; 方式回复 add_header \u0026#39;Access-Control-Allow-Origin\u0026#39; \u0026#39;*\u0026#39;; #添加额外的 HTTP 头 add_header \u0026#39;Access-Control-Allow-Credentials\u0026#39; \u0026#39;true\u0026#39;; #添加额外的 HTTP 头 } # 在原来rtmp配置的地方加入如下字样 application http_flv{ live on; } 特别注意的是，每次修改完配置一定要记得sudo /usr/local/nginx/sbin/nginx -s reload\nps:这里有个坑就是我改了worker_processes后就不能运行了。。这个具体细节可以搜索，实际上比较复杂。\n三、开始推流 按照前文同样的方式你可以直接推送成rtmp流，如果你想要推送成http-flv支持的格式则修改：\nrtmp = \u0026#39;rtmp://localhost:1935/mylive/test\u0026#39; #把原来的rtmp推送地址修改为如下: rtmp = \u0026#39;rtmp://localhost:1935/http_flv/test\u0026#39; 然后再使用html模板进行直接查看（flv.js）\n【此处需要修改url: 'http://你的ip/live?port=1935\u0026amp;app=http_flv\u0026amp;stream=test',为你的ip】（这个是给前端拉流的地址）\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta content=\u0026#34;text/html; charset=utf-8\u0026#34; http-equiv=\u0026#34;Content-Type\u0026#34;\u0026gt; \u0026lt;title\u0026gt;flv.js demo\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; .mainContainer { display: block; width: 640px; } .urlInput { display: block; width: 100%; margin-top: 8px; margin-bottom: 8px; } .centeredVideo { display: block; width: 100%; height: 320px; } .controls { display: block; width: 100%; text-align: left; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;mainContainer\u0026#34;\u0026gt; \u0026lt;video id=\u0026#34;videoElement\u0026#34; class=\u0026#34;centeredVideo\u0026#34; controls autoplay width=\u0026#34;640\u0026#34; height=\u0026#34;320\u0026#34;\u0026gt;Your browser is too old which doesn\u0026#39;t support HTML5 video.\u0026lt;/video\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;br\u0026gt; \u0026lt;div class=\u0026#34;controls\u0026#34;\u0026gt; \u0026lt;button onclick=\u0026#34;flv_start()\u0026#34;\u0026gt;开始\u0026lt;/button\u0026gt; \u0026lt;button onclick=\u0026#34;flv_pause()\u0026#34;\u0026gt;暂停\u0026lt;/button\u0026gt; \u0026lt;button onclick=\u0026#34;flv_destroy()\u0026#34;\u0026gt;停止\u0026lt;/button\u0026gt; \u0026lt;input style=\u0026#34;width:100px\u0026#34; type=\u0026#34;text\u0026#34; name=\u0026#34;seekpoint\u0026#34; /\u0026gt; \u0026lt;button onclick=\u0026#34;flv_seekto()\u0026#34;\u0026gt;跳转\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;https://cdn.bootcdn.net/ajax/libs/flv.js/1.5.0/flv.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; var player = document.getElementById(\u0026#39;videoElement\u0026#39;); if (flvjs.isSupported()) { var flvPlayer = flvjs.createPlayer({ type: \u0026#39;flv\u0026#39;, isLive: true, enableWorker:true, enableStashBuffer:false, stashInitialSize:128, url: \u0026#39;http://你的ip/live?port=1935\u0026amp;app=http_flv\u0026amp;stream=test\u0026#39;, }); flvPlayer.attachMediaElement(videoElement); flvPlayer.load(); flv_start(); } function flv_start() { player.play(); } function flv_pause() { player.pause(); } function flv_destroy() { player.pause(); player.unload(); player.detachMediaElement(); player.destroy(); player = null; } function flv_seekto() { player.currentTime = parseFloat(document.getElementsByName(\u0026#39;seekpoint\u0026#39;)[0].value); } \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 点击开始播放，此时你已经可以看到页面上呈现了！\n这里还要注意一点，如果你修改了主服务的监听端口（比如80到8080），\n你需要修改 'http://你的ip/live?port=1935\u0026amp;app=http_flv\u0026amp;stream=test'\n为 'http://你的ip:新端口/live?port=1935\u0026amp;app=http_flv\u0026amp;stream=test'\n切记切记\nReference rtmp、http-flv视频直播以及配合视频处理算法的实现\nhttps://zhuanlan.zhihu.com/p/375548523\nFFmpeg + nginx-http-flv-module + flv.js 实现视频流播放\nhttps://hasaik.com/posts/358f95d9.html\n不依赖flashrtsp流通过ffmpeg+nginx-http-flv转成rtmp以及http-flv流并通过flv.js在页面播放(附带所用的工具下载)\nhttps://www.361shipin.com/blog/1542511538894536704\n","date":"2022-10-14T17:56:50+08:00","permalink":"https://sanbuphy.github.io/p/%E5%88%A9%E7%94%A8nginx%E7%9A%84%E8%BD%AC%E6%8E%A8%E6%B5%81http-flv/","title":"利用Nginx的转推流http-flv"},{"content":"前言： 整个探索过程源于两句话：\n1、计算机世界没有魔法，机器永远是对的，让自己舒服才会有动力（比如调试）——jyy\n2、从今天开始, 不要偷懒了；RTFM + STFW ——yzh\nstackoverflow真心救大命- -\n你可以选择使用ubuntu20.04系统环境，最好使用ubuntu22.04（这个可以省去第四步），而且在20上不能显示csr寄存器，22上可以完美观察mepc等等。\n经过我的充分测试（包括测试了云服务器），最好的体验是22.04版本的ubuntu（wsl和虚拟机都可以）。\n如果你想用ubuntu20完成也可以，只要在想要看csr相关寄存器的时候关闭xml（第四步提到的target xml）就可以用gdb命令打印出相关csr或设置监视点（监视点后面加上,x可以变成十六进制如$mepc,x）。如果开启xml只能看到基础的32个寄存器，并且不能用监视点和打印出csr寄存器的相关内容，但这也足够陪伴你一段时间了。\n“Get out of your comfort zone.” 不要惧怕调试任何一部分 一定要相信是可以优雅地做到的 一、准备工作 💡为了能有一个流畅愉快的旅途，你应该拥有并安装以下依赖程序: 1、https://pdos.csail.mit.edu/6.828/2021/tools.html\n接下来我们可能会反复使用“根目录”，他的意思是直接在xv6-labs-2021文件夹下进行操作。\n💡注意：如果你想要用vscode远程调试服务器上的xv6，可以参考这个链接的教程\nhttp://hitsz-cslab.gitee.io/os-labs/remote_env_gdb/\n二、第一次运行 💡 1、你需要根据lab0：https://pdos.csail.mit.edu/6.828/2022/labs/util.html 成功在命令行运行qemu 2、根据在根目录下创建.vscode文件夹，并创建如下内容的两个文件：launch.json、tasks.json 3、修改.gdbinit.tmpl-riscv文件内容 4、用虔诚的心态按下键盘上的F5\n//launch.json { \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;debug xv6\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;cppdbg\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;program\u0026#34;: \u0026#34;${workspaceFolder}/kernel/kernel\u0026#34;, \u0026#34;args\u0026#34;: [], \u0026#34;stopAtEntry\u0026#34;: true, \u0026#34;cwd\u0026#34;: \u0026#34;${workspaceFolder}\u0026#34;, \u0026#34;miDebuggerServerAddress\u0026#34;: \u0026#34;127.0.0.1:26000\u0026#34;, //这里实际上可以用各种能调试的gdb，如果找不到你可以使用which gdb-multiarch //但要注意的是，为了能在ubuntu20.04调出寄存器，强烈建议使用riscv64的gdb \u0026#34;miDebuggerPath\u0026#34;: \u0026#34;/usr/bin/gdb-multiarch\u0026#34;, \u0026#34;environment\u0026#34;: [], \u0026#34;externalConsole\u0026#34;: false, \u0026#34;MIMode\u0026#34;: \u0026#34;gdb\u0026#34;, \u0026#34;preLaunchTask\u0026#34;: \u0026#34;xv6build\u0026#34;, \u0026#34;setupCommands\u0026#34;: [ { \u0026#34;description\u0026#34;: \u0026#34;pretty printing\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;-enable-pretty-printing\u0026#34;, \u0026#34;ignoreFailures\u0026#34;: true, }, ], //用于gdb调试的工具，可以发现gdb出错的原因 // \u0026#34;logging\u0026#34;: { // \u0026#34;engineLogging\u0026#34;: true, // \u0026#34;programOutput\u0026#34;: true, // } } ] } // tasks.json { \u0026#34;version\u0026#34;: \u0026#34;2.0.0\u0026#34;, \u0026#34;tasks\u0026#34;: [ { \u0026#34;label\u0026#34;: \u0026#34;xv6build\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;isBackground\u0026#34;: true, \u0026#34;command\u0026#34;: \u0026#34;make qemu-gdb\u0026#34;, \u0026#34;problemMatcher\u0026#34;: [ { \u0026#34;pattern\u0026#34;: [ { \u0026#34;regexp\u0026#34;: \u0026#34;.\u0026#34;, \u0026#34;file\u0026#34;: 1, \u0026#34;location\u0026#34;: 2, \u0026#34;message\u0026#34;: 3 } ], \u0026#34;background\u0026#34;: { \u0026#34;beginsPattern\u0026#34;: \u0026#34;.*Now run \u0026#39;gdb\u0026#39; in another window.\u0026#34;, // 要对应编译成功后,一句echo的内容. 此处对应 Makefile Line:170 \u0026#34;endsPattern\u0026#34;: \u0026#34;.\u0026#34; } } ] } ] } 都创建后我们发现直接F5会报错，原因是.gdbinit中的target remote问题，为了解决我们直接修改.gdbinit.tmpl-riscv文件内容（从makefile中我们能够知道是他创造了.gdbinit）\n然后make clean再次f5后即可发现他安静的停在了main！\n三、运行用户程序 💡 按照以下步骤即可得到结果，或者参考jyy的方法：https://jyywiki.cn/OS/2022/slides/18.slides#/2/2\n在参考“MIT 6.S081 xv6调试不完全指北”后成功找到了最简单的方法，当我们直接f5点亮后，先不要做任何操作，我们以ls程序为例，首先进入ls.c的main处打下断点（一定要在main有）\n此时的断点是没有生效的，我们在左下角的断点也可以看到他是灰色的：\n接下来我们在调试控制台输入-exec file ./user/_ls （他的相对地址），此时我们发现他读取到了符号表信息：\n让我们按下“播放”让程序跑到输入处，然后在终端输入ls并回车，你会发现他已经停在了用户程序中，也可以进入汇编文件：\n此时已经可以愉快的调试用户程序了~你可以参考reference1中的不完全指北，用vscode尝试调试第一个用户程序。\n如果你发现这ls停止还没有成功，请按照类似的步骤先停在init，再尝试停在ls（具体什么是init请RTSC）\n四、恢复寄存器显示 通常来说，当我们打开了vscode，左边都应该显示出寄存器信息：\n但如果我们在ubuntu20.04中打开调试后，会惊奇的发现，完全没有显示！\nvscode没有寄存器，这完全不能忍！心态一开始就有点小崩了，不过别着急，让我们先打开位于launch的gdb日志看看发生了什么：\n日志告诉我们有个叫做ustatus的寄存器无法显示，应该是gdb不支持（然而我们也确实只见过mstatus\u0026hellip;）那么关键的问题就是我们该如何解决这个register问题。\n（我还尝试修改了各种makefile等等。。。但并未奏效，实际上和问题无关故不再重复说明）\n4.1有关gdb版本的坑问题（并非解决方法） 经过一顿搜索，我发现有人也遇到了类似的E14错误问题，他说要更新gdb，但我们仔细一想，在ubuntu20版本下的软件源只有9版本的gdb，哪来的12？（22上完美运行的gdb版本是12）\n而且我们可以通过-exec show version发现此时运行的gdb确实是9版本，我们也有理由相信这确实是gdb的问题。\n提前卸载了gdb及其gdb-multiarch并一顿操作猛如虎找到了gdb的源码：\nhttps://www.sourceware.org/gdb/\n随便找了个教程编译后看了一下gdb -v以及gdb-multiarch -v都没有安装。。心态又不好了\n好那咱们换个方法编译一下，一顿操作猛如虎找到了riscv64-unknown-elf-gdb：\nhttp://rcore-os.cn/rCore-Tutorial-deploy/docs/pre-lab/gdb.html\n一顿操作编译后（记得修改launch）还是不行\u0026hellip;..开始怀疑人生了，老板你这rv是不是假的啊？\n突然想到ustatus好像确实没有在rv出现过，那看来不能错怪他，也许是qemu之类的配置问题。\n此时我再次按照这个帖子提到的问题进行编译make CXXFLAGS=\u0026quot;-static-libstdc++\u0026quot;：（其实后面发现不需要静态编译也是可以的）\nhttps://stackoverflow.com/questions/32773255/how-to-update-gdb-to-most-current-stable-version\n此时可以发现gdb版本成功显示为gdb 12但是仍然没有gdb-multiarch，也无法直接吧这个版本的gdb加入到launch供vscode使用。于是我们需要再换一个缝合怪的gdb（我后面发现gdb其实可以包含各种架构也可以切换）\n此时我打算将gdb更新到与22同步的版本，我们发现Ubuntu22版本中的gdb打印版本是不会出现—target=riscv之类字样的，只有gnu-linux。所以我再一次尝试编译完整的gdb，加上了--enable-targets=all，此时我们可以直接更换launch的gdb为gdb了（之前只能gdb-multiarch或者riscv64，现在的gdb是融合了各种框架的超级缝合怪），进去后再次观察寄存器\u0026hellip;\u0026hellip;..还是一片空白\n又开始怀疑人生了，说好的gdb版本呢？痛定思痛后直接放弃了这个问题解决路线，让我们回到最开始的地方——到底那个奇怪的问题是怎么出现的？\n4.2直接解决问题 💡太长不看版： 1、F5运行情况下在调试控制台中输入-exec maintenance print xml-tdesc ，完整复制输出的内容后存放在根目录下的myxml.xml文件夹下（名字也可以看你喜欢修改）\n2、保存文件并结束调试，在根目录下运行make clean 3、修改launch.json为：\n{ \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;debug xv6\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;cppdbg\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;program\u0026#34;: \u0026#34;${workspaceFolder}/kernel/kernel\u0026#34;, \u0026#34;args\u0026#34;: [], \u0026#34;stopAtEntry\u0026#34;: true, \u0026#34;cwd\u0026#34;: \u0026#34;${workspaceFolder}\u0026#34;, \u0026#34;miDebuggerServerAddress\u0026#34;: \u0026#34;127.0.0.1:26000\u0026#34;, //看你喜欢可以修改成什么能用的gdb，为了防止奇怪现象我选择了rv \u0026#34;miDebuggerPath\u0026#34;: \u0026#34;/usr/local/bin/riscv64-unknown-elf-gdb\u0026#34;, \u0026#34;environment\u0026#34;: [], \u0026#34;externalConsole\u0026#34;: false, \u0026#34;MIMode\u0026#34;: \u0026#34;gdb\u0026#34;, \u0026#34;preLaunchTask\u0026#34;: \u0026#34;xv6build\u0026#34;, \u0026#34;setupCommands\u0026#34;: [ { \u0026#34;description\u0026#34;: \u0026#34;pretty printing\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;-enable-pretty-printing\u0026#34;, \u0026#34;ignoreFailures\u0026#34;: true, }, //在这里加载了寄存器信息表 { \u0026#34;text\u0026#34;: \u0026#34;set tdesc filename myxml.xml\u0026#34;, } ], //用于gdb调试的工具，可以发现gdb出错的原因 // \u0026#34;logging\u0026#34;: { // \u0026#34;engineLogging\u0026#34;: true, // \u0026#34;programOutput\u0026#34;: true, // } } ] } 3、F5运行后发现已经安静的停在main，此时你会发现寄存器恢复了 4、为了定制化xml，你可以修改内部结构但要遵守regnum排序，具体请自行尝试\n花了更多时间搜索log中提到的相关关键词，最后锁定了一个帖子：https://stackoverflow.com/questions/72759791/why-does-gdb-do-not-show-all-risc-v-csrs-when-debugging-bare-metal-program-runni（非常关键的帖子不然要花更多时间搞明白）\n我一直在思考怎么才能\u0026quot;hack\u0026quot;gdb，也就是让他不去读取那个寄存器的信息（毕竟gdb只是一个程序！是程序就可以改），在这个帖子我找到了潜在的解决方法。我们通过-exec maintenance print xml-tdesc成功在vscode看到了xml信息，根据描述我们知道gdb是通过qemu给的xml得到寄存器信息的，那么我们就有了一个想法，我们能不能不利用他给的xml进行寄存器读取，而是使用自己的xml呢？（因为它能保存，能保存就一定可以读取）\n一顿操作猛如虎我们找到了一个解决方法set tdesc filename xxxxx其中xxx是你保存的xml的相对地址（这里我直接复制保存为一个新的xml了）。在里面我们发现了罪魁祸首ustatus直接进行删去操作，然后搓搓小手开始进行设置工作。\n一开始我很高兴他在运行中加载不会报错，但发现这样还是显示不了寄存器，也许他要在开头修改才有用？于是我修改了launch让他在开头加载\u0026hellip;\n成功点亮~\n至此，我们能相对愉快的畅游vscode的调试世界了。\n五、修复注释高亮 这里我们用到了bear（具体原理可看jyy18课：），bear make创造的compile_commands.json 还需要让他生效\n💡 你可以参考https://zhangjk98.xyz/6.S081-VSCode-prepare-and-kernel-debugging/中提到的方法 也可以使用这个教程：https://simplestupidcode.github.io/post/2022062501.html\n你还可以配合使用ctrl+p输入文件跳转文件与ctrl+p输入#加上函数名查找函数相应部分来辅助查找 （这里笔者尝试了第一步clang没有完全运行，会提示typedef的问题，按照第一个博主的说法做了还是不行，但是很神奇的在加入第二个博主的cpp_properties.json后就可以跑起来了也可以跳转\u0026hellip;.计算机真神奇啊，如果你不能用其中的一个成功跳转和兼容运行，可以尝试两个都加上，然后make clean后重新make 或者重启vscode与clang插件。）\n六、调试控制台中省略exec 💡直接按照下列操作即可\n偷懒要偷到底！此时我们发现每次都要输入-exec进行gdb操作，这未免有些太麻烦了（我观摩了vscode在github上被一群人锐kuang评pen，为了让vscode的调试控制台能更加接近gdb的原生体验，我们还需要进行进一步操作：\n1、在vscode中搜索插件multi-command\n2、在.vscode中创建一个settings.json文件，内容为：\n{ \u0026#34;multiCommand.commands\u0026#34;: [ { \u0026#34;command\u0026#34;: \u0026#34;multiCommand.enterExec\u0026#34;, \u0026#34;sequence\u0026#34;: [ \u0026#34;repl.action.acceptInput\u0026#34;, {\u0026#34;command\u0026#34;: \u0026#34;editor.action.insertSnippet\u0026#34;, \u0026#34;args\u0026#34;: {\u0026#34;snippet\u0026#34;: \u0026#34;-exec \u0026#34;}} ] } ] } 3、分别按下ctrl+k ctrl+s 或者在首选项中打开键盘快捷方式设置，在右上角找到并点击：\n此时能看到keybindings.json，然后粘贴以下内容：\n[ { \u0026#34;key\u0026#34;: \u0026#34;enter\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;extension.multiCommand.execute\u0026#34; , \u0026#34;args\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;multiCommand.enterExec\u0026#34; }, \u0026#34;when\u0026#34;: \u0026#34;inDebugRepl\u0026#34; }, ] 接下来就重新开始调试，然后你会惊奇的发现回车的时候已经能够自动补全exec了，体验愉快使用原生gdb的快乐吧！\n七、追踪函数调用的踪迹 💡 1、你需要下载jyy29课中提到的trace，然后将它放在 根目录/mkfs 的文件夹下 2、如果你是ubuntu22.04系统，可以直接运行gdb -ex 'source mkfs/trace.py' mkfs/mkfs 如果你是ubuntu20.04系统，你可能会遇到一些问题，请参考下文提到的解决方法 3（可选）、如果你想看到更猛的状态机过程，你可以参考这个github的方法\n在代码的海洋中，用肉眼看代码显然是会超载的，也极其耗费时间；进行调试一步步看容易跳过关键步骤不得返回，令人懊恼不已，有什么方法可以让我们获得更快乐的debug体验？——trace，想想看超级武器strace，itrace吧，他能让我们一窥内核用户态的调用奥秘。（俗话说得好，读代码不如读执行）\n当然，如果想要更简单的方法，直接让gdb生成历史记录也是可以的，同样也可以类似pa中宏包裹的方式，自己做一个日志并保存输出到文本当中，这是所有程序都通用的一种方式。\n按照提示的操作后我们很自然可以得到结果（其他代码其实逻辑好理解一些，主要是文件系统写的实在是太邪门了）\n但你可能会想，我们能不能迁移到其他地方呢？我做了一些尝试（但也有一些问题，比如static的函数显示不了对应参数，内核调试没有尝试成功），如果你想体验或者魔改，可以参考改进我的方法看看能不能做的更好：\nTRACED = \u0026#39;main ls\u0026#39;.split() IGNORE = \u0026#39;buf fd\u0026#39;.split() class trace(gdb.Breakpoint): def stop(self): f, bt = gdb.selected_frame(), [] while f and f.is_valid(): if (name := f.name()) in TRACED: lvars = [f\u0026#39;{sym.name}={sym.value(f)}\u0026#39; for sym in f.block() if sym.is_argument and sym.name not in IGNORE] bt.append(f\u0026#39;\\033[32m{name}\\033[0m({\u0026#34;, \u0026#34;.join(lvars)})\u0026#39;) f = f.older() print(\u0026#39; \u0026#39; * (len(bt) - 1) + bt[0]) return False # won\u0026#39;t stop at this breakpoint gdb.execute(\u0026#39;target remote localhost:26000\u0026#39;) gdb.execute(\u0026#39;set prompt off\u0026#39;) gdb.execute(\u0026#39;set pagination off\u0026#39;) gdb.execute(\u0026#39;file ./user/_ls\u0026#39;) for fn in TRACED: trace(fn) 将代码保存为mytrace放在根目录后执行gdb -ex 'source mytrace.py' ，然后在其他地方make qemu-gdb ，此时发现打开gdb的终端有反应了但没有开始，你需要输入c，回车后就发现xv6运行起来了，然后按下ls，你就可以看到他打印了对应的调用栈和参数了，但这个trace对于ls实在是杀鸡用牛刀（因为我们可以通过vscode调试就非常清楚流程了），我们可以在更复杂的情况（比如文件系统）下再使用它。但不管如何，我们的调试武器库又一次增加了。\n7.1 Remote \u0026lsquo;g\u0026rsquo; packet reply is too long 你可能会见到形如\u0026quot;Remote \u0026lsquo;g\u0026rsquo; packet reply is too long\u0026quot;相关的问题，这很可能是因为gdb版本不支持或者太低，你可以更改gdb为gdb-multiarch或者riscv64-unknown-elf-gdb，如果都不行，你需要重新编译升级gdb版本，可以选择7.2的方式，或者参考这个方式重新编译gdb：http://rcore-os.cn/rCore-Tutorial-deploy/docs/pre-lab/gdb.html\n如果还不能解决，你可以参考这里对这个问题的解决方法：https://github.com/Alan-Lee123/TOSView\n7.2海象运算符等python不支持的问题 注意：你可能会在这里遇到:=运算符的问题，这是编译gdb选择的python太低的问题，你需要重新编译过gdb的版本让他能够支持：\n首先参考4.1下载gdb源码，然后进入主页面后分别运行\n(这个相当于选择菜单，我选择编译了支持全体系结构的gdb，同时内置python版本是3.8）\n./configure --with-python=/usr/bin/python3.8 --enable-targets=all --enable-64-bit-bfd make -j8 sudo make install 安装成功后再次运行即可成功！\n7.3 参数显示\u0026lt;optimized out\u0026gt; 如标题所示，我们只需要降低优化等级就好，在makefile中找到-o2改成-o0，并且注意到有关编译选项中有-o需要改成-o2（比如调试内核中的），修改后重新编译就可以解决问题\n外传：vscode和gdb是如何工作的？ 通过一波探索，我们对vscode的运行原理有了一点好奇心（当然对gdb调试也有，为什么要tcp？）\n我找到了这些相关资料（有空再写个博客好了）：\nhttps://fed.taobao.org/blog/taofed/do71ct/vscode-debug-source-analyse/\nhttps://blog.csdn.net/m0_37621078/article/details/113886458\n有关断点的故事也有很多可以说\u0026hellip;比如通过更换Int3中断指令使得断点可以生效，等到结束恢复为原来的指令。（这也是为什么优化等级高了有时候停不下来，因为没有对应的指令可以替换）\n谢谢你看到最后，如果有问题或者有更优雅的方式欢迎提出或者发送邮件:\nphysicoada@gmail.com\n也欢迎来我的github来找我玩：\nhttps://github.com/sanbuphy\nReference 基本环节的打通 MIT 6.S081 xv6调试不完全指北（包含了常见问题）\nhttps://www.cnblogs.com/KatyuMarisaBlog/p/13727565.html\n从零开始使用Vscode调试XV6（包含了task与launch）\nhttps://zhuanlan.zhihu.com/p/501901665\n6.S081的调试和VSCode环境配置（代码提示和自动补全以及风格化）\nhttps://zhangjk98.xyz/6.S081-VSCode-prepare-and-kernel-debugging/\n如果gdb调试报错Cannot access memory at address，也许需要在.gdbinit.tmpl-riscv加一条set riscv use-compressed-breakpoints yes\n有关gdb问题的排查 编译gdb最新版\nhttps://stackoverflow.com/questions/32773255/how-to-update-gdb-to-most-current-stable-version\n打印寄存器相关xml文件\nhttps://stackoverflow.com/questions/72759791/why-does-gdb-do-not-show-all-risc-v-csrs-when-debugging-bare-metal-program-runni\n修改寄存器定义\nhttps://blog.csdn.net/abeldeng/article/details/80325364\n有关vscode配置 launch的一些参数讲解\nhttps://blog.csdn.net/ZCShouCSDN/article/details/60466707\n优雅的配置launch.json：\nhttps://www.barretlee.com/blog/2019/03/18/debugging-in-vscode-tutorial/\nexec省略\nhttps://github.com/Microsoft/vscode-cpptools/issues/106#issuecomment-829008826\n其他\nhttps://www.lagerdata.com/articles/vscode-and-gdb\n","date":"2022-09-29T08:50:40+08:00","permalink":"https://sanbuphy.github.io/p/%E4%BC%98%E9%9B%85%E7%9A%84%E8%B0%83%E8%AF%95%E5%9C%A8vscode%E4%B8%8A%E5%AE%8C%E7%BE%8E%E8%B0%83%E8%AF%95xv6%E5%AE%8C%E7%BB%93/","title":"优雅的调试—在vscode上完美调试xv6（完结）"},{"content":" 从这我越来越感受到系统复杂度上升带来的挑战，也明白了抽象的根本目的。\n抽象是为了降低复杂度，为了系统能够更好的做大以及稳健和排错。\n而且抽象能让你切换不同的“后续程序”进行测试，甚至在大概率正确的载体上进行diff查看到底是哪一层出现了问题（参考各种native）\n如何相信抽象是对的？——对每一个抽象层完成后的充分测试。\n善用assert是魔法！\n（个人能力受限，挂在了2阶的最后pal阶段。。。也许有机会能请教大佬解决一下，这样就可以做第三阶段了，很可惜，但也只能这样了。）\n菜得承认，我的能力可能暂时就到此为止了；还是很想做完的，但是从时间成本和能力估计上是不行了。。。\n等以后变强了再挑战一次。\n2022年9月16日记\n上下文切换 自从有了上下文切换后，程序也就有了进程的概念。（从静止到运动的飞跃 ~~·）\n假设进程A运行的过程中触发了系统调用, 陷入到内核. 根据__am_asm_trap()的代码, A的上下文结构(Context)将会被保存到A的栈上. 在PA3中, 系统调用处理完毕之后, __am_asm_trap()会根据栈上保存的上下文结构来恢复A的上下文.\n如果我们先不着急恢复A的上下文, 而是先将栈顶指针切换到另一个进程B的栈上, 那会发生什么呢? 由于B的栈上存放了之前B保存的上下文结构, 接下来的操作就会根据这一结构来恢复B的上下文. 上下文切换其实就是不同进程之间的栈切换!\n进程控制块 有不少信息都是进程相关的, 除了刚才提到的上下文指针cp之外, 上文提到的栈空间也是如此. 为了方便对这些进程相关的信息进行管理, 操作系统使用一种叫进程控制块(PCB, process control block)的数据结构, 为每一个进程维护一个PCB. Nanos-lite使用一个联合体来把其它信息放置在进程堆栈的底部. 代码为每一个进程分配了一个32KB的堆栈, 已经足够使用了, 不会出现栈溢出导致UB. 在进行上下文切换的时候, 只需要把PCB中的cp指针返回给CTE的__am_irq_handle()函数即可, 剩余部分的代码会根据上下文结构恢复上下文.\n内核线程 对于刚刚加载完的进程, 我们要怎么切换到它来让它运行起来呢?? 答案很简单, 我们只需要在进程的栈上人工创建一个上下文结构, 使得将来切换的时候可以根据这个结构来正确地恢复上下文即可. 我们先把Nanos-lite中直接定义的一些测试函数作为程序. Nanos-lite提供了一个测试函数hello_fun()(在nanos-lite/src/proc.c中定义), 我们接下来的任务就是为它创建一个上下文, 然后切换到它来执行. 这样的执行流有一个专门的名称, 叫\u0026quot;内核线程\u0026quot;(kernel thread).\n创建内核线程的上下文是通过CTE提供的kcontext()函数 (在abstract-machine/am/src/$ISA/nemu/cte.c中定义)来实现的, 在Nanos-lite中, 我们可以通过一个context_kload()函数来进行进一步的封装: 它会调用kcontext()来创建上下文, 并把返回的指针记录到PCB的cp中\n上下文的创建和切换是CTE的工作, 而具体切换到哪个上下文, 则是由操作系统来决定的, 这项任务叫做进程调度 进程调度是由schedule()函数(在nanos-lite/src/proc.c中定义)来完成的, 它用于返回将要调度的进程上下文. 因此, 我们需要一种方式来记录当前正在运行哪一个进程, 这样我们才能在schedule()中返回另一个进程的上下文\n我们让schedule()总是切换到pcb[0]. 注意它的上下文是通过kcontext()创建的, 在schedule()中才决定要切换到它, 然后在CTE的__am_asm_trap()中才真正地恢复这一上下文.\n努力理解了一下，然后写了个汇编，成功点亮~（主要卡在kcontex如何传送area）\n这里还要思考一下area到底怎么才是对的。开头地址kstack.start应该拿谁？那段空间应该从哪边开始界定（这也是需要理解的坑）\n内核线程的参数 我们来创建两个内核线程, 给它们传递不同的参数, 然后在输出的信息中把参数也一同输出, 这样我们就能看到执行流在两个内核线程之间来回切换了! 我们只需要让kcontext()按照调用约定将arg放置在正确的位置, 将来hello_fun()执行的时候就可以获取正确的参数了.\n感叹这个设计真聪明~\n实现上下文切换(2) 根据讲义的上述内容, 实现以下功能:\n修改CTE的kcontext()函数, 使其支持参数arg的传递\n通过kcontext()创建第二个以hello_fun()为入口的内核线程, 并传递不同的参数\n修改Nanos-lite的schedule()函数, 使其轮流返回两个上下文\n你可以自行约定用何种类型来解析参数arg(整数, 字符, 字符串, 指针等皆可), 然后修改hello_fun()中的输出代码, 来按照你约定的方式解析arg. 如果你的实现正确, 你将会看到hello_fun()会轮流输出不同参数的信息.\n这里要想想，riscv用什么方法传参呢？然后思考一下会不会和我们之前的操作有没有冲突（本质是执行顺序的问题，实际上没任何问题）\n为什么这里叫做内核线程？我的想法是因为他在nanos内部调用实现，并且可以达到快速的执行流切换的效果。\n在真实的操作系统中, 内核中的很多后台任务, 守护服务和驱动程序都是以内核线程的形式存在的. 如果你执行ps aux, 你就会看到系统中有很多COMMAND中带有中括号的内核线程(例如[kthreadd]). 而创建和执行它们的原理, 也是和上面的实验内容非常相似(当然具体实现肯定会有所不同).\n有关一些调用约定：\n用户进程 创建用户进程上下文 在PA3的批处理系统中, 我们在naive_uload()中直接通过函数调用转移到用户进程的代码, 那时候使用的还是内核区的栈\n怎么知道的？因为naive_uload跳转的entry本质是在nanos的时候调用函数，出入栈都在内部完成。\n如果内核线程发生了栈溢出, 怎么办?\n如果能检测出来, 最好的方法就是触发kernel panic, 因为这时候内核的数据已经不再可信, 如果将一个被破坏的数据写回磁盘, 将会造成无法恢复的毁灭性损坏.\n好消息是, 内核线程的正确性可以由内核开发人员来保证, 这至少要比保证那些来路不明的用户进程的正确性要简单多了. 而坏消息则是, 大部分的内核bug都是第三方驱动程序导致的: 栈溢出算是少见的了, 更多的是use-after-free, double-free, 还有难以捉摸的并发bug. 而面对海量的第三方驱动程序, 内核开发人员也难以逐一保证其正确性. 如果你想到一个可以提升驱动程序代码质量的方法, 那就是为计算机系统领域作出贡献了.\nNanos-lite和Navy作了一项约定: Nanos-lite把栈顶位置设置到GPRx中, 然后由Navy里面的_start来把栈顶位置真正设置到栈指针寄存器中.\n这里我实现后一直出不来。。（首先记得不能在init加载程序了）\n最后发现原来是局部变量和全局的问题（我把参数设置在init，init结束后在stack上的参数自动没了。。。所以就找不到了），最好的方法是直接传入或者是全局变量\n此时有点“一起卡”的感觉，本质是因为pal 的屏幕io的时候就切换去跑hello了。（yield）\n问：如何验证仙剑奇侠传确实在使用用户栈而不是内核栈? 只要获取pal内部的地址信息在什么范围即可。\n还好检查了一下这个，一看发现我的pal还是在内核，直接翻车- -\n后面思考了一下发现应该是stack分配的问题。。这点上讲义确实不骗人 老老实实实现就行了。\n认真注意这句话：“目前我们让Nanos-lite把heap.end作为用户进程的栈顶, 然后把这个栈顶赋给用户进程的栈指针寄存器就可以了.”\n用户进程的参数 最适合存放参数和环境变量的地方就是用户栈了, 因为在首次切换到用户进程的时候, 用户栈上的内容就已经可以被用户进程访问. 于是操作系统在加载用户进程的时候, 还需要负责把argc/argv/envp以及相应的字符串放在用户栈中, 把它们的存放方式和位置作为和用户进程的约定之一, 这样用户进程在_start中就可以根据约定访问它们了.\nhttps://github.com/riscv-non-isa/riscv-elf-psabi-doc ABI手册有一节Process Initialization的内容, **里面详细约定了操作系统需要为用户进程的初始化提供哪些信息. **不过在我们的Project-N系统里面, 我们只需要一个简化版的Process Initialization就够了: 操作系统将argc/argv/envp及其相关内容放置到用户栈上, 然后将GPRx设置为argc所在的地址.\n这里遇到了一个问题，数组一旦作为参数传入后就退化成了指针，我们怎么才能求得正确的大小呢？一个机智的方式是在末尾留个NULL（很多东西都参考了这个设计），这样就可以随意遍历求得数组大小了。\n每次操作差点忘记操作栈顶导致翻车，一顿操作猛如虎安排好了用户栈的空间状况，成功跳过开头。（pal的代码写的确实比较通俗）\n实现带参数的SYS_execve 用户进程的参数还是应该由用户来指定的.最好能有一个方法能把用户指定的参数告诉操作系统, 让操作系统来把指定的参数放到新进程的用户栈里面. 为了实现带参数的SYS_execve, 我们可以在sys_execve()中直接调用context_uload(). 但我们还需要考虑如下的一些细节, 为了方便描述, 我们假设用户进程A将要通过SYS_execve来执行另一个新程序B.\n如何在A的执行流中创建用户进程B?\n如何结束A的执行流?\n我们可以从栈底(heap.end)到栈顶(栈指针sp当前的位置)列出用户栈中的内容:\nNanos-lite之前为A传递的用户进程参数(argc/argv/envp)\nA从_start开始进行函数调用的栈帧, 这个栈帧会一直生长, 直到调用了libos中的execve()\nCTE保存的上下文结构, 这是由于A在execve()中执行了系统调用自陷指令导致的\nNanos-lite从__am_irq_handle()开始进行函数调用的栈帧, 这个栈帧会一直生长, 直到调用了SYS_execve的系统调用处理函数\n通过上述分析, 我们得出一个重要的结论: 在加载B时, Nanos-lite使用的是A的用户栈! 这意味着在A的执行流结束之前, A的用户栈是不能被破坏的. 因此heap.end附近的用户栈是不能被B复用的, 我们应该申请一段新的内存作为B的用户栈\n可以让context_uload()统一通过调用new_page()函数来获得用户栈的内存空间. new_page()函数在nanos-lite/src/mm.c中定义, 它会通过一个pf指针来管理堆区, 用于分配一段大小为nr_page * 4KB的连续内存区域, 并返回这段区域的首地址. 我们让context_uload()通过new_page()来分配32KB的内存作为用户栈, 这对PA中的用户程序来说已经足够使用了.\n操作系统作为一个特殊的AM应用, 很多时候对动态内存申请却有更严格的要求, 例如申请一段起始地址是4KB整数倍的内存区域, malloc()通常不能满足这样的要求. 因此操作系统一般都会自己来管理堆区, 而不会调用klib中的malloc(). 在操作系统中管理堆区是MM(Memory Manager)模块的工作\n一开始理解错了什么是A还以为hello是A。。。。。然后被提醒后看了好几遍发现原来是这个意思= = （联系一下PA的上文，搞清楚到底是什么进程，这个进程在当下是什么，要换成什么进程）\n一顿操作猛如虎成功：\n这里运行nterm又挂了（其他都可以）我哭了- - 又开始排查问题，发现传入argc就会挂。。。具体原因不明，又要继续排查。最后发现是argv飞掉的问题（没有参数的时候如果传入指针拦不住）\n总结：你必须搞清楚上下文是怎么从创建到调度的全过程，这样才能理解关键的每一个细节。\n运行Busybox 我的不知道为啥遇到了致命的ld错误。。。。没办法跑\n只能放弃了（很神奇的ld符号缺失）\n虽然我后面暴力调整了源码可以编译通过了- -但是只能cat之类的基础功能。。。\n然后不知道为什么让虚拟机走了几次快照，就可以用了- -只能说计算机真神奇呀。。。\nWC也完美运行~\n—skip也同理完结~ 这阶段最主要的就是麻烦。。很多时候可能一不小心argv就会爆炸。\n第一阶段结束,这一阶段的关键就是1：上下文执行流是怎么保存和切换的 2：有关参数的指针小练习\n以下几个问题：\n终端如何读取用户的按键? 各种等待键盘事件。。。\nShell如何进行命令的解析? 可以类似eval,然后要注意argv的维护\n库函数如何根据命令解析出的字符串搜索到可执行文件? execvp，维护了一个PATH\n操作系统如何加载执行一个可执行文件? 维护参数表进入一个_start，处理后才进行真正的main（上下文切换和跳转）\n程序和内存位置（很感人的阅读环节） 绝对代码 一般来说, 程序的内存位置是在链接时刻(link time)确定的(Navy-apps中的程序就是这样), 以前的程序员甚至在程序中使用绝对地址来进行内存访问, 这两种代码称为绝对代码(absolute code). 绝对代码会假设程序中的对象(函数和数据)位于某个固定的位置, 绝对代码只能在固定的内存位置才能正确运行.\n操作系统在加载时刻分配的空闲内存位置, 并不总是能让这种程序正确运行. 因此, 这个问题的一个解决方案, 就是让操作系统记录程序的加载位置, 当一个程序试图加载到一个已经被使用的内存位置时, 加载将会失败, 操作系统将返回一个错误. 为了避免加载失败, 一个方法是为每个程序维护多个不同加载地址的版本, 期望其中有一个版本可以被成功加载.\n可重定位代码 为什么一定要提前确定一个程序的加载位置呢? 如果我们把链接时的重定位阶段往后推迟, 不就可以打破绝对代码的限制了吗?\n于是有程序员开发了一类\u0026quot;自重定位(self-relocation)\u0026ldquo;的特殊程序, 这种程序可以**在开始运行的时候, 先把自己重定位到其它内存位置, **然后再开始真正的运行. 这种重定位类型称为\u0026rdquo;运行时(run time)重定位\u0026quot;.\n但对多任务操作系统来说, 这并没有真正解决问题, 因为程序在运行时刻并不知道重定位的目标内存位置是否空闲.\n既然只有操作系统才知道内存是否空闲, 那就干脆让加载器来进行重定位吧, 于是有了\u0026quot;加载时(load time)重定位\u0026quot;的说法. 具体地, 加载器会申请一个空闲的内存位置, 然后将程序加载到这个内存位置, 并把程序重定位到这个内存位置, 之后才会执行这个程序. 今天的GNU/Linux就是通过这种方式来插入内核模块的.\n位置无关代码 PIC 有没有方法可以节省重定位的开销, 甚至不进行重定位呢? 但链接时的重定位又可能会产生绝对代码, 这并不是我们所希望的 . 如果程序中的所有寻址, 都是针对程序位置来进行相对寻址操作, 这样的程序就可以被加载到任意位置执行, 而不会出现绝对代码的问题\n这就是PIC(position-independent code, 位置无关代码)的基本思想. 今天的动态库都是PIC, 这样它们就可以被加载到任意的内存位置了. 此外, 如果一个可执行文件全部由PIC组成, 那么它有一个新名字, 叫PIE(position-independent executable, 位置无关可执行文件). 编译器可以通过特定的选项编译出PIE.\nPIE之所以能做到位置无关, 其实是要依赖于程序中一个叫GOT(global offset table, 全局偏移量表)的数据结构\n但总有一些包含绝对代码的程序, 考虑到兼容问题, 还需要想办法运行它们. 有没有更好的, 一劳永逸的方案呢?\n虚实交错的魔法 绝对代码经过编译链接之后, 程序看到的内存地址就会确定下来了, 加载运行的时候就会让程序使用这一内存地址, 来保证程序可以正确运行. 一种尝试是把程序看到的内存和它运行时候真正使用的内存解耦开来. 这就是虚拟内存的思想.\n有了虚拟内存之后, 进程只需要认为自己运行在虚拟地址上就可以了, 真正运行的时候, 才把虚拟地址映射到物理地址. 我们只要**把程序链接到一个固定的虚拟地址, 加载的时候把它们加载到不同的物理地址, 并维护好虚拟地址到物理地址的映射关系, **\n关键：硬件把物理地址映射成虚拟地址，维护地址映射功能。操作系统决定具体要把虚拟地址映射到哪些物理地址。\n虚拟内存机制是一个软硬协同才能工作的机制: 操作系统加载进程的时候决定要把进程的虚拟地址映射到哪些物理地址;\n等到进程真正运行之前, 还需要配置MMU, 把之前决定好的映射落实到硬件上, 进程运行的时候, MMU就会进行地址转换, 把进程的虚拟地址映射到操作系统希望的物理地址. （注意到这个映射是进程相关的: 不同的进程有不同的映射,）\n分段 MMU地址映射最简单的方法就是, 物理地址=虚拟地址+偏移量。即段式虚拟内存管理机制, 简称分段机制. 把物理内存划分成若干个段, 不同的进程就放到不同的段中运行, 进程不需要关心自己具体在哪一个段里面, 操作系统只要让不同的进程使用不同的偏移，进程之间就不会相互干扰\nMinix就是这样工作的, 一些简单的嵌入式系统和实时系统, 也是通过分段机制来进行虚存管理.\n但是很复杂+性能不高，实际上现在没什么人用这个了。。。。。\n超越容量的界限 这部分我看的有点吃力，参考了一些其他资料：\nhttps://blog.csdn.net/jinking01/article/details/107098437\nhttps://blog.csdn.net/starter____ _/article/details/100998087\nhttps://www.cnblogs.com/wkfvawl/p/11700301.html\n为什么 Linux 默认页大小是 4KB\nhttps://draveness.me/whys-the-design-linux-default-page/\n其中页目录项和页表项的结构是\npresent位表示物理页是否可用, 不可用的时候又分两种情况:\n物理页面由于交换技术被交换到磁盘中了, Page fault\n图访问一个未映射的线性地址, 并没有实际的物理页与之相对应, 就是一个非法操作\nR/W位表示物理页是否可写\nU/S位表示访问物理页所需要的权限, 如果一个ring 3的进程尝试访问一个ring 0的页面, 当然也会被判定为非法操作\n分页 事实上, 我们需要一种按需分配的虚存管理机制. 之所以分段机制不好实现按需分配, 就是因为段的粒度太大了, 为了实现这一目标, 我们需要反其道而行之: 把连续的存储空间分割成小片段, 以这些小片段为单位进行组织, 分配和管理. 这正是分页机制的核心思想\n分页机制引入了一个叫\u0026quot;页表\u0026quot;的结构, 页表中的每一个表项记录了一个虚拟页到物理页的映射关系, 来**把不必连续的物理页面重新组织成连续的虚拟地址空间. **\n操作系统首先需要以物理页为单位对内存进行管理. **每当加载程序的时候, 就给程序分配相应的物理页(注意这些物理页之间不必连续), 并为程序准备一个新的页表, 在页表中填写程序用到的虚拟页到这些物理页的映射关系. **\n等到程序运行的时候, 操作系统就**把之前为这个程序填写好的页表设置到MMU中, MMU就会根据页表的内容进行地址转换, **把程序的虚拟地址空间映射到操作系统所希望的物理地址空间上.\n每一张页目录和页表都有1024个表项, 每个表项的大小都是4字节, （4k）\n除了包含页表(或者物理页)的基地址, 还包含一些标志位信息. 要放在寄存器中是不可能的, 因此它们要放在内存中. 为了找到页目录, i386提供了一个CR3(control register 3)寄存器, 专门用于存放页目录的基地址. 这样,** 页级地址转换就从CR3开始一步一步地进行, 最终将虚拟地址转换成真正的物理地址, 这个过程称为一次page table walk.**\n总结：操作系统负责写好小纸条和分配关系，MMU负责执行小纸条。\n问：虚存管理中PIC的好处 我们之前提到, PIC的其中一个好处是可以将代码加载到任意内存位置执行. 如果配合虚存管理, PIC还有什么新的好处呢? (Hint: 动态库已经在享受这些好处了)\n问：理解分页细节 i386不是一个32位的处理器吗, 为什么表项中的基地址信息只有20位, 而不是32位? 答：页表信息表示本身需要2^12的空间，即4kb\n手册上提到表项(包括CR3)中的基地址都是物理地址, 物理地址是必须的吗? 能否使用虚拟地址? 整个页表的基址存放在 CR3 寄存器里。CR3 存放的是物理地址，这是整个地址转换最根本的基础。在系统初始化时，CR3 必须填入物理地址，否则没办法进行地址转换了。这个东西是要让 MMU \u0026ldquo;看\u0026quot;的，它是个硬件，只能看得懂物理地址。\n每个页表项（PML4E, PDPTE, PDE，PTE）里的基址，都是物理地址。\n但是，整个页转换表结构是存放内存里，属于虚拟地址。也就是：页转换表结构需要进行内存映射。\n为什么不采用一级页表? 或者说采用一级页表会有什么缺点? 当虚拟空间巨大的时候，页表项增多，页表本身占据的空间也会非常庞大。\n对于32位虚拟地址空间，假设页面大小为4K，页表项大小为4字节：\n一个进程有4G/4k = 2^20个页面 因为一个页面需要一个页表项来对应，所以，进程的页表项个数也为2^20个 不难得出该进程的页表占用了 2^20 * 4 / 4096(4k) = 1024个页面的大小\n没有必要让整个页表常驻内存，因为进程在一段时间内可能只需要访问某几个特定的页面。\n问：空指针真的是\u0026quot;空\u0026quot;的吗? 程序设计课上老师告诉你, 当一个指针变量的值等于NULL时, 代表空, 不指向任何东西. 仔细想想, 真的是这样吗? 当程序对空指针解引用的时候, 计算机内部具体都做了些什么? 你对空指针的本质有什么新的认识?\n进程试图访问一个未映射的线性地址, 并没有实际的物理页与之相对应，出现错误。\n或者访问没有权限的地址页，导致直接出错。\nLinux 中，每个进程空间的 0x0 虚拟地址开始的线性区(memory region)都会被映射到一个用户态没有访问权限的页上。通过这样的映射，内核可以保证没有别的页会映射到这个区域。\n编译器把空指针当做 0 对待，开心地让你去访问空指针。\n缺页异常处理程序被调用，因为在 0x0 的页没有在物理内存里面。\n缺页异常处理程序发现你没有访问的权限。\n内核发送 SIGSEGV 信号给进程，该信号默认是让进程自杀。\n出自https://www.quora.com/What-actually-happens-when-dereferencing-a-NULL-pointer-Usually-the-process-terminates-Does-the-reaction-depend-on-the-operating-system-or-is-it-controlled-by-the-compiler-Is-it-mandatory-that-NULL-always-be-defined-as-“0”-with-proper-casting\n这个文章不错，Linux C程序真的不能访问NULL指针吗：\nhttps://cloud.tencent.com/developer/article/1536302\n状态机视角下的虚存管理机制 fvm()函数可以认为是系统寄存器SR的一部分, 操作系统通过修改SR来对虚存进行管理\n在分页机制上运行Nanos-lite 为了让map()填写的映射生效, 我们还需要在NEMU中实现分页机制. 具体地, 我们需要实现以下两点:\n如何判断CPU当前是否处于分页模式?\n分页地址转换的具体过程应该如何实现?\n但这两点都是ISA相关的, 于是NEMU将它们抽象成相应的API:\n// 检查当前系统状态下对内存区间为[vaddr, vaddr + len), 类型为type的访问是否需要经过地址转换.\nint isa_mmu_check(vaddr_t vaddr, int len, int type);\n// 对内存区间为[vaddr, vaddr + len), 类型为type的内存访问进行地址转换\npaddr_t isa_mmu_translate(vaddr_t vaddr, int len, int type);\nriscv32的Sv32分页机制和x86非常类似, 只不过寄存器的名字和页表项结构有所不同: 在riscv32中, 页目录基地址和分页使能位都是位于satp寄存器中. 至于页表项结构的差异, 这里就不详细说明了, 还是RTFM吧.\n你需要理解分页地址转换的过程, 然后实现isa_mmu_check()(在nemu/src/isa/$ISA/include/isa-def.h中定义) 和isa_mmu_translate()(在nemu/src/isa/$ISA/system/mmu.c中定义), 你可以查阅NEMU的ISA相关API说明文档来了解它们的行为. 另外由于我们不打算实现保护机制, 在isa_mmu_translate()的实现中, 你务必使用assertion检查页目录项和页表项的present/valid位, 如果发现了一个无效的表项, 及时终止NEMU的运行, 否则调试将会非常困难. 这通常是由于你的实现错误引起的, 请检查实现的正确性.\n我参考了一些其他的关于页表叙述：\nhttps://xy-plus.gitbook.io/rcore-step-by-step/ye-biao-jian-jie\ncsr寄存器：\n地址和页表项的构成：\n此时一种最简单的解决方案是：将全部物理内存区域映射到虚拟地址空间。此时虚拟地址和物理地址之间会有一种简单的对应关系，称为 线性映射 ，具体关系式如下：\nvirtual address = physical address + offset\n具体的页表转换过程：\n注意到riscv32 中所有页面都是 4k 对齐，因此任何页表基地址的低 12 位一定是 0 。这使得我们在保存页表基址的时候只需要保存其高 22 位（PPN）。\n我思考了很久页目录项的每一项怎么实现………然后小伙伴提醒不需要那么复杂，只要最简单的地址索引就好… 顿时泪流满面。\n然后我们还要知道一点就是，map只需要实现填写一级和二级页表，然后一级就是用VA，二级是用VA+PA（图上都有，一个是正向思考一个是反向思考！）\n如果你感到很困难，把这个过程的每一步写下来（第一步做什么，第二部做什么，都要细化！写得出来才是懂了，没写出来就没真的懂。）\n而且还要注意看看map的循环，具体的源码是怎么样走的，要注意是顺序映射，所以不需要考虑很多花里胡哨的问题。（什么时候才要创造新页表？看循环其实就知道了。）\n此时还要注意一个点：\n对于不同isa的映射，我们跑的算是客户程序（所有的都是am上的客户程序），然后真正的转换到物理 还要guest到host（这个问题很坑）。其实就是一个问题：\n硬件层你怎么解引用？？怎么获取软件的信息？？？要用什么才能读取到软件的信息？？怎么read？ 这是非常关键且重要的问题，怎么在nemu实现“解引用”\n调不出来，想哭，发现是我的页表项加法有点问题（感觉是指针之类的运算问题），然后一个个仔细修改，发现问题出在最后的页表项，一顿尝试后终于调出来了 哭瞎QWQ 太好哭了\n实在绷不住了，借用了阿尼亚的mmu进行diff各种神奇的段错误。\n还要注意的是，在页表相关计算的时候要记得转换一下指针。。。别用指针做加法运算。。\n这东西让我怀疑了自己100次是不是不适合做PA\n在分页机制上运行用户进程 目前这个地址空间除了内核映射之外就没有其它内容了, 具体可以参考abstract-machine/am/src/$ISA/nemu/vme.c.\n不过, 此时loader()不能直接把用户进程加载到内存位置0x40000000附近了, 因为这个地址并不在内核的虚拟地址空间中, 内核不能直接访问它. loader()要做的事情是, 获取程序的大小之后, 以页为单位进行加载:\n申请一页空闲的物理页\n通过map()把这一物理页映射到用户进程的虚拟地址空间中. 由于AM native实现了权限检查, 为了让程序可以在AM native上正确运行, 你调用map()的时候需要将prot设置成可读可写可执行\n从文件中读入一页的内容到这一物理页中\n这一切都是为了让用户进程在将来可以正确地运行:** 用户进程在将来使用虚拟地址访问内存, 在loader为用户进程维护的映射下, 虚拟地址被转换成物理地址, 通过这一物理地址访问到的物理内存, 恰好就是用户进程想要访问的数据.**\n另一个需要考虑的问题是用户栈, 和loader()类似, 我们需要把new_page()申请得到的物理页通过map()映射到用户进程的虚拟地址空间中. 我们把用户栈的虚拟地址安排在用户进程虚拟地址空间的末尾, 你可以通过as.area.end来得到末尾的位置, 然后把用户栈的物理页映射到[as.area.end - 32KB, as.area.end)这段虚拟地址空间.\n最后, 为了让这一地址空间生效, 我们还需要将它落实到MMU中. 具体地, 我们希望在CTE恢复进程上下文的时候来切换地址空间. 为此, 我们需要将进程的地址空间描述符指针as-\u0026gt;ptr加入到上下文中, 框架代码已经实现了这一功能(见abstract-machine/am/include/arch/$ISA-nemu.h), 在x86中这一成员为cr3, 而在mips32/riscv32中则为pdir. 你还需要\n修改ucontext()的实现, 在创建的用户进程上下文中设置地址空间描述符指针\n在__am_irq_handle()的开头调用__am_get_cur_as() (在abstract-machine/am/src/$ISA/nemu/vme.c中定义), 来将当前的地址空间描述符指针保存到上下文中\n在__am_irq_handle()返回前调用__am_switch() (在abstract-machine/am/src/$ISA/nemu/vme.c中定义)来切换地址空间, 将被调度进程的地址空间落实到MMU中\n这里遇到的第一个大坑就是怎么优雅的改写loader（差点忘了具体程序头表的成分了，又去看书复习了一遍。。。）\n然后又忘了as里面其实是有个ptr的。。。。\n写loader实在蚌埠住了（浮躁了），开始抱大腿（卡在具体页读取思路上）\n此时我又被vaddr_ifetch没实现卡了一晚上 - -。。。。。（一直到不了mmu，直接说我要访问的地方飘了。。。。）出现了超边界提示。通过排查指令可以知道我们执行前会进行fetch_decode——isa_fetch_decode——instr_fetch——vaddr_ifetch，就发现了问题源。。\n然后发现神奇mepc之类都为0的问题。。。。开始怀疑上下文是不是有问题。。。一顿操作猛如虎调了一下用户栈相关，解决\n这里要重新实现一下sbrk的映射\n（笔者在这一阶段打出了GG）\n问：内核映射的作用 对于x86和riscv32, 在protect()中创建地址空间的时候, 有一处代码用于拷贝内核映射:\n// map kernel space\nmemcpy(updir, kas.ptr, PGSIZE);\n尝试注释这处代码, 重新编译并运行, 你会看到发生了错误. 请解释为什么会发生这个错误.\n","date":"2022-09-16T08:50:40+08:00","permalink":"https://sanbuphy.github.io/p/nju%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C-pa4%E7%AC%94%E8%AE%B0%E5%A4%A7%E7%BB%93%E5%B1%80/","title":"NJU计算机课程基础实验 PA4笔记（大结局）"},{"content":"Reference https://blog.csdn.net/zong596568821xp/article/details/92790502\nhttps://blog.csdn.net/u014303844/article/details/80394101\n一些关于nginx的常见操作：\nhttps://kalacloud.com/blog/how-to-install-nginx-on-ubuntu-20-04/\nnginx rtmp配置相关官方手册：\nhttps://github.com/arut/nginx-rtmp-module/wiki/Directives#server\n比较全的中文可参考conf文件内容解析\nhttps://www.jianshu.com/p/15316e0f3de1\n因为业务上需求需要将流拉下来处理后转为其他流推送出去，之前的博客内容涉及到的是rtsp流的处理，这次利用nginx服务器转发推rtmp流。（拉流后可以进行任何图像处理）\n操作环境：Ubuntu 20.04 + python3\nNginx服务器搭建 因为要将处理过的图片串成rtmp码流，因此，需要搭建一个rtmp服务器，常用的方案是Nginx服务器。\n安装依赖 sudo apt-get install openssl libssl-dev sudo apt-get install libpcre3 libpcre3-dev sudo apt-get install zlib1g-dev 安装nginx 首先下载nginx：\nhttp://nginx.org/en/download.html\n选择稳定版本即可，比如http://nginx.org/download/nginx-1.22.0.tar.gz\n以及nginx-rtmp-module:\ngit clone https://github.com/arut/nginx-rtmp-module.git 将两者放在同级目录的文件夹下：\n之后进入nginx的文件夹，依次运行指令进行编译：\n./configure --add-module=../nginx-rtmp-module make sudo make install 安装后的一些信息：\nnginx安装目录 /usr/local/nginx nginx配置目录 /usr/local/nginx/conf/nginx.conf nginx运行目录 /usr/local/nginx/sbin/nginx \u0026ndash;options 运行指令启动nginx:\nsudo /usr/local/nginx/sbin/nginx 在浏览器中输入localhost，若看到如下画面，表示运行成功\n配置nginx用于推流转发 可以采取vim或者vscode进行编辑\n这里采用vscode，首先运行\ncode /usr/local/nginx/conf/nginx.conf 接着找到对应位置进行填充：\n#地址为 /usr/local/nginx/conf/nginx.conf #注明：请勿直接覆盖原来的conf文件,这只是部分有关直播的内容 #配置RTMP，这个配置格式在github的readme上有详细说明 rtmp { server { listen 1935; #服务端口--默认 chunk_size 4096; #数据传输块的大小--默认 #设置直播的application名称是 mylive application mylive{ live on; #live on表示开启直播模式 } } } #请在http里面找到server http{ ...#这里有一些其他的配置 #复制粘贴这个替换原来的server server { listen 80; server_name localhost; location / { root html; index index.html index.htm; } location /pop/video { alias /var/video; } location /info { rtmp_stat all; rtmp_stat_stylesheet stat.xsl; } location /stat.xsl { root html; #这里可以进行一个替换 } } 如图所示：\n配置完之后，需要重启nginx\nsudo /usr/local/nginx/sbin/nginx -s reload\n接下来配置服务器的监控信息显示，修改之前server的一个路径信息,把这个路径改成开头下载好的module的绝对路径（因为那里面有个stat.xsl）：\n保存后重启nginx，然后然后在浏览器中输入localhost/info可看到如下界面：\n至此，完成了rtmp-nginx服务器的全部配置\n推流代码部分 import cv2 import subprocess rtsp = \u0026#34;随便选个视频源测试\u0026#34; rtmp = \u0026#39;rtmp://localhost:1935/mylive/test\u0026#39; # 读取视频并获取属性 cap = cv2.VideoCapture(rtsp) size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))) sizeStr = str(size[0]) + \u0026#39;x\u0026#39; + str(size[1]) print(\u0026#34;sezie is\\n\u0026#34;,sizeStr) command = [\u0026#39;ffmpeg\u0026#39;, \u0026#39;-y\u0026#39;, \u0026#39;-an\u0026#39;, \u0026#39;-f\u0026#39;, \u0026#39;rawvideo\u0026#39;, \u0026#39;-vcodec\u0026#39;,\u0026#39;rawvideo\u0026#39;, \u0026#39;-pix_fmt\u0026#39;, \u0026#39;bgr24\u0026#39;, \u0026#39;-s\u0026#39;, sizeStr, \u0026#39;-r\u0026#39;, \u0026#39;15\u0026#39;, \u0026#39;-i\u0026#39;, \u0026#39;-\u0026#39;, \u0026#39;-c:v\u0026#39;, \u0026#39;libx264\u0026#39;, \u0026#39;-pix_fmt\u0026#39;, \u0026#39;yuv420p\u0026#39;, \u0026#39;-preset\u0026#39;, \u0026#39;ultrafast\u0026#39;, \u0026#39;-f\u0026#39;, \u0026#39;flv\u0026#39;, rtmp] pipe = subprocess.Popen(command , shell=False , stdin=subprocess.PIPE ) while cap.isOpened(): success,frame1 = cap.read() # print(frame1.shape()) if success: #=================进行一些图像处理================= frame = cv2.rectangle(frame1,(50,200),(900,400),[0,255,255],2) #=================进行一些图像处理================= if cv2.waitKey(1) \u0026amp; 0xFF == ord(\u0026#39;q\u0026#39;): break pipe.stdin.write(frame1.tostring()) cap.release() pipe.terminate() 运行上述代码，然后在nginx服务器info上可查看推流情况\n之后用ffplay或者VLC等客户端软件即可查看推流视频\n可能遇到的坑： 推送时的fps选取要和源相近，不要自己随意跳帧。。。。否则speed会很奇葩的延迟。以1.0左右为准。\n快速重启可以写一个shell：\necho 你的sudo密码 | sudo -S /usr/local/nginx/sbin/nginx xdg-open http://localhost/info ","date":"2022-09-03T11:56:50+08:00","permalink":"https://sanbuphy.github.io/p/opencv%E8%AF%BB%E5%8F%96%E8%A7%86%E9%A2%91%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%90%8E%E6%8E%A8%E6%B5%81rtmp/","title":"opencv读取视频图像处理后推流rtmp"},{"content":" 4、简易文件系统 对用户程序来说, 它怎么知道文件位于ramdisk的哪一个位置呢? 更何况文件会动态地增删, 用户程序并不知情. 这说明, 把ramdisk的读写接口直接提供给用户程序来使用是不可行的. 操作系统还需要在存储介质的驱动程序之上为用户程序提供一种更高级的抽象, 那就是文件.\n定义一个简易文件系统sfs(Simple File System):\n每个文件的大小是固定的\n写文件时不允许超过原有文件的大小\n文件的数量是固定的, 不能创建新文件\n没有目录(/a/b/c）\n既然文件的数量和大小都是固定的, 我们自然可以把每一个文件分别固定在ramdisk中的某一个位置. 为了记录ramdisk中各个文件的名字和大小, 我们还需要一张\u0026quot;文件记录表\nnanos-lite/Makefile修改后然后运行make ARCH=riscv32-nemu update\n就会自动编译Navy中的程序, 并把navy-apps/fsimg/目录下的所有内容整合成ramdisk镜像navy-apps/build/ramdisk.img, 同时生成这个ramdisk镜像的文件记录表navy-apps/build/ramdisk.h, Nanos-lite的Makefile会通过软连接把它们链接到项目中.\n如果你修改了Navy中的内容, 请记得通过上述命令来更新镜像文件.\n\u0026ldquo;文件记录表\u0026quot;其实是一个数组, 数组的每个元素都是一个结构体:\ntypedef struct {\nchar *name; // 文件名\nsize_t size; // 文件大小\nsize_t disk_offset; // 文件在ramdisk中的偏移\n} Finfo;\n最基本的文件读写操作:\nsize_t read(const char *filename, void *buf, size_t len);\nsize_t write(const char *filename, void *buf, size_t len);\n操作系统中存在不少\u0026quot;没有名字\u0026quot;的文件（比如管道传输给另一个工具的标准输入，less等）. 为了统一管理它们, **通过一个编号来表示文件, 文件描述符(file descriptor). **\n一个文件描述符对应一个正在打开的文件, 由操作系统来维护文件描述符到具体文件的映射. 于是我们很自然地通过open()系统调用来打开一个文件, 并返回相应的文件描述符\nint open(const char *pathname, int flags, int mode);\n由于sfs的文件数目是固定的, 我们可以简单地把文件记录表的下标作为相应文件的文件描述符返回给用户程序. 在这以后, 所有文件操作都通过文件描述符来标识文件:\nsize_t read(int fd, void *buf, size_t len);\nsize_t write(int fd, const void *buf, size_t len);\nint close(int fd);\n我们为每一个已经打开的文件引入偏移量属性open_offset, 来记录目前文件操作的位置. 每次对文件读写了多少个字节, 偏移量就前进多少.\n偏移量可以通过lseek()系统调用来调整, 从而可以对文件中的任意位置进行读写:\nsize_t lseek(int fd, size_t offset, int whence);\n为了方便用户程序进行标准输入输出, 操作系统准备了三个默认的文件描述符:\n#define FD_STDIN 0\n#define FD_STDOUT 1\n#define FD_STDERR 2\n它们分别对应标准输入stdin, 标准输出stdout和标准错误stderr. 我们经常使用的printf, 最终会调用write(FD_STDOUT, buf, len)进行输出; 而scanf将会通过调用read(FD_STDIN, buf, len)进行读入.\nnanos-lite/src/fs.c中定义的file_table会包含nanos-lite/src/files.h, 其中前面还有3个特殊的文件: stdin, stdout和stderr的占位表项, 它们只是为了保证sfs和约定的标准输入输出的文件描述符保持一致, 例如根据约定stdout的文件描述符是1, 而我们添加了三个占位表项之后, 文件记录表中的1号下标也就不会分配给其它的普通文件了.\n根据以上信息, 我们就可以在文件系统中实现以下的文件操作了:\nint fs_open(const char *pathname, int flags, int mode);\nsize_t fs_read(int fd, void *buf, size_t len);\nsize_t fs_write(int fd, const void *buf, size_t len);\nsize_t fs_lseek(int fd, size_t offset, int whence);\nint fs_close(int fd);\n这些文件操作实际上是相应的系统调用在内核中的实现. 由于sfs中每一个文件都是固定的, 不会产生新文件, 因此\u0026rdquo;fs_open()没有找到pathname所指示的文件\u0026quot;属于异常情况, 你需要使用assertion终止程序运行.\n为了简化实现, 我们允许所有用户程序都可以对所有已存在的文件进行读写, 这样以后, 我们在实现fs_open()的时候就可以忽略flags和mode了.\n使用ramdisk_read()和ramdisk_write()来进行文件的真正读写.\n由于文件的大小是固定的, 在实现fs_read(), fs_write()和fs_lseek()的时候, 注意偏移量不要越过文件的边界.\n除了写入stdout和stderr之外(用putch()输出到串口), 其余对于stdin, stdout和stderr这三个特殊文件的操作可以直接忽略.\n由于sfs没有维护文件打开的状态, fs_close()可以直接返回0, 表示总是关闭成功.\n最后你还需要在Nanos-lite和Navy的libos中添加相应的系统调用, 来调用相应的文件操作.\n一开始看不懂表达的意思是啥。。。看着看着打算先写了再说。一顿操作猛如虎成功：（自由切换文件，拦截了奇怪的情况）\n一开始一直想不到怎么在loader对段头表处理部分可以隔离对ramdisk_read的依赖，因为参数数目不匹配。随后突然想到可以用lseek设置偏移再读写操作，而且我们可以利用结构体偏移量，那么这个抽象就是可以被完成的了。一顿操作猛如虎解除了loader的耦合。\n(这里要注意navy系统调用的返回值，请按照man填写否则吃大亏！手册！手册！手册！）\n我这里还遇到一个很坑的问题：边界拦截，自己把自己坑了，因为实际上失败返回-1即可，我自己给自己panic了- -。。。。这件事情告诉我们，好好按照man的规定不要自己花里胡哨QAQ\n为了更好的调试，学习pony哥方法给log换了个皮肤：\nhttps://cloud.tencent.com/developer/article/1142372\n一切皆文件 我们需要有一种方式对设备的功能进行抽象, 向用户程序提供统一的接口.\n内存是以字节编址的, 天然就是一个字节序列, 因而我们之前使用的ramdisk作为字节序列也更加显而易见了\n管道(shell命令中的|)是一种先进先出的字节序列, 本质上它是内存中的一个队列缓冲区\n磁盘也可以看成一个字节序列: 我们可以为磁盘上的每一个字节进行编号, 例如第x柱面第y磁头第z扇区中的第n字节, 把磁盘上的所有字节按照编号的大小进行排列, 便得到了一个字节序列\nsocket(网络套接字)也是一种字节序列, 它有一个缓冲区,** 负责存放接收到的网络数据包**,上层应用将socket中的内容看做是字节序列, 并通过一些特殊的文件操作来处理它们. 我们在PA2中介绍了DiffTest, 如果你RTFSC, 就会发现其中的qemu-diff就是通过socket与QEMU进行通信的, 而操作socket的方式就是fgetc()和fputc()\n操作系统提供的一些特殊的功能, 如随机数生成器, 也可以看成一个无穷长的字节序列\n文件就是字节序列, 那很自然地, 上面这些五花八门的字节序列应该都可以看成文件. 我们可以使用文件的接口来操作计算机上的一切, 而不必对它们进行详细的区分: 例如 navy-apps/Makefile的ramdisk规则通过管道把各个shell工具的输入输出连起来, 生成文件记录表\n虚拟文件系统 真实文件系统, 其实是指具体如何操作某一类文件。\nVFS其实是对不同种类的真实文件系统的抽象,** 它用一组API来描述了这些真实文件系统的抽象行为, 屏蔽了真实文件系统之间的差异,** 上层模块(比如系统调用处理函数)不必关心当前操作的文件具体是什么类型, 只要调用这一组API即可完成相应的文件操作\n只要把真实文件系统的访问方式包装成VFS的API, 上层模块无需修改任何代码, 就能支持一个新的真实文件系统了\n其中ReadFn和WriteFn分别是两种函数指针, 它们用于指向真正进行读写的函数, 并返回成功读写的字节数. 有了这两个函数指针, 我们只需要在文件记录表中对不同的文件设置不同的读写函数, 就可以通过f-\u0026gt;read()和f-\u0026gt;write()的方式来调用具体的读写函数了.\n由于特殊文件的数量很少, 我们约定, 当上述的函数指针为NULL时, 表示相应文件是一个普通文件, 通过ramdisk的API来进行文件的读写, 这样我们就不需要为大多数的普通文件显式指定ramdisk的读写函数了.\n我们把文件看成字节序列, 大部分字节序列都是\u0026quot;静止\u0026quot;的, 例如对于ramdisk和磁盘上的文件, 如果我们不对它们进行修改, 它们就会一直位于同一个地方, 这样的字节序列具有\u0026quot;位置\u0026quot;的概念; 但有一些特殊的字节序列并不是这样, 例如键入按键的字节序列是\u0026quot;流动\u0026quot;的, 被读出之后就不存在了, 这样的字节序列中的字节之间只有顺序关系, 但无法编号, 因此它们没有\u0026quot;位置\u0026quot;的概念. 属于前者的文件支持lseek操作, 存储这些文件的设备称为\u0026quot;块设备\u0026quot;; 而属于后者的文件则不支持lseek操作, 相应的设备称为\u0026quot;字符设备\u0026quot;. 真实的操作系统还会对lseek操作进行抽象, 我们在Nanos-lite中进行了简化, 就不实现这一抽象了.\n操作系统之上的IOE 有了VFS, 要把IOE抽象成文件就非常简单了.\n串口. 在Nanos-lite中, stdout和stderr都会输出到串口. 之前你可能会通过判断fd是否为1或2, 来决定sys_write()是否写入到串口. 现在有了VFS, 我们就不需要让系统调用处理函数关心这些特殊文件的情况了: 我们只需要在nanos-lite/src/device.c中实现serial_write(), 然后在文件记录表中设置相应的写函数, 就可以实现上述功能了. 由于串口是一个字符设备, 对应的字节序列没有\u0026quot;位置\u0026quot;的概念, 因此serial_write()中的offset参数可以忽略. 另外Nanos-lite也不打算支持stdin的读入, 因此在文件记录表中设置相应的报错函数即可.\n这一步比较简单，就按照描述加入即可，把fswrite进行一下抽象\n在Nanos-lite中, 我们也提供一个SYS_gettimeofday系统调用, 用户程序可以通过它读出当前的系统时间.\n根据以前的am依葫芦画瓢（实际上我们能知道am就是为了这时候做准备）\n替换成NDL库的过程中，注意NDL的导入（想想make的时候怎么搜索库）\n另一个输入设备是键盘, 按键信息对系统来说本质上就是到来了一个事件. 一种简单的方式是把事件以文本的形式表现出来, 我们定义以下两种事件,\n按下按键事件, 如kd RETURN表示按下回车键\n松开按键事件, 如ku A表示松开A键\n按键名称与AM中的定义的按键名相同, 均为大写. 此外, 一个事件以换行符\\n结束.\n我们采用文本形式来描述事件有两个好处, 首先文本显然是一种字节序列, 这使得事件很容易抽象成文件; 此外文本方式使得用户程序可以容易可读地解析事件的内容. Nanos-lite和Navy约定, 上述事件抽象成一个特殊文件/dev/events, 它需要支持读操作, 用户程序可以从中读出按键事件, 但它不必支持lseek, 因为它是一个字符设备.\n这里关键问题要理解：键入按键的字节序列是\u0026quot;流动\u0026quot;的, 被读出之后就不存在了, 它们没有\u0026quot;位置\u0026quot;的概念. 属于后者的文件则不支持lseek操作, 相应的设备称为\u0026quot;字符设备\u0026quot;，说明我们需要让数据直接被“读出”，也就是读函数中交互过程能直接把数据传送到我们需要的地方。\n答：实际上fopen得到的FILE也是可以通过转换得到最后的fd的，但是之所以不用是因为可能错误使用了fread，因为这系列的读写操作实际上是对FILE里面的缓冲区进行操作的，而我们的设备文件需要直接把我们需要的buf打印。\n注意对好各类接口（返回值 0和1以及对应的buf传输链即可得到结果）\nNanos-lite需要做的, 便是把显存抽象成文件. 显存本身也是一段存储空间, 它以行优先的方式存储了将要在屏幕上显示的像素. Nanos-lite和Navy约定, 把显存抽象成文件/dev/fb(fb为frame buffer之意), 它需要支持写操作和lseek, 以便于把像素更新到屏幕的指定位置上.\n其中\u0026quot;画布\u0026quot;是一个面向程序的概念, 程序绘图时的坐标都是针对画布来设定的, 这样程序就无需关心系统屏幕的大小, 以及需要将图像绘制到系统屏幕的哪一个位置. NDL可以根据系统屏幕大小以及画布大小, 来决定将画布\u0026quot;贴\u0026quot;到哪里, 例如贴到屏幕左上角或者居中, 从而将画布的内容写入到frame buffer中正确的位置.\nNDL_DrawRect()的功能和PA2中介绍的绘图接口是非常类似的. 但为了实现它, NDL还需要知道屏幕大小的信息. Nanos-lite和Navy约定, 屏幕大小的信息通过/proc/dispinfo文件来获得, 它需要支持读操作. navy-apps/README.md中对这个文件内容的格式进行了约定, 你需要阅读它. 至于具体的屏幕大小, 你需要通过IOE的相应API来获取.\n把VGA显存抽象成文件 实现fb_write()(在nanos-lite/src/device.c中定义), 用于把buf中的len字节写到屏幕上offset处. 你需要先从offset计算出屏幕上的坐标, 然后调用IOE来进行绘图. 另外我们约定每次绘图后总是马上将frame buffer中的内容同步到屏幕上.\n在NDL中实现NDL_DrawRect(), 通过往/dev/fb中的正确位置写入像素信息来绘制图像. 你需要梳理清楚系统屏幕(即frame buffer), NDL_OpenCanvas()打开的画布, 以及NDL_DrawRect()指示的绘制区域之间的位置关系.\n让Nanos-lite运行navy-apps/tests/bmp-test, 如果实现正确, 你将会看到屏幕上显示Project-N的logo.\n这里我一直卡着没做出来，主要是不理解fb_write和NDL_DrawRect到底要做什么。实际上要理解的是，绘制工作已经被am完成了，所以我们只需要吧数据全部丢过去即可。而重要的是在fs的特别write中根据am的接口把我们的数据喂过去（需要w,h,x,y的信息），而NDL是为喂过去而准备的。\n【其实就要注意一点，在navy中的读写其实都是依靠fs完成，所以对应的buff和len都是在navy才进行处理，因为那才是真正调用处理的函数，想想他们拿到的东西是什么，是不是一样】\n精彩纷呈的应用程序 miniSDL的代码位于navy-apps/libs/libminiSDL/目录下, 它由6个模块组成:\ntimer.c: 时钟管理\nevent.c: 事件处理\nvideo.c: 绘图接口\nfile.c: 文件抽象\naudio.c: 音频播放\ngeneral.c: 常规功能, 包括初始化, 错误管理等\n我们可以通过NDL来支撑miniSDL的底层实现, 让miniSDL向用户程序提供更丰富的功能, 这样我们就可以在Navy上运行更复杂的程序了. miniSDL中的API和SDL同名, 你可以通过RTFM来查阅这些API的具体行为. 另外miniSDL中的大部分API都没有实现, 你最好想个办法让程序用到某个未实现API的时候提醒你, 否则你可能难以理解由此导致的复杂程序非预期行为.\n虽然Navy的native和AM中的native同名, 但它们的机制是不同的: 在AM native上运行的系统, 需要AM, Nanos-lite, libos, libc这些抽象层来支撑上述的运行时环境, 在AM中的ARCH=native, 在Navy中对应的是ISA=am_native; 而在Navy native中, 上述运行时环境是直接由Linux native实现的.\n问：神奇的LD_PRELOAD bmp-test需要打开一个路径为/share/pictures/projectn.bmp的文件, 但在Linux native中, 这个路径对应的文件并不存在. 但我们还是把bmp-test成功运行起来了, 你知道这是如何实现的吗? 如果你感兴趣, 可以在互联网上搜索LD_PRELOAD相关的内容.\n答：LD_PRELOAD是Linux系统的一个环境变量，它可以影响程序的运行时的链接（Runtime linker），它允许你定义在程序运行前优先加载的动态链接库。这个功能主要就是用来有选择性的载入不同动态链接库中的相同函数。通过这个环境变量，我们可以在主程序和其动态链接库的中间加载别的动态链接库，甚至覆盖正常的函数库。一方面，我们可以以此功能来使用自己的或是更好的函数（无需别人的源码），而另一方面，我们也可以以向别人的程序注入程序，从而达到特定的目的。\nSDL2常用函数\u0026amp;结构分析:SDL_Surface\u0026amp;SDL_GetWindowSurface\u0026amp;SDL_LoadBMP\nhttps://blog.csdn.net/qq_25333681/article/details/89789479\n幻灯片显示：\n这里的pdf转换一开始我还以为只能转换开头那张pdf。。。经过查资料后成功转了其他页面~\n有可能会出现数字键爆炸的问题，请注意是否清除缓存以及键盘type。\n接下来实现menu，有点痛不欲生。。。\n其实SDL_FillRect的关键是要理解什么是像素。。。其实像素是一个“数组”里面根据00rrrggbb00rrrggbb这样的方式排列下去（4byte的情况），理解了这点就好办了。理解画布并不是要画上去，只是准备画布。\n接下来最难的就是SDL_BlitSurface的实现：\n实现后能看到这样的画面：开始菜单（还没有execve的功能）\nNTerm (NJU Terminal) Flappy Bird 这里我首当其冲遇到了爆炸问题：fe_read出边界，但实际上是手册没读好的问题。。。。（被pony哥拯救系列）\n然后又遇到了- -神奇的按键没反应的情况。。。。后面发现是对“事件”不够理解。。。如果你也遇到了请仔细阅读事件的定义然后反思下某个函数是否返回正确。。。。\n仙剑奇侠传 首先很快就找到了data（就是data，其他花里胡哨的不算）然后你可能会看到一坨大写文件发现段错误。。。。这里是个坑\n【具体查找过程开gdb，你会发现出错的地方。。。。。建议不要放过这个过程。】\n首先在pal下运行make ISA=native gdb 查找段错误的原因，此时你会看到一个io错误，fp=NULL（0x0），那么是什么文件打开错误呢？\n注意到讲义：此外, 你还需要创建配置文件sdlpal.cfg, 具体请阅读repo/docs/README.md和repo/docs/sdlpal.cfg.example.\n一顿操作找到了cfg文件，那么这个要放在那呢？\n先在makefile中加入-g 方便调试（具体什么地方自己找apps），然后在pal下继续gdb，r结束后bt打印堆栈信息，这时候你就会发现访问某个文件出错了，找到对应的文件即可（或者把cfg放进去。）。如果你发现他需要访问某个share/games之类的文件信息，检查下有没有，然后想想在之前的小鸟下做了什么操作。\n反复测试直到make ISA=native run不报错，此时你就发现make run 可以运行了！\n但是在这里native还不能运行，这是因为我们还没有处理调色盘（这里关键的是理解调色盘）\n注意到此时的pixels只是索引，那么我们要做的就是取出真正的像素做成真正的pixels喂给NDL即可。\n如果遇到有些update还是没有去除的奇怪情况，建议在pal重新install后再update run看看。\n处理完成后成功跑native~:\n接下来发现跑nemu还是有点问题，主要是update实现不对，又要返工一下ndl。。。。。（注意到这里的src→w和w其实是有区别的。我们需要理解以下几点：【我在这卡了特别久。。】\nNDL_DrawRect的xywh对pixels做什么，为什么\nSDL_UpdateRect的xywh要对surface做什么为什么？\n实际上这是一个抠图的过程。wh是我们在运行中需要扣出的范围，而实际上的s是画布，我们要把x,y偏移处的东西从surface抠出来然后更新到NDL中，让他更新到屏幕。\n然后这里我有个问题，就是我的x,y居中逻辑是错误的，因为没有旧xy的信息只是强制更新，容易出问题，换了一版新的逻辑正常了。\n我的fps只有6左右，有小伙伴最高11，不过还是感觉很流畅的~\n刚跑出来的时候我是特别开心的，高兴了一晚上睡不着。\n显卡读写是我的一生之敌，真的花了很久去理解像素的绘制，这个还是需要动手会比较直观。\n问：仙剑奇侠传的框架是如何工作的? 我们在PA2中讨论过一个游戏的基本框架, 尝试阅读仙剑奇侠传的代码, 找出基本框架是通过哪些函数实现的. 找到之后, 可能会对你调试仙剑奇侠传带来一定的帮助. 虽然仙剑奇侠传的代码很多, 但为了回答这个问题, 你并不需要阅读大量的代码.\n问：仙剑奇侠传的脚本引擎 在navy-apps/apps/pal/repo/src/game/script.c中有一个PAL_InterpretInstruction()的函数, 尝试大致了解这个函数的作用和行为. 然后大胆猜测一下, 仙剑奇侠传的开发者是如何开发这款游戏的? 你对\u0026quot;游戏引擎\u0026quot;是否有新的认识?\nam-kernels 开局一条狗内容全靠偷后实现（基本上native能跑就胜利）\n这里如果出现找不到文件错误，可以尝试一下子文件\nFCEUX 一开始卡着段错误。。。然后打印后发现其实是rom没有东西 是个NULL 。。\n翻了一下源码后恍然大悟，成功调出~\n快乐卡比\n展示你的批处理系统 这里我实现execve后遇到了魔数爆炸的情况。。。。最后发现是有个地方偏移没有清零- -。。。。。难怪读取不正确（总感觉是读写的问题）修改后一切正常~\n然后菜单menu一直有不显示的情况。。。感到非常伤心\n然后pony哥教我gdb调试后发现一个窗口创建的问题- -，不知道原因是什么,最后排查源码发现原来又是一个api没认真看手册漏的坑（之前被自己删掉了一句）。。。。open窗口，难怪一直不显示。\n修改后正常：（给不同游戏加个退出，就非常帅气了！）\n最后处理了一下execvp相关内容 顺利完成 ~~(原来不需要自己实现。。。害我之前还以为要自己设定env\n（不太完美的地方就是不会清屏~）\n接下来开始接受pa4的折磨。。。\n","date":"2022-08-28T08:50:40+08:00","permalink":"https://sanbuphy.github.io/p/nju%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C-pa3%E7%AC%94%E8%AE%B0%E4%BA%8C/","title":"NJU计算机课程基础实验 PA3笔记（二）"},{"content":" 写在前面：感谢pony、杨婆婆等群友的讨论和帮助，让我对PA有了更深入的理解。\n关于问题部分：请遵守学术诚信，有关提问都要自己思考（笔记也不会涉及到任何直接给出代码的部分，有关自己的心得体会很可能是错的，请自己思考。遵守以下协议：\n1、最简单的操作系统 Nanos-lite是运行在AM之上, AM的API在Nanos-lite中都是可用的. 虽然操作系统对我们来说是一个特殊的概念, 但在AM看来, 它只是一个调用AM API的普通C程序而已, Nanos-lite目前的行为:\n打印Project-N的logo, 并通过Log()输出hello信息和编译时间. 在Nanos-lite中, Log()宏通过你在klib中编写的printf()输出, 最终会调用TRM的putch().\n调用init_device()对设备进行一些初始化操作. 目前init_device()会直接调用ioe_init().\n在NEMU中对磁盘进行模拟是一个略显复杂工作, 先让Nanos-lite把其中的一段内存作为磁盘来使用. 这样的磁盘有一个专门的名字, 叫ramdisk.\ninit_fs()和init_proc(), 分别用于初始化文件系统和创建进程, 目前它们均未进行有意义的操作, 可以忽略它们.\n调用panic()结束Nanos-lite的运行.\n回顾历史, 要实现一个最简单的操作系统, 就要实现以下两点功能:\n用户程序执行结束之后, 可以跳转到操作系统的代码继续执行\n操作系统可以加载一个新的用户程序来执行\n（没错，就是fork与execve）\n为了操作系统的稳定性，我们所希望是一种可以限制入口的执行流切换方式,而不像用户程序那样可以随意切换PC跳转：\ni386：保护模式(protected mode)和特权级(privilege level)\nmips32处理器：内核模式和用户模式\nriscv32：机器模式(M-mode), 监控者模式(S-mode)和用户模式(U-mode)\n最厉害的是硬件检查：如mips32都是通过硬件检查，只要软件运行在硬件上面, 都无法逃出这一天网. 硬件保护机制使得恶意程序永远无法全身而退,\n在硬件中加入一些与特权级检查相关的门电路(例如比较器电路), 如果发现了非法操作, 就会抛出一个异常信号, 让CPU跳转到一个约定好的目标位置, 并进行后续处理.\n直接看看效果：\n此时会出现异常，因为我们还没实现csrw伪指令，但要注意的是这里中文文档有个错误，从csrwi的可以推测这里应该是csrrw，也可以直接看英文文档的说明\n这里我们发现了一个名词“控制状态寄存器”，应该如何理解呢？我们看看下文中对控制状态寄存器的解释。\n2、穿越时空的旅程 硬件需要提供一种可以限制入口的执行流切换方式. 这种方式就是自陷指令, 程序执行自陷指令之后, 就会陷入到操作系统预先设置好的跳转目标. 这个跳转目标也称为异常入口地址.\n非法指令可以定义成\u0026quot;不属于ISA手册描述范围的指令\u0026quot;, 而自陷指令可以认为是一种特殊的无条件失败. riscv32提供ecall指令作为自陷指令, 并提供一个mtvec寄存器来存放异常入口地址. 为了保存程序当前的状态, riscv32提供了一些特殊的系统寄存器, 叫控制状态寄存器(CSR寄存器). 在PA中, 我们只使用如下3个CSR寄存器:\n**mepc寄存器 **- 存放触发异常的PC\nmstatus寄存器 - 存放处理器的状态\nmcause寄存器 - 存放触发异常的原因\nriscv32触发异常后硬件的响应过程如下:\n将当前PC值保存到mepc寄存器\n在mcause寄存器中设置异常号\n从mtvec寄存器中取出异常入口地址\n跳转到异常入口地址\n上述保存程序状态以及跳转到异常入口地址的工作, 都是硬件自动完成的\n所以我们知道，如果要补全csrw指令，首先要能区分不同的控制状态寄存器，具体怎么区分呢，\n首先修复一下对应的指令，此时要注意的是CSR寄存器的实现方法。\n注意到：The standard RISC-V ISA sets aside a 12-bit encoding space (csr[11:0]) for up to 4,096 CSRs.\n此时需要查阅的是新手大礼包（具体是哪个需要自己RTFM）之Control and Status Registers——CSR Listing的Currently allocated RISC-V machine-level CSR addresses\n因为此时立即数位置对应的就是CSR地址，打印出来后发现是0x305查手册后发现也确实是mtvec——Machine trap-handler base address.\n根据手册的地址进行匹配并存入寄存器。\n状态机视角下的异常响应机制 SR[mepc] \u0026lt;- PC （发生异常的pc）\nSR[mcause] \u0026lt;- 一个描述失败原因的号码 PC \u0026lt;- SR[mtvec] （异常入口地址）\nfex: S -\u0026gt; {0, 1}, 给定状态机的任意状态S, fex(S)都可以唯一表示当前PC指向的指令是否可以成功执行\n将上下文管理抽象成CTE 程序的状态, 在操作系统中有一个等价的术语, 叫\u0026quot;上下文\u0026quot;.AM的一类新的API中名字叫CTE(ConText Extension).\n与IOE一样, 上下文管理的具体实现也是架构相关的: 例如上文提到, x86/mips32/riscv32中分别通过int/syscall/ecall指令来进行自陷, native中甚至可以通过一些神奇的库函数来模拟相应的功能\n操作系统的处理过程其实需要哪些信息：\n引发这次执行流切换的原因, 是程序除0, 非法指令, 还是触发断点, 又或者是程序自愿陷入操作系统? 程序的上下文了（寄存器）\n把这两点信息抽象成一种统一的表示方式, 就可以定义出CTE的API.\n对于切换原因, 我们只需要定义一种统一的描述方式即可. CTE定义了名为\u0026quot;事件\u0026quot;的数据结构(见abstract-machine/am/include/am.h)\n其中event表示事件编号, cause和ref是一些描述事件的补充信息, msg是事件信息字符串, 我们在PA中只会用到event. 然后, 我们只要定义一些统一的事件编号(上述枚举常量), 让每个架构在实现各自的CTE API时, 都统一通过上述结构体来描述执行流切换的原因,\n对于上下文, 我们只能将描述上下文的结构体类型名统一成Context至于其中的具体内容, 就无法进一步进行抽象了. 这主要是因为不同架构之间上下文信息的差异过大（比如各种寄存器）,在AM中, Context的具体成员也是由不同的架构自己定义的, 比如x86-nemu的Context结构体在abstract-machine/am/include/arch/x86-nemu.h\n不过大多数情况下, 操作系统并不需要单独访问Context结构中的成员. CTE也提供了一些的接口, 来让操作系统在必要的时候访问它们, 从而保证操作系统的相关代码与架构无关.\n最后还有另外两个统一的API:\nbool cte_init(Context* (*handler)(Event ev, Context *ctx))用于进行CTE相关的初始化操作. 其中它还接受一个来自操作系统的事件处理回调函数的指针, 当发生事件时,** CTE将会把事件和相关的上下文作为参数, 来调用这个回调函数, 交由操作系统进行后续处理**.\nvoid yield()用于进行自陷操作, 会触发一个编号为EVENT_YIELD事件.** 不同的ISA会使用不同的自陷指令来触发自陷操作**,\nQ：AM究竟给程序提供了多大的栈空间呢? 事实上, 如果你在PA2的时候尝试努力了解每一处细节, 你已经知道这个问题的答案了;\nA：\n_stack_top = ALIGN(0x1000);\n. = _stack_top + 0x8000;\n_stack_pointer = .;\nend = .;\n_end = .;\n_heap_start = ALIGN(0x1000);\n注意区别：\n/* Minimum stack size for a signal handler. */\n#define MINSIGSTKSZ 2048\n/* System default stack size. */\n#define SIGSTKSZ 8192\n插播一个潜在大坑 【发现者为jyyos群的杨婆婆，也是一位超神的大佬】：\n涉及到ra寄存器相关跳转的顺序问题，要严格按照这个顺序操作\n为什么呢？原因是如果我们的源操作数和目的操作数寄存器刚好是同一个的时候（比如ra），重复写入会直接覆盖值，如果我们先用pc+4赋值，很可能再次使用的时候就会出大问题，值被提前覆盖了！！！\n尝试在Nanos-lite中触发一次自陷操作 设置异常入口地址 按照ISA的约定来设置异常入口地址, 将来切换执行流时才能跳转到正确的异常入口. 这显然是架构相关的行为, 因此我们把这一行为放入CTE中, 而不是让Nanos-lite直接来设置异常入口地址. 你需要在nanos-lite/include/common.h中定义宏HAS_CTE, 这样以后, Nanos-lite会多进行一项初始化工作: 调用init_irq()函数, 这最终会调用位于abstract-machine/am/src/nemu/isa/$ISA/cte.c中的cte_init()函数. cte_init()函数会做两件事情, 第一件就是设置异常入口地址\ncte_init()函数做的第二件事是注册一个事件处理回调函数, 这个回调函数由Nanos-lite提供,\n对于riscv32来说, 直接将异常入口地址设置到mtvec寄存器中即可. 实现完各种指令框架后我们能看到\n这时还没完全实现ecall，进入实现过程：\n你需要实现上文提到的新指令, 并实现isa_raise_intr()函数. 然后阅读cte_init()的代码, 找出相应的异常入口地址.\n实现后, 重新运行Nanos-lite, 如果你发现NEMU确实跳转到你找到的异常入口地址, 说明你的实现正确\n你需要在自陷指令的辅助函数中调用isa_raise_intr()\n此时先实现isa_raise_intr，模拟上文提到的异常响应机制：\n会发现我们需要找到一个NO，而这个异常NO可以在yield的代码中“领略到怎么获取”，我们直接看他的汇编代码asm volatile(\u0026quot;li a7, -1; ecall\u0026quot;); 可以猜想是不是和a7有关呢？这时候可以拿出a7看看。至于怎么拿出，这个就是基础操作了。（注意：这里其实是错误的，之后会说为什么）\n同时我们再看到asm volatile(\u0026quot;csrw mtvec, %0\u0026quot; : : \u0026quot;r\u0026quot;(__am_asm_trap));\n这是什么意思呢，首先我们能知道应该是把寄存器的值写入控制状态寄存器（有理由猜测这就是异常地址），那后面的\u0026quot;r\u0026quot;是什么意思呢？\n我们可以对照一下知道了那是输入操作数，我们有理由猜测这就是为了把trap相关的地址存到mtvec，在另外一个文件可以看到类似的东西\n此时大胆猜测这就是异常相关入口。\n一顿操作猛如虎实现了ecall调用，找了个地方加入了异常处理的寄存器：\n开diff检查发现了问题：\n为啥是b呢？我们发现这其实是mcause的返回值，难道不是前面的li a7 -1吗？？？\n经过搜索手册可以查到那其实表示一种environment call。\n经过查阅资料：\nRISC-V中系统调用通过（environment call）来实现。在U-mode、S-mode、M-mode下执行 ecall分别会触发environment-call-from-U-mode异常、environment-call-from-S-mode异常、environment-call-from-M-mode异常。在系统调用的实现中，我们通过在U-mode下执行 ecall触发environment-call-from-U-mode异常，并由S-mode中运行的内核处理这个异常。\n在head.S中内核boot阶段时，设置 medeleg 寄存器为用户模式系统调用添加异常委托。 在没有设置异常委托的情况下，ecall指令产生的异常由M-mode来处理，而不是交由内核所在的S-mode进行处理。通过 medeleg 中设置相应的位，可以将environment-call-from-U-mode异常直接交由S-mode处理。\n链接：https://www.zhihu.com/question/24960401/answer/2308952497 来源：知乎 那么里面的U,S,M是什么意思呢？以支持现代操作系统的RISC-V处理器为例, 它们存在M, S, U三个特权模式, 分别代表机器模式, 监管者模式和用户模式. M模式特权级最高, U模式特权级最低。所以我们知道了到底是什么调用。\n华中科技大学操作系统团队：https://gitee.com/hustos/pke-doc/blob/master/chapter1_riscv.md\n系统发生中断（我们用中文的“中断”这个名词来指代广义的中断，并非以上的interrupt）时执行的这段程序，往往被称为中断例程（interrupt routine）。因为事件的多样性，系统可能有多个这样的中断例程，通常的做法是把这些例程的入口放在一张表中，而这张表一般称为中断向量表（interrupt table）。RV64G处理器在发生中断后，会将发生的中断类型、编号自动记录（硬件完成）到目标模式的CSR中。假设发生中断的目标模式为M模式，则中断的这些信息会记录到mcause寄存器。 表1.7列出了mcause的可能取值以及对应的中断信息\n那么a7到底是什么呢，从man syscall可以查到，原来只是用于存放syscall调用号的地方，并不是真正的mcause，只是为了触发自陷操作,不同ISA的实现不同的(可以全局搜索yield)\n（至于为什么是-1，和小伙伴讨论还是个迷）\n接下来目的就是找到正确的mcause，什么才是正确的呢？这里就需要你查手册理解PA有几种模式了，以及理解为什么说在后面我们会再次用到isa_raise_intr()函数。（想想isa_raise_intr()的翻译是什么？并不是异常指令）\n你可以用diff检查自己实现的对不对。\n通过diff检查：\n保存上下文 现在的通用寄存器, 里面存放的都是执行流切换之前的内容. 这些内容也是上下文的一部分, 如果不保存就覆盖它们, 将来就无法恢复这一上下文了. 但通常硬件并不负责保存它们, 因此需要通过软件代码来保存它们的值. riscv32则通过sw指令将各个通用寄存器依次压栈.\n除了通用寄存器之外, 上下文还包括:\n**触发异常时的PC和处理器状态. **epc/mepc和status/mstatus寄存器, 异常响应机制把它们保存在相应的系统寄存器中, 我们还需要将它们从系统寄存器中读出, 然后保存在堆栈上.\n**异常号. **异常号已经由硬件保存在cause/mcause寄存器中, 我们还需要将其保存在堆栈上.\n地址空间. 这是为PA4准备的,将地址空间信息与0号寄存器共用存储空间, 反正0号寄存器的值总是0, 也不需要保存和恢复. 我们暂时不使用地址空间信息, 你目前可以忽略它们的含义.\n问：异常号的保存 Q:x86通过软件来保存异常号, 没有类似cause的寄存器. mips32和riscv32也可以这样吗? 为什么?\nA：我认为可以，因为异常地址之类的都能保存到上下文信息，那么riscv也可以有。\n重新组织Context结构体 你的任务如下:\n实现这一过程中的新指令, 详情请RTFM.\n理解上下文形成的过程并RTFSC, 然后重新组织abstract-machine/am/include/arch/$ISA-nemu.h 中定义的Context结构体的成员, 使得这些成员的定义顺序和 abstract-machine/am/src/$ISA/nemu/trap.S中构造的上下文保持一致.\n需要注意的是, 虽然我们目前暂时不使用上文提到的地址空间信息, 但你在重新组织Context结构体时仍然需要正确地处理地址空间信息的位置, 否则你可能会在PA4中遇到难以理解的错误.\n实现之后, 你可以在__am_irq_handle()中通过printf输出上下文c的内容, 然后通过简易调试器观察触发自陷时的寄存器状态, 从而检查你的Context实现是否正确.\n这部分关键是理解结构体和汇编语言的关系，让我们看一段示例代码：\nstruct test { char ch; short s; int i; long l; }; int fun(void) { int ret; struct test tmp; ret=0; tmp.ch=\u0026#39;a\u0026#39;; tmp.s=123; tmp.i=1234; tmp.l=12345; return ret; } 汇编代码：\npushl %ebp movl %esp, %ebp subl $16, %esp //ret=0; movl $0, -16(%ebp) //tmp.ch=\u0026#39;a\u0026#39;; movb $97, -12(%ebp) //tmp.s=123; movw $123, -10(%ebp) //tmp.i=1234; movl $1234, -8(%ebp) //tmp.l=12345; movl $12345, -4(%ebp) //返回值 movl -16(%ebp), %eax leave ret 从顺序上我们就知道根据压入栈该如何组织结构体了，同时我们也可以在handler处理后看到结果。\n问：必答题(需要在实验报告中回答) - 理解上下文结构体的前世今生 你会在__am_irq_handle()中看到有一个上下文结构指针c, c指向的上下文结构究竟在哪里? 这个上下文结构又是怎么来的? 具体地, 这个上下文结构有很多成员, 每一个成员究竟在哪里赋值的? $ISA-nemu.h, trap.S, 上述讲义文字, 以及你刚刚在NEMU中实现的新指令, 这四部分内容又有什么联系?\n答：本质是Context* (user_handler)(Event, Context)的结构体指针。其中定义在am.h，赋值在cte_init阶段初始化\n（怀疑就是为了软件存储上下文信息。所谓的保存到堆栈（S的过程））\n具体的Context是怎么被加载的？\n首先我们能在S中找到.globl __am_asm_trap，其中.globl关键字作用是\n能被链接后，就会和extern相对应，所以我们确定__am_irq_trap 是可以在链接过程打包到可执行文件的\n再回顾S代码，我们发现这确实就是结构体的push过程。最开始是寄存器，最后是mepc。（我们可以通过打印结构体指针的讯息来看看是不是对应的位置（比如mepc）。）同时我们可以注意到jal __am_irq_handle，这里就真正跳转到了框架代码。但这个明明是Context ，哪来的Context？\n可以合理猜测应该是mv a0,sp 中传入sp得到了context的指针信息Context *c，而结构体指针的第一个成员的地址也即是结构体指针的地址。\n事件分发 __am_irq_handle()的代码会把执行流切换的原因打包成事件, 然后调用在cte_init()中注册的事件处理回调函数（user_handler）, 将事件交给Nanos-lite来处理\n实现完成后发现卡在自现异常的死循环,之后会解决这个问题\n恢复上下文 代码将会一路返回到trap.S的__am_asm_trap()中, 接下来的事情就是恢复程序的上下文. __am_asm_trap()将根据之前保存的上下文内容, 恢复程序的状态, 最后执行\u0026quot;异常返回指令\u0026quot;返回到程序触发异常之前的状态.\n需要注意之前自陷指令保存的PCr。iscv32的ecall, 保存的是自陷指令的PC, 因此需要在适当的地方对保存的PC加上4, 使得将来返回到自陷指令的下一条指令.\n什么叫做合适的地方？我们该想想什么叫做恢复上下文——用什么恢复？\n所以我们应该在恢复的地方将pc+4。\n问：从加4操作看CISC和RISC 事实上, 自陷只是其中一种异常类型. 有一种故障类异常, 它们返回的PC和触发异常的PC是同一个, 例如缺页异常, 在系统将故障排除后, 将会重新执行相同的指令进行重试, 因此异常返回的PC无需加4. 所以根据异常类型的不同, 有时候需要加4, 有时候则不需要加.\n这时候, 我们就可以考虑这样的一个问题了: 决定要不要加4的, 是硬件还是软件呢? CISC和RISC的做法正好相反, CISC都交给硬件来做, 而RISC则交给软件来做. 思考一下, 这两种方案各有什么取舍? 你认为哪种更合理呢? 为什么?\n答：riscv不支持用硬件，只有一个，是因为pc要存在mepc里，mepc只有1个，x86执行到int指令后会直接把flags,cs,ip压栈。x86是硬件做的 (by pony)\n而且我倾向于x86放在硬件主要是指令太多，放在软件会拖慢速度而且可能会导致奇奇怪怪的问题。\n问：必答题(需要在实验报告中回答) - 理解穿越时空的旅程 从Nanos-lite调用yield()开始, 到从yield()返回的期间, 这一趟旅程具体经历了什么? 软(AM, Nanos-lite)硬(NEMU)件是如何相互协助来完成这趟旅程的? 你需要解释这一过程中的每一处细节, 包括涉及的每一行汇编代码/C代码的行为, 尤其是一些比较关键的指令/变量. 事实上, 上文的必答题\u0026quot;理解上下文结构体的前世今生\u0026quot;已经涵盖了这趟旅程中的一部分, 你可以把它的回答包含进来.\n别被\u0026quot;每一行代码\u0026quot;吓到了, 这个过程也就大约50行代码, 要完全理解透彻并不是不可能的. 我们之所以设置这道必答题, 是为了强迫你理解清楚这个过程中的每一处细节. 这一理解是如此重要, 以至于如果你缺少它, 接下来你面对bug几乎是束手无策\n答：暂时参考理解上下文结构体的前世今生\n3、用户程序和系统调用 这部分强烈推荐先看袁妈妈有关链接和可执行文件的讲解\n简直是手把手喂给你：\nhttps://www.bilibili.com/video/BV1kE411X7S5\n加载第一个用户程序 加载的过程就是把可执行文件中的代码和数据放置在正确的内存位置,\n然后跳转到程序入口, 程序就开始执行了. 更具体的, 为了实现loader()函数, 我们需要解决以下问题:\n可执行文件在哪里?\n代码和数据在可执行文件的哪个位置?\n代码和数据有多少?\n\u0026ldquo;正确的内存位置\u0026quot;在哪里?\n其中, navy-apps/libs/libc中是一个名为Newlib的项目, 它是一个专门为嵌入式系统提供的C库, 库中的函数对运行时环境的要求极低. 用户程序的入口位于navy-apps/libs/libos/src/crt0/start/$ISA.S中的_start()函数, 这里的crt是C RunTime的缩写, 0的含义表示最开始. _start()函数会调用navy-apps/libs/libos/src/crt0/crt0.c中的call_main()函数, 然后调用用户程序的main()函数, 从main()函数返回后会调用exit()结束运行.\n我们约定目前用户程序需要被链接到内存位置0x83000000附近, Navy已经设置好了相应的选项(见navy-apps/scripts/$ISA.mk中的LDFLAGS变量).\n注：这里我的电脑在make ISA=riscv32的时候出现了问题，我怀疑是交叉汇编环境冲突。。不明白(assert.h相关说undefined reference to `__assert_fail\u0026rsquo;）于是从另外一个电脑弄来了编译通过的文件。\n可执行文件位于ramdisk偏移为0处, 访问它就可以得到用户程序的第一个字节.\n问：堆和栈在哪里? 我们提到了代码和数据都在可执行文件里面, 但却没有提到堆(heap)和栈(stack). 为什么堆和栈的内容没有放入可执行文件里面? 那程序运行时刻用到的堆和栈又是怎么来的? AM的代码是否能给你带来一些启发?\n答：这些代码和数据本身都是静态的。程序要想运行，首先要OS负责为其创建进程，并在进程的虚拟地址空间中为其代码段和数据段建立映射。光有代码段和数据段是不够的，进程在运行过程中还要有其动态环境，其中最重要的就是堆栈。\n内核在创建进程的时候，在创建task_struct的同时，会为进程创建相应的堆栈。每个进程会有两个栈，一个用户栈，存在于用户空间，一个内核栈，存在于内核空间。\n问：如何识别不同格式的可执行文件? 如果你在GNU/Linux下执行一个从Windows拷过来的可执行文件, 将会报告\u0026quot;格式错误\u0026rdquo;. 思考一下, GNU/Linux是如何知道\u0026quot;格式错误\u0026quot;的?\n答：\n不同组织形式形成了不同格式的可执行文件, 例如Windows主流的可执行文件是PE(Portable Executable)格式, 而GNU/Linux主要使用ELF(Executable and Linkable Format)格式. 因此一般情况下, 你不能在Windows下把一个可执行文件拷贝到GNU/Linux下执行, 反之亦然. ELF是GNU/Linux可执行文件的标准格式, 这是因为GNU/Linux遵循System V ABI(Application Binary Interface).\nE:可执行 L：链接\n通过解析数据结构可以得到信息。比如ELF头。\nELF文件提供了两个视角来组织一个可执行文件,\n一个是面向链接过程的section视角, 这个视角提供了用于链接与重定位的信息(例如符号表); 另一个是面向执行的segment视角, 这个视角提供了用于加载可执行文件的信息. 可以参考这篇文章：https://blog.csdn.net/GoolyOh/article/details/119801160\n一个segment可能由0个或多个section组成, 但一个section可能不被包含于任何segment中.\nprogram header table的一个表项描述了一个segment的所有属性, 包括类型, 虚拟地址, 标志, 对齐方式, 以及文件内偏移量和segment大小.\n加载一个可执行文件并不是加载它所包含的所有内容, 只要加载那些与运行时刻相关的内容就可以了, 例如调试信息和符号表就不必加载. 我们可以通过判断segment的Type属性是否为PT_LOAD来判断一个segment是否需要加载.\n问：冗余的属性? 使用readelf查看一个ELF文件的信息, 你会看到一个segment包含两个大小的属性, 分别是FileSiz和MemSiz, 这是为什么? 再仔细观察一下, 你会发现FileSiz通常不会大于相应的MemSiz, 这又是为什么?\n答： 相对文件偏移Offset指出相应segment的内容从ELF文件的第Offset字节开始,在文件中的大小为FileSiz, 它需要被分配到以VirtAddr为首地址的虚拟内存位置, 在内存中它占用大小为MemSiz.\n这个segment使用的内存就是[VirtAddr, VirtAddr + MemSiz)这一连续区间, 然后将segment的内容从ELF文件中读入到这一内存区间, 想想为什么要预留nobits的空间——本质是.bss相关。\n你需要找出每一个需要加载的segment的Offset, VirtAddr, FileSiz和MemSiz这些参数. 其中相对文件偏移Offset指出相应segment的内容从ELF文件的第Offset字节开始, 在文件中的大小为FileSiz, 它需要被分配到以VirtAddr为首地址的虚拟内存位置, 在内存中它占用大小为MemSiz. 也就是说, 这个segment使用的内存就是[VirtAddr, VirtAddr + MemSiz)这一连续区间, 然后将segment的内容从ELF文件中读入到这一内存区间, 并将[VirtAddr + FileSiz, VirtAddr + MemSiz)对应的物理区间清零.\n问：为什么要清零? 为什么需要将 [VirtAddr + FileSiz, VirtAddr + MemSiz) 对应的物理区间清零?\n.bss清零的原因:(注意初始化为0的全局变量也在bss）\n转载自：http://www.zhihu.com/question/23147702/answer/23738366\nBSS段清零的原因是因为这个段是BSS 要说为什么要有BSS的话，历史就比较久远了。 BSS段我所知道的起源是Unix最初的时候（当然，不排除可能有更早的情况）。变量分两种：局部变量、全局变量。根据C语法的规定，局部变量不设置初始值的时候，其初始值是不确定的，局部变量（不含静态局部变量）的存储位置位于栈上，具体位置不固定。全局变量（和静态局部变量）有专门数据段存储，初始值是0，具体位置是固定的。其实说到底，就两种，一种是位置固定（数据段里），一种是位置不固定的（栈上）。 要知道，早期的计算机存储设备是很贵的，而很多时候，数据段里的全局变量都是0（或者没有初始值），那么存储这么多的0到目标文件里其实是没有必要的。所以为了节约空间，在生成目标文件的时候，就把没有初始值（实际就是0）的数据段里的变量都放到BSS段里，这样目标文件就不需要那么大的体积里（节约磁盘空间）。只有当目标文件被载入的时候，加载器负责把BSS段清零（一个循环就可以搞定）。 之后，这个规则慢慢的成为一个标准配置，大多数编译器也就都支持了BSS段。\nQ:如果BSS不清零可不可以？ A:可以，如果编译器规定BSS段不清零，也是可以的，但这样的话C语言语法就要改了：未初始化的全局变量和静态局部变量，其值是未知的。甚至其它语言也要跟着改语法。 所以，BSS段清零的原因是因为这个段是BSS\n插播ld过程： http://learn.lianglianglee.com/专栏/深入浅出计算机组成原理/08 ELF和静态链接：为什么程序无法同时在Linux和Windows下运行？.md\n自己的补充：C语言的标准对于未初始化的数据是UB还是0 https://stackoverflow.com/questions/1597405/what-happens-to-a-declared-uninitialized-variable-in-c-does-it-have-a-value\n自己的补充：Why are global and static variables initialized to their default values https://stackoverflow.com/questions/2091499/why-are-global-and-static-variables-initialized-to-their-default-values/2091505#2091505\nSecurity: leaving memory alone would leak information from other processes or the kernel.\nEfficiency: the values are useless until initialized to something, and it\u0026rsquo;s more efficient to zero them in a block with unrolled loops. The OS can even zero freelist pages when the system is otherwise idle, rather than when some client or user is waiting for the program to start.\nReproducibility: leaving the values alone would make program behavior non-repeatable, making bugs really hard to find.\nElegance: it\u0026rsquo;s cleaner if programs can start from 0 without having to clutter the code with default initializers.\nOne might then wonder why the auto storage class does start as garbage. The answer is two-fold:\nIt doesn\u0026rsquo;t, in a sense. The very first stack frame page at each level (i.e., every new page added to the stack) does receive zero values. The \u0026ldquo;garbage\u0026rdquo;, or \u0026ldquo;uninitialized\u0026rdquo; values that subsequent function instances at the same stack level see are really the previous values left by other method instances of your own program and its library.\nThere might be a quadratic (or whatever) runtime performance penalty associated with initializing auto (function locals) to anything. A function might not use any or all of a large array, say, on any given call, and it could be invoked thousands or millions of times. The initialization of statics and globals, OTOH, only needs to happen once.\n当操作系统将控制权交给它的时候, 计算机把它解释成指令并逐条执行. loader让计算机的生命周期突破程序的边界: 一个程序结束并不意味着计算机停止工作, 计算机将终其一生履行执行程序的使命.\n实现loader 你需要在Nanos-lite中实现loader的功能, 来把用户程序加载到正确的内存位置, 然后执行用户程序. loader()函数在nanos-lite/src/loader.c中定义, 其中的pcb参数目前暂不使用, 可以忽略, 而因为ramdisk中目前只有一个文件, filename参数也可以忽略. 在下一个阶段实现文件系统之后, filename就派上用场了.\n实现后, 在init_proc()中调用naive_uload(NULL, NULL), 它会调用你实现的loader来加载第一个用户程序, 然后跳转到用户程序中执行. 如果你的实现正确, 你会看到执行dummy程序时在Nanos-lite中触发了一个未处理的4号事件. 这说明loader已经成功加载dummy, 并且成功地跳转到dummy中执行了. 关于未处理的事件, 我们会在下文进行说明.\n这里我犯傻了一下。。。实际上读取的都是整数类型，我在那一直打印字符串数据格式就说一直怎么不对- -。。。习惯了char * arr[]直接打印arr而不习惯普通int arr[]需要取数值了233333\u0026hellip;\n直接调用函数可以打印出魔数\n和我们dump出来的结果是一致的：\n把用户程序加载到正确的内存位置,这意味着我们要获取程序开始地址以及程序头表（段头表），具体是什么需要自己RTFM，看了袁妈的视频就会觉得这并不难。\n返回开始地址和读取elf头很简单，段头的处理有一点点操作，主要是注意我们只需要读取LOAD相关段，需要做一个拦截（最好有个数组），然后根据讲义说的：\n然后注意一下我们要写入到virtaddr的位置要用指针（也就是这个地址本身指针）\n此时发现进入死循环（别紧张，其实是对的。。。。可以接下去看讲义，我们发现调用了两次ecall。\nDIFF大坑的解说【memcpy】 (本问题有不少群友都遇到了，提出解决方法的是pony哥）\n在loader实现阶段，你可能会用diff遇到pc漂移diff出错很离谱的神奇状况，甚至在之后也会遇到（但仍然有结果不会陷入奇怪的循环等等）也许你需要考虑这个问题：\n操作系统的运行时环境 程序的运行需要运行时环境的支撑. 而操作系统希望加载并运行程序, 自然有责任来提供运行时环境的功能.\n需要有一个角色来对系统中的资源进行统一的管理: 程序不能擅自使用资源了, 使用的时候需要向资源管理者提出申请. 既然操作系统位于高特权级, 享受着至高无上的权利, 自然地它也需要履行相应的义务: 作为资源管理者管理着系统中的所有资源, 操作系统还需要为用户程序提供相应的服务. 这些服务需要以一种统一的接口来呈现, 用户程序也只能通过这一接口来请求服务.\n这一接口就是系统调用. 这是操作系统从诞生那一刻就被赋予的使命: 我们之前提到GM-NAA I/O的一个主要任务就是加载新程序, 而它的另一个主要功能, 就是为程序提供输入输出的公共接口. GM-NAA I/O所提供的公共接口, 可以认为是系统调用的初原形态.\n问：系统调用的必要性 对于批处理系统来说, 系统调用是必须的吗? 如果直接把AM的API暴露给批处理系统中的程序, 会不会有问题呢?\n答：可能会有各种奇怪的并发资源竞争问题，而且会被恶意程序利用\n系统调用把整个运行时环境分成两部分, 一部分是操作系统内核区, 另一部分是用户区. 那些会访问系统资源的功能会放到内核区中实现, 而用户区则保留一些无需使用系统资源的功能(比如strcpy()), 以及用于请求系统资源相关服务的系统调用接口.\n在这个模型之下, 用户程序只能在用户区安分守己地\u0026quot;计算\u0026quot;, 任何超越纯粹计算能力之外的任务, 都需要通过系统调用向操作系统请求服务. 如果用户程序尝试进行任何非法操作, CPU就会向操作系统抛出一个异常信号, 让非法操作的指令执行\u0026quot;失败\u0026quot;, 并交由操作系统进行处理. 对, 这就是之前介绍的硬件保护机制, 操作系统需要借助这一天然屏障来阻挡程序的恶意行为.\n虽然操作系统需要为用户程序服务, 但这并不意味着操作系统需要把所有信息都暴露给用户程序. 有些信息是用户进程没有必要知道的, 也永远不应该知道, 例如一些与内存管理相关的数据结构. 如果一个恶意程序获得了这些信息, 可能会为恶意攻击提供了信息基础. 因此, 通常不存在一个系统调用来获取这些操作系统的私有数据.\n系统调用 系统调用的过程：用户程序通过一种方法描述自己的需求, 然后告诉操作系统。\n\u0026ldquo;告诉操作系统\u0026rdquo;, 这是通过自陷指令来实现的。\n在GNU/Linux中, 用户程序通过自陷指令来触发系统调用, Nanos-lite也沿用这个约定. CTE中的yield()也是通过自陷指令来实现,\n对用户程序来说, 用来向操作系统描述需求的最方便手段就是使用通用寄存器了, 因为执行自陷指令之后, 执行流就会马上切换到事先设置好的入口, 通用寄存器也会作为上下文的一部分被保存起来. 系统调用处理函数只需要从上下文中获取必要的信息, 就能知道用户程序发出的服务请求是什么了.\n目前dummy已经通过_syscall_()直接触发系统调用, 你需要让Nanos-lite识别出系统调用事件EVENT_SYSCALL.\n在abstract-machine/am/include/arch/$ISA-nemu.h中实现正确的GPR?宏, 让它们从上下文c中获得正确的系统调用参数寄存器.\n添加SYS_yield系统调用.\n设置系统调用的返回值.\n处理系统调用的最后一件事就是设置系统调用的返回值. 对于不同的ISA, 系统调用的返回值存放在不同的寄存器中, 宏GPRx用于实现这一抽象, 所以我们通过GPRx来进行设置系统调用返回值即可.\n经过CTE, 执行流会从do_syscall()一路返回到用户程序的_syscall_()函数中. 代码最后会从相应寄存器中取出系统调用的返回值, 并返回给_syscall_()的调用者,\n重新运行dummy程序, 如果你的实现正确, 你会看到dummy程序又触发了一个号码为0的系统调用. 查看nanos-lite/src/syscall.h, 你会发现它是一个SYS_exit系统调用. 这说明之前的SYS_yield已经成功返回, 触发SYS_exit是因为dummy已经执行完毕, 准备退出了.\n你需要实现SYS_exit系统调用, 它会接收一个退出状态的参数. 为了方便测试, 我们目前先直接使用这个参数调用halt(). 实现成功后, 再次运行dummy程序, 你会看到HIT GOOD TRAP的信息.\n【你需要阅读上面提到的所有函数，这样就能完成所需内容。】\n问：RISC-V系统调用号的传递 如果你选择的是RISC-V, 你会发现它并不是通过a0来传递系统调用号. 事实上, 我们参考了RISC-V Linux的系统调用参数传递的约定: 即在RISC-V Linux上也是通过这个寄存器来传递系统调用号的. 你觉得RISC-V Linux为什么没有使用a0来传递系统调用号呢?\n答：\n经过一顿操作猛如虎补充好了对应内容。（认真看讲义即可）\n操作系统之上的TRM 我们需要构造os的运行时环境\n用户程序还可以做什么呢? 最基本的, 为了满足程序的基本计算能力, 需要有这些条件:\n机器提供基本的运算指令 （机器提供了）\n能输出字符 有堆区可以动态申请内存\n可以结束运行 （sys_exit）\n为了向用户程序提供输出字符和内存动态申请的功能, 我们需要实现更多的系统调用.\nwrite实现 简单实现一下write： 发现打印不全\n其实这是后面提到的：\n堆区管理 调整堆区大小是通过sbrk()库函数来实现的,用于将用户程序的program break增长increment字节, 其中increment可为负数.\nmalloc()被第一次调用的时候, 会通过sbrk(0)来查询用户程序当前program break的位置, 之后就可以通过后续的sbrk()调用来动态调整用户程序program break的位置了\n在Navy的Newlib中, sbrk()最终会调用_sbrk(), 它在navy-apps/libs/libos/src/syscall.c中定义. 框架代码让_sbrk()总是返回-1, 表示堆区调整失败, 事实上,** 用户程序在第一次调用**printf()的时候会尝试通过malloc()申请一片缓冲区, 来存放格式化的内容. 若申请失败, 就会逐个字符进行输出.\n我们还需要提供一个用于设置堆区大小的系统调用. 在GNU/Linux中, 这个系统调用是SYS_brk, 它接收一个参数addr, 用于指示新的program break的位置. _sbrk()通过记录的方式来对用户程序的program break位置进行管理, 其工作方式如下:\nprogram break一开始的位置位于_end\n被调用时, 根据记录的program break位置和参数increment, 计算出新program break\n通过SYS_brk系统调用来让操作系统设置新program break\n若SYS_brk系统调用成功, 该系统调用会返回0, 此时更新之前记录的program break的位置, 并将旧program break的位置作为_sbrk()的返回值返回\n若该系统调用失败, _sbrk()会返回-1\n上述代码是在用户层的库函数中实现的, 我们还需要在Nanos-lite中实现SYS_brk的功能. 由于目前Nanos-lite还是一个单任务操作系统, 空闲的内存都可以让用户程序自由使用, 因此我们只需要让SYS_brk系统调用总是返回0即可, 表示堆区大小的调整总是成功. 在PA4中, 我们会对这一系统调用进行修改, 实现真正的内存分配.\n根据上述内容在Nanos-lite中实现SYS_brk系统调用, 然后在用户层实现_sbrk(). 你可以通过man 2 sbrk来查阅libc中brk()和sbrk()的行为, 另外通过man 3 end来查阅如何使用_end符号.\n需要注意的是, 调试的时候不要在_sbrk()中通过printf()进行输出, 这是因为printf()还是会尝试通过malloc()来申请缓冲区, 最终会再次调用_sbrk(), 造成死递归. 你可以通过sprintf()先把调试信息输出到一个字符串缓冲区中, 然后通过_write()进行输出.\n这里按照一步步操作就好，其实就是pa2的malloc的稍微改写。至于end怎么拿看man就懂了。\n（这里其实有个坑，要注意堆分配的作用域。不然多次堆分配就没有意义了）\n这里其实我不太理解一个问题，那就是“malloc的系统调用失败”，怎么算失败呢？访问到不可访问的内存应该会直接panic，或者出界也会直接panic。也许应该有机制会在pa自己panic的情况前拦截（比如再次提前检查地址是否出界）\n然后我发现了一个乱码问题（检查了很多次应该不是堆的问题）\n后面突然想到是不是缓冲区的问题（没有遇到\\n就暂停），修改了write逻辑后恢复正常：\n如果通过系统调用千辛万苦地陷入操作系统只是为了输出区区一个字符, 那就太不划算了. 于是有了批处理(batching)的技术: 将一些简单的任务累积起来, 然后再一次性进行处理. 缓冲区是批处理技术的核心, libc中的fread()和fwrite()正是通过缓冲区来将数据累积起来, 然后再通过一次系统调用进行处理. 例如通过一个1024字节的缓冲区, 就可以通过一次系统调用直接输出1024个字符, 而不需要通过1024次系统调用来逐个字符地输出. 显然, 后者的开销比前者大得多.\n有兴趣的同学可以在GNU/Linux上编写相应的程序, 来粗略测试一下一次write()系统调用的开销, 然后和这篇文章对比一下\nprintf()打印的字符不一定会马上通过write()系统调用输出, 但遇到\\n时可以强行将缓冲区中的内容进行输出. 有兴趣的同学可以阅读navy-apps/libs/libc/src/stdio/wbuf.c, 这个文件实现了缓冲区的功能.\n必答题 - hello程序是什么, 它从而何来, 要到哪里去 到此为止, PA中的所有组件已经全部亮相, 整个计算机系统也开始趋于完整. 你也已经在这个自己创造的计算机系统上跑起了hello这个第一个还说得过去的用户程序 (dummy是给大家热身用的, 不算), 好消息是, 我们已经距离运行仙剑奇侠传不远了(下一个阶段就是啦).\n不过按照PA的传统, 光是跑起来还是不够的, 你还要明白它究竟怎么跑起来才行. 于是来回答这道必答题吧:\n我们知道navy-apps/tests/hello/hello.c只是一个C源文件, 它会被编译链接成一个ELF文件. 那么, hello程序一开始在哪里?\n它是怎么出现内存中的? 为什么会出现在目前的内存位置? 它的第一条指令在哪里? 究竟是怎么执行到它的第一条指令的?\nhello程序在不断地打印字符串, 每一个字符又是经历了什么才会最终出现在终端上?\n","date":"2022-08-26T08:50:40+08:00","permalink":"https://sanbuphy.github.io/p/nju%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C-pa3%E7%AC%94%E8%AE%B0%E4%B8%80/","title":"NJU计算机课程基础实验 PA3笔记（一）"},{"content":"一天看到有个群友问了这样一个问题：\n为什么这个类没有看到继承于谁，但是在里面可以直接super？\n在这个栏目中我们先不谈有关__setattr__魔术方法的具体作用（其实就是反射）和应用场景，就单纯谈为什么在这里可以凭空super。\n举个简单的例子：\nclass Person: def __setattr__(self,name,value): print(f\u0026#34;setting attribute [{name}] to {value}\u0026#34;) super().__setattr__(name,value) 看似没有集成任何类，为什么在这里我们直接可以super呢？其实相当于重写了Person类的父类的__setattr__方法，person类的父类是什么呢？这里我们需要了解元类的概念：（转载自b站阿岳同学）\n实际上我们创建的类person本身就是object的派生类，所以当我们在person里直接super的时候，事实上使用的是object的魔术方法。\n我们可以做个实验：\n这里我们使用__base__查看父类能够看到class\u0026rsquo;object\u0026rsquo;，那么到底他是个什么呢？\n在builtins.pyi中我们能一探究竟：\n所以一切都很显然了，我们能够直接super原因是我们创造的class本身也是一种派生。\n“一生二，二生三，三生万物“ —— 如果老子是个程序员，应该很喜欢python\n","date":"2022-08-13T09:03:03+08:00","permalink":"https://sanbuphy.github.io/p/python%E8%BF%9B%E9%98%B6-%E6%9C%89%E5%85%B3%E5%85%83%E7%B1%BB%E7%9A%84%E6%B4%BE%E7%94%9F/","title":"python进阶 有关元类的派生"},{"content":"基础设施(2)（还未全完成 trace系列暂时待填坑。。。。\nNEMU是一个用来执行其它程序的程序. 在可计算理论中, 这种程序有一个专门的名词, 叫通用程序(Universal Program),\nNEMU和各种模拟器只不过是通用程序的实例化, 我们也可以毫不夸张地说, 计算机就是一个通用程序的实体化. 通用程序的存在性为计算机的出现奠定了理论基础, 是可计算理论中一个极其重要的结论,\nmemset通过测试\n推荐阅读 计算的极限： https://zhuanlan.zhihu.com/p/270155475\n阅读相关Makefile, 尝试理解abstract-machine是如何生成native的可执行文件的. 待补充\n奇怪的错误码 为什么错误码是1呢? 你知道make程序是如何得到这个错误码的吗?\n别高兴太早了, 框架代码编译到native的时候默认链接到glibc, 我们需要把这些库函数的调用链接到我们编写的klib来进行测试. 我们可以通过在abstract-machine/klib/include/klib.h 中通过定义宏__NATIVE_USE_KLIB__来把库函数链接到klib. 如果不定义这个宏, 库函数将会链接到glibc, 可以作为正确的参考实现来进行对比.\n待补充\n这是如何实现的? 为什么定义宏__NATIVE_USE_KLIB__之后就可以把native上的这些库函数链接到klib? 这具体是如何发生的? 尝试根据你在课堂上学习的链接相关的知识解释这一现象.\n待补充\n输入输出 设备与CPU 要向设备发送一些有意义的数字信号, 设备就会按照这些信号的含义来工作. 让一些信号来指导设备如何工作, 这不就像\u0026quot;程序的指令指导CPU如何工作\u0026quot;一样吗? 恰恰就是这样! 设备也有自己的状态寄存器(相当于CPU的寄存器), 也有自己的功能部件(相当于CPU的运算器). 当然不同的设备有不同的功能部件, 例如键盘有一个把按键的模拟信号转换成扫描码的部件, 而VGA则有一个把像素颜色信息转换成显示器模拟信号的部件. 控制设备工作的信号称为\u0026quot;命令字\u0026quot;, 可以理解成【设备的指令】, 设备的工作就是负责接收命令字, 并进行译码和执行\u0026hellip; 你已经知道CPU的工作方式, 这一切对你来说都太熟悉了.\n所谓的访问设备, 说白了就是从设备获取数据(输入), 比如从键盘控制器获取按键扫描码, 或者是向设备发送数据(输出), 比如向显存写入图像的颜色信息. 但是, 如果万一用户没有敲键盘, 或者是用户想调整屏幕的分辨率, 怎么办呢? 这说明, 除了纯粹的数据读写之外, 我们还需要对设备进行控制: 比如需要获取键盘控制器的状态, 查看当前是否有按键被按下; 或者是需要有方式可以查询或设置VGA控制器的分辨率. 所以, 在程序看来,访问设备 = 读出数据 + 写入数据 + 控制状态.\n既然设备也有寄存器, 一种最简单的方法就是把设备的寄存器作为接口, 让CPU来访问这些寄存器. CPU要如何访问设备寄存器呢? 我们先来回顾一下CPU是如何访问CPU自己的寄存器的: 首先给这些寄存器编个号, 比如eax是0, ecx是1\u0026hellip; 然后在指令中引用这些编号, 电路上会有相应的选择器, 来选择相应的寄存器并进行读写. 对设备寄存器的访问也是类似的: 我们也可以给设备中允许CPU访问的寄存器逐一编号, 然后通过指令来引用这些编号. 设备中可能会有一些私有寄存器, 它们是由设备自己维护的, 它们没有这样的编号, CPU不能直接访问它们.\n这些编号也称为设备的地址. 常用的编址方式有两种：端口I/O、內存映射I/O\n端口I/O 端口映射I/O(port-mapped I/O), CPU使用专门的I/O指令对设备进行访问, 并把设备的地址称作端口号. 有了端口号以后, 在I/O指令中给出端口号, 就知道要访问哪一个设备寄存器了. 市场上的计算机绝大多数都是IBM PC兼容机, IBM PC兼容机对常见设备端口号的分配有专门的规定.\nx86提供了in和out指令用于访问设备, 其中in指令用于将设备寄存器中的数据传输到CPU寄存器中, out指令用于将CPU寄存器中的数据传送到设备寄存器中.\nmovl $0x41, %al\nmovl $0x3f8, %edx\noutb %al, (%dx)\n上述代码把数据0x41传送到0x3f8号端口所对应的设备寄存器中. CPU执行上述代码后, 会将0x41这个数据传送到串口的一个寄存器中, 串口接收之后, 发现是要输出一个字符A; 但对CPU来说, 它并不关心设备会怎么处理0x41这个数据, 只会老老实实地把0x41传送到0x3f8号端口. 事实上, 设备的API及其行为都会在相应的文档里面有清晰的定义, 在PA中我们无需了解这些细节, 只需要知道, 驱动开发者可以通过RTFM, 来编写相应程序来访问设备即可.\nAPI, 行为, RTFM\u0026hellip; 没错, 我们又再次看到了计算机系统设计的一个例子: 设备向CPU暴露设备寄存器的接口, 把设备内部的复杂行为(甚至一些模拟电路的特性)进行抽象, CPU只需要使用这一接口访问设备, 就可以实现期望的功能. 计算机系统处处蕴含抽象的思想, 只要理解其中的原理, 再加上RTFM的技能, 你就能掌握计算机系统的全部!\n內存映射I/O 端口映射I/O把端口号作为I/O指令的一部分, 这种方法很简单, 但同时也是它最大的缺点. 指令集为了兼容已经开发的程序, 是只能添加但不能修改的.这意味着, 端口映射I/O所能访问的I/O地址空间的大小, 在设计I/O指令的那一刻就已经决定下来了. 所谓I/O地址空间, 其实就是所有能访问的设备的地址的集合. 随着设备越来越多, 功能也越来越复杂, I/O地址空间有限的端口映射I/O已经逐渐不能满足需求了. 有的设备需要让CPU访问一段较大的连续存储空间, 如VGA的显存, 24色加上Alpha通道的1024x768分辨率的显存就需要3MB的编址范围. 于是内存映射I/O(memory-mapped I/O, MMIO)应运而生.\n编址方式将一部分物理内存的访问\u0026quot;重定向\u0026quot;到I/O地址空间中, CPU尝试访问这部分物理内存的时候, 实际上最终是访问了相应的I/O设备,\n现代计算机都已经是64位计算机, 物理地址线都有48根,\n（注意64位并不需要2的64次方，而是48就够了，因为过大空间导致了资源浪费。32位的时候寻址是32次方。每个地址总线可以对两个存储单元寻址，确定两种状态（0或1）1GB是2的30次方Byte，1TB是2的40次方B，再乘上256即2的8次方即是）\n这意味着物理地址空间有256TB这么大, 从里面划出3MB的地址空间给显存, 根本就是不痛不痒. 正因为如此, 内存映射I/O成为了现代计算机主流的I/O编址方式: RISC架构只提供内存映射I/O的编址方式, 而PCI-e, 网卡, x86的APIC等主流设备, 都支持通过内存映射I/O来访问.\n作为RISC架构, mips32和riscv32都是采用内存映射I/O的编址方式. 对x86来说, 内存映射I/O的一个例子是NEMU中的物理地址区间[0xa1000000, 0xa1800000). 这段物理地址区间被映射到VGA内部的显存, 读写这段物理地址区间就相当于对读写VGA显存的数据. 例如\nmemset((void *)0xa1000000, 0, SCR_SIZE); 会将显存中一个屏幕大小的数据清零, 即往整个屏幕写入黑色像素, 作用相当于清屏. 可以看到, 内存映射I/O的编程模型和普通的编程完全一样: 程序员可以直接把I/O设备当做内存来访问. 这一特性也是深受驱动开发者的喜爱.\n状态机视角下的输入输出 我们可以把设备分成两部分, 一部分是数字电路. 我们刚才粗略地介绍了一些设备控制器的功能, 例如我们CPU可以从键盘控制器中读出按键信息. 既然是数字电路, 我们就可以把其中的时序逻辑电路看成是设备数字电路部分的状态D.\n但D比较特殊, 计算机只能通过端口I/O指令或者内存映射I/O的访存指令来访问和修改.​\n有意思的是设备的另一部分: 模拟电路, 它也可以改变D. 例如键盘通过检查按键位置的电容变化来判断是否有按键被按下, 若有, 则会将按键信息写入到键盘控制器的寄存器中. 而按键位置的电容是否发生变化, 又是由物理世界中的用户是否按下按键决定的. 所以我们会说, 设备是连接计算机和物理世界的桥梁.\n要对设备的状态和行为进行建模是一件很困难的事情, 除了设备本身的行为五花八门之外, 设备的状态还时时刻刻受到物理世界的影响. 于是, 我们在对状态机模型的行为进行扩展的时候, 并不考虑将D加入到S中, 而是仅仅对输入输出相关指令的行为进行建模: ​\n通过内存进行数据交互的输入输出 我们知道S = \u0026lt;R, M\u0026gt;, 上文介绍的端口I/O和内存映射I/O都是通过寄存器R来进行数据交互的. 很自然地, 我们可以考虑, 有没有通过内存​来进行数据交互的输入输出方式呢?\n其实是有的, 这种方式叫DMA. 为了提高性能, 一些复杂的设备一般都会带有DMA的功能. 不过在NEMU中的设备都比较简单, 关于DMA的细节我们就不展开介绍了.\nNEMU中的输入输出 终于进入紧张刺激的正式话题！\nNEMU的框架代码已经在nemu/src/device/目录下提供了设备相关的代码,\n映射和I/O方式 这部分蛮重要的，多读读原文把，可以在之后回头读。\n设备 NEMU使用SDL库来实现设备的模拟, nemu/src/device/device.c含有和SDL库相关的代码. init_device()函数主要进行以下工作:\n调用init_map()进行初始化. cpu_exec()在执行每条指令之后就会调用device_update()函数, 这个函数首先会检查距离上次设备更新是否已经超过一定时间, 若是, 则会尝试刷新屏幕, 并进一步检查是否有按键按下/释放, 以及是否点击了窗口的​按钮; 否则则直接返回, 避免检查过于频繁, 因为上述事件发生的频率是很低的.\n将输入输出抽象成IOE 设备访问的具体实现是架构相关的, 比如NEMU的VGA显存位于物理地址区间[0xa1000000, 0xa1080000), 但对native的程序来说, 这是一个不可访问的非法区间, 因此native程序需要通过别的方式来实现类似的功能. 自然地, 设备访问这一架构相关的功能, 应该归入AM中. 与TRM不同, 设备访问是为计算机提供输入输出的功能, 因此我们把它们划入一类新的API, 名字叫IOE(I/O Extension).\n访问设备其实想做什么: 访问设备 = 读出数据 + 写入数据 + 控制状态. 进一步的, 控制状态本质上也是读/写设备寄存器的操作, 所以访问设备 = 读/写操作.\nbool ioe_init();\nvoid ioe_read(int reg, void *buf);\nvoid ioe_write(int reg, void *buf);\n第一个API用于进行IOE相关的初始化操作. 后两个API分别用于从编号为reg的寄存器中读出内容到缓冲区buf中, 以及往编号为reg寄存器中写入缓冲区buf中的内容.\n【这里的reg寄存器并不是上文讨论的设备寄存器, 因为设备寄存器的编号是架构相关的.】\nabstract-machine/am/include/amdev.h中定义了常见设备的\u0026quot;抽象寄存器\u0026quot;编号和相应的结构. 这些定义是架构无关的, 每个架构在实现各自的IOE API时, 都需要遵循这些定义(约定). NEMU作为一个平台, 设备的行为是与ISA无关的, 只需要在abstract-machine/am/src/platform/nemu/ioe/目录下实现一份IOE, 来供NEMU平台的架构共享. 其中, abstract-machine/am/src/platform/nemu/ioe/ioe.c中实现了上述的三个IOE API, ioe_read()和ioe_write()都是通过抽象寄存器的编号索引到一个处理函数, 然后调用它. 处理函数的具体功能和寄存器编号相关, 下面我们来逐一介绍NEMU中每个设备的功能.\n一些重要的文件、函数记录 代码框架可参考：https://ysyx.oscc.cc/forum/topic/16/pa2-3-nemu-am-am-kernels共同构建的虚拟世界概念图\n随着代码复杂度越来越高，对框架的熟悉度要求指数上涨，必须开始记录每个框架的功能及其使用方式：\n基础文件 指令集相关文件：\n各类指令RTL调用函数实现部分：/home/physico/ics2021/nemu/src/isa/riscv32/instr/ *.h\n译码函数部分：/home/physico/ics2021/nemu/src/isa/riscv32/instr/decode.c\n函数名-宏展开需要部分：/home/physico/ics2021/nemu/src/isa/riscv32/include/isa-all-instr.h（旁边的isa-exec可以包括1提到的）\nISADecodeInfo：/home/physico/ics2021/nemu/src/isa/riscv32/include/isa-def.h\nRTL实现相关：\n/home/physico/ics2021/nemu/src/engine/interpreter/rtl-basic.h （def_rtl_compute_reg_imm）\n/home/physico/ics2021/nemu/src/engine/interpreter/c_op.h（c_add(a, b) ((a) + (b)) 以及 interpret_relop类似RELOP_NE）\n调试测试用指令与文件（我以自己的路径为准） IOE（包括时间等）：\n地址：/home/physico/ics2021/am-kernels/tests/am-tests\n测试方式：make ARCH=riscv32-nemu run mainargs=t （其他测试方式自行读代码）\nbenchmark测试：\n地址：/home/physico/ics2021/am-kernels/benchmarks/microbench\n测试方式：make ARCH=riscv32-nemu run （其他benchmark同样方法可测）\n马里奥测试：\n地址：home/physico/ics2021/fceux-am\n测试方式： make ARCH=riscv32-nemu run mainargs=mario\n设备相关文件： 时钟：\nAM的相关实现：\n/home/physico/ics2021/abstract-machine/am/src/platform/nemu/ioe/timer.c （需要实现） native的相关实现\n/home/physico/ics2021/abstract-machine/am/src/native/ioe/timer.c nemu的相关实现：\n/home/physico/ics2021/nemu/src/device/timer.c\n/home/physico/ics2021/nemu/src/utils/timer.c\n串口 nemu/src/device/serial.c模拟了串口的功能. 其大部分功能也被简化, 只保留了数据寄存器. 串口初始化时会分别注册0x3F8处长度为8个字节的端口, 以及0xa00003F8处长度为8字节的MMIO空间, 它们都会映射到串口的数据寄存器. 由于NEMU串行模拟计算机系统的工作, 串口的状态寄存器可以一直处于空闲状态; 每当CPU往数据寄存器中写入数据时, 串口会将数据传送到主机的标准错误流进行输出.\nabstract-machine/am/src/platform/nemu/trm.c中的putch()会将字符输出到串口.\n可以配合vsprintf做成Printf。\n理解mainargs 请你通过RTFSC理解这个参数是如何从make命令中传递到hello程序中的, $ISA-nemu和native采用了不同的传递方法, 都值得你去了解一下.\n答：\nISA-NEMU通过ics2021/abstract-machine/scripts/platform/nemu.mk中的宏定义：-D\nCFLAGS += -DMAINARGS=\\\u0026quot;$(mainargs)\\\u0026ldquo;然后就在main（mainargs）\n时钟【埋了大坑】 有了时钟, 程序才可以提供时间相关的体验, 例如游戏的帧率, 程序的快慢等. nemu/src/device/timer.c模拟了i8253计时器的功能. 计时器的大部分功能都被简化, 只保留了\u0026quot;发起时钟中断\u0026quot;的功能(目前我们不会用到). 同时添加了一个自定义的时钟. i8253计时器初始化时会分别注册0x48处长度为8个字节的端口, 以及0xa0000048处长度为8字节的MMIO空间, 它们都会映射到RTC寄存器. CPU可以访问这两个寄存器来获得当前时间.\nabstract-machine/am/include/amdev.h中为时钟的功能定义了两个抽象寄存器:\nAM_TIMER_RTC, AM实时时钟(RTC, Real Time Clock), 可读出当前的年月日时分秒. PA中暂不使用.\nAM_TIMER_UPTIME, AM系统启动时间, 可读出系统启动后的微秒数.\n实现IOE\n在abstract-machine/am/src/platform/nemu/ioe/timer.c中实现AM_TIMER_UPTIME的功能. 在abstract-machine/am/src/platform/nemu/include/nemu.h和 abstract-machine/am/src/$ISA/$ISA.h中有一些输入输出相关的代码供你使用.\n实现后, 在$ISA-nemu中运行am-kernel/tests/am-tests中的real-time clock test测试. 如果你的实现正确, 你将会看到程序每隔1秒往终端输出一行信息. 由于我们没有实现AM_TIMER_RTC, 测试总是输出1900年0月0日0时0分0秒, 这属于正常行为, 可以忽略.\nnative的IOE是基于SDL库实现的, 它们假设常用库函数的行为会符合glibc标准, 但我们自己实现的klib通常不能满足这一要求. 因此__NATIVE_USE_KLIB__仅供测试klib实现的时候使用, 我们不要求在定义__NATIVE_USE_KLIB__的情况下正确运行所有程序.\n这里我卡了一段时间（主要是跑分过高甚至有些跑不了。），我参考了一生一芯论坛某个大佬的思路：\nhttps://ysyx.oscc.cc/forum/topic/56/pa2-3实现时钟为例的一些rtsc思路\n解决时钟问题的钥匙——理解更新过程 我们需要思考，内存映射的逻辑是什么，为什么我们通过学习类似abstract-machine/am/src/platform/nemu/ioe/timer.c 的方法能够读出数据？或者使用文档里让我们看文件中的读写方式能够读出时间数据？（具体可以看上面那个大佬的思路）关键在于——时间是被更新到地址上的，那么什么造成了地址对应数据的更新？讲义给出了答案，让我们反复阅读映射和IO方式： 框架代码为映射定义了一个结构体类型IOMap(在nemu/include/device/map.h中定义), 包括名字, 映射的起始地址和结束地址, 映射的目标空间, 以及一个回调函数.\nnemu/src/device/io/map.c实现了映射的管理, 包括I/O空间的分配及其映射, 还有映射的访问接口.\n其中map_read()和map_write()用于将地址addr映射到​所指示的目标空间, 并进行访问. 访问时, 可能会触发相应的回调函数, 对设备和目标空间的状态进行更新.\nnemu/src/device/io/port-io.c是对端口映射I/O的模拟. add_pio_map()函数用于为设备的初始化注册一个端口映射I/O的映射关系. pio_read()和pio_write()是面向CPU的端口I/O读写接口, 它们最终会调用map_read()和map_write(), 对通过​注册的I/O空间进行访问.\n这时候我们就会想到，这个对设备和目标空间状态更新的函数，对时钟来说，是什么呢？\n注意到———— nemu/src/device/timer.c模拟了i8253计时器的功能\n此时进入后会发现熟悉的add_pio_map，还有一个rtc_io_handler这里出现了gettime! 感觉是我们想要的答案，但此时会发现一个offset，那么这个offset到底是什么呢，让我们继续打开add_pio_map，继续一路寻找用到callback的地方会发现回到了map，其中的map_read的write告诉了我们原来在这里传入callback,其中offset也就不言而喻了。\n得知offset = addr - map-\u0026gt;low后，我们再倒回去看某个函数就显得可疑了， addr 可以就是 map-\u0026gt;low，也可以是low+4。那么哪个才是对的呢？让我们再复习这句话：\n其中map_read()和map_write()用于将地址addr映射到​所指示的目标空间, 并进行访问. 访问时, 可能会触发相应的回调函数, 对设备和目标空间的状态进行更新.\n这时候问题就变成addr到底是等于什么的时候更新才是对的呢？我们怎么访问地址更新数据才是正确的？\n这个访问会对我们读取时钟数据有什么影响？我们读取地址上的时钟数据的时候是怎么做的？\n在反复阅读一下前面大佬分享的RTFC的过程，相信你能得到答案。\n键盘 这部分只要弄懂了时钟，非常简单。\nVGA 现代的显示器一般都支持24位的颜色(R, G, B各占8个bit, 共有2^8*2^8*2^8约1600万种颜色)\n为了让屏幕显示不同的颜色成为可能, 在8位颜色深度时会使用调色板的概念. 调色板是一个颜色信息的数组, 每一个元素占4个字节, 分别代表R(red), G(green), B(blue), A(alpha)的值\n一个像素存储的就不再是颜色的信息, 而是一个调色板的索引\n要得到一个像素的颜色信息, 就要把它的值当作下标, 在调色板这个数组中做下标运算, 取出相应的颜色信息. 因此, 只要使用不同的调色板, 就可以在不同的时刻使用不同的256种颜色了.\nQ：在一些90年代的游戏中(比如仙剑奇侠传), 很多渐出渐入效果都是通过调色板实现的, 聪明的你知道其中的玄机吗?\nA:通过线性改变索引？\n在NEMU中, GPU仅仅保留绘制像素的基本功能.\nabstract-machine/am/include/amdev.h中为GPU定义了五个抽象寄存器, 在NEMU中只会用到其中的两个:\nAM_GPU_CONFIG, AM显示控制器信息, 可读出屏幕大小信息width和height. 另外AM假设系统在运行过程中, 屏幕大小不会发生变化.\nAM_GPU_FBDRAW, AM帧缓冲控制器, 可写入绘图信息, 向屏幕(x, y)坐标处绘制w*h的矩形图像. 图像像素按行优先方式存储在pixels中, 每个像素用32位整数以00RRGGBB的方式描述颜色. 若sync为true, 则马上将帧缓冲中的内容同步到屏幕上.\nVGA设备还有两个寄存器: 屏幕大小寄存器和同步寄存器.\n屏幕大小寄存器的硬件(NEMU)功能已经实现, 但软件(AM)还没有去使用它;\n同步寄存器软件(AM)已经实现了同步屏幕的功能, 但硬件(NEMU)尚未添加相应的支持.\n这里我卡的最久的是1、如何理解隐藏的同步信息 2、如何绘制像素。\n针对第一个问题， 其实关键是不理解抽象寄存器是如何与实际硬件寄存器联系起来的。经过RTFSC我们能知道形如“_port_base”（在内存读取中参数为space）才是真正的寄存器位置，而且也在地址空间中开辟了对应的内存。(当然你不仅可以通过开辟的空间去猜测只有两个寄存器，因为你会找到一个newplace（8）；同时也可以找到SYNC_ADDR的地址，那里是同步的地址，再配合VGA本体映射的地址猜猜看即可；或者你也可以参考有一个叫做pixel *render的地方，那里也可以参考）\n（同时这里我也还不知道指针也可以直接取下标运算，我一直记着指针不等同数组，直到查阅知道了其实编译器中这是一个东西：\n除了优先级不同之外，下标表达式 array[ value ] 和间接访问表达式 *（array + ( value )） 是一样的。因此，下标不仅可以用作数组名，也可以用于指针表达式中。不过这样一来，编译器就很难检查下标的有效性。（斟酌）（意思是如果用指针加下标的方式来表达数组的元素，编译器无法检测到是否越界！）\nhttps://blog.51cto.com/u_15338162/5206658\nhttps://zhuanlan.zhihu.com/p/399327901\n让我们回来继续思考问题，抽象寄存器的编号又是如何与实际寄存器的编号（比如5、6、7和具体的[0] [1]）联系起来的呢？\n所以，如果实现了AM的同步寄存器但没有硬件支持，说明硬件部分实际上缺少了一个对同步寄存器的读取，那么哪一个才是硬件同步寄存器呢？他在哪呢？这就需要RTFSC了。\n针对第二个问题， 实际上pa2021的框架比2020的难，因为2021的native没有办法参考，而2020的native代码给出了绘制实现。这里我是参考了2020的native才做出来的。实际上要理解这一句话：\n向屏幕(x, y)坐标处绘制w*h的矩形图像. 图像像素按行优先方式存储在pixels中\n这个x y w h的含义，实际上是从绘制理解的。我们图像的绘制从左上角开始，也就是多维数组展平成一维数据一直画下去（你可以更改fb(i)=[i]的值和for范围查看），而一个好的理解方式是把x,y当做开始绘制的点。也就是说如果你要绘制一个小矩形框，本质是一个点“拖出来的”，因为本质是从一维数组从左到右画。那么我们知道了此时的x,y是基础偏移坐标（也就是绘制小矩形框的基础坐标），而我们绘制需要for循环表达的是i和j坐标也就是小矩形框的坐标，其中pixels是我们将要画的小矩形的像素信息。\n我们的目的是把小矩形的像素信息从行开始遍历一个个i和j,再通过fb绘制到大矩形框（gpu内存映射地址）上，所以你应该思考这个映射是怎么做的，如何表达“从某一行开始，一列列的画过去？”，具体的坐标信息该如何转换？这就是你应该思考的了。实在不行，你可以参考2020naitive有关gpu的相关实现。\n实现完后你就可以跑马里奥等程序了，我的fps大概是25左右，好好享受自己的作品！\n声卡部分 暂时坑了\n【做完PA2应该熟悉的代码】（待完成 NEMU中除了fixdep, kconfig, 以及没有选择的ISA之外的全部已有代码(包括Makefile)\nabstract-machine/am/下与$ISA-nemu相关的, 除去CTE和VME之外的代码\nabstract-machine/klib/中的所有代码\nabstract-machine/Makefile和abstract-machine/scripts/中的所有代码\nam-kernels/tests/cpu-tests/中的所有代码\nam-kernels/tests/am-tests/中运行过的测试代码\nam-kernels/benchmarks/microbench/bench.c\nam-kernels/kernels/中的hello, slider和typing-game的所有代码\n如果你发现自己不能理解这些代码的行为, 就赶紧看看吧. 多看一个文件, bug少调几天, 到了PA3你就会领教到了. （这句话我还是非常相信的，所以宁愿慢一点一个个去看，慢就是快。）\n【你应该知道并理解的知识】（待完成 程序是个状态机 理解YEMU的执行过程, 具体请参考这里.\nRTFSC 请整理一条指令在NEMU中的执行过程, 具体请参考这里.\n程序如何运行 理解打字小游戏如何运行, 具体请参考这里.\n编译与链接 在nemu/src/engine/interpreter/rtl-basic.h中, 你会看到由static inline开头定义的各种RTL指令函数. 选择其中一个函数, 分别尝试去掉static, 去掉inline或去掉两者, 然后重新进行编译, 你可能会看到发生错误. 请分别解释为什么这些错误会发生/不发生? 你有办法证明你的想法吗?\n编译与链接\n在nemu/include/common.h中添加一行volatile static int dummy; 然后重新编译NEMU. 请问重新编译后的NEMU含有多少个dummy变量的实体? 你是如何得到这个结果的?\n添加上题中的代码后, 再在nemu/include/debug.h中添加一行volatile static int dummy; 然后重新编译NEMU. 请问此时的NEMU含有多少个dummy变量的实体? 与上题中dummy变量实体数目进行比较, 并解释本题的结果.\n修改添加的代码, 为两处dummy变量进行初始化:volatile static int dummy = 0; 然后重新编译NEMU. 你发现了什么问题? 为什么之前没有出现这样的问题? (回答完本题后可以删除添加的代码.)\n了解Makefile 请描述你在am-kernels/kernels/hello/目录下敲入make ARCH=$ISA-nemu 后, make程序如何组织.c和.h文件, 最终生成可执行文件am-kernels/kernels/hello/build/hello-$ISA-nemu.elf. (这个问题包括两个方面:Makefile的工作方式和编译链接的过程.) 关于Makefile工作方式的提示:\nMakefile中使用了变量, 包含文件等特性\nMakefile运用并重写了一些implicit rules\n在man make中搜索-n选项, 也许会对你有帮助\nReference https://nju-projectn.github.io/ics-pa-gitbook/ics2021\n网络上搜到的一些细节，但由于学术诚信不予放出。\n","date":"2022-08-13T08:50:40+08:00","permalink":"https://sanbuphy.github.io/p/nju%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C-pa2%E7%AC%94%E8%AE%B0%E4%BA%8C/","title":"NJU计算机课程基础实验 PA2笔记（二）"},{"content":"PA2.1 冯诺依曼计算机 写在前面：\n首先要感谢jyy群一直帮助我的pony小哥、17号小哥、YSYX论坛（还有很多帮助我的人，没写出来但我都很感谢！）\n没有你们我是不可能能这么快理解（甚至完全做不出）这一部分的。\n我的基础很薄弱，对于ISA真的一无所知，感谢无私的帮助\n注意，包老师的中文版手册有些地方是有错的，建议只看概念，具体的编码参考英文的资料，比如：https://msyksphinz-self.github.io/riscv-isadoc/html/rvi.html#fence-i\n具体还是要以英文手册的译码为准。\n【前半部分都是纯粹的抄讲义阶段。。但是抄了后真的能比较好理解】\nPA2一开始的任务是实现译码的流程，补充辅助译码函数（注意一下伪指令不用实现，函数体可以留空）\nRTFSC(2) fetch_decode_exec_updatepc()： 取指, 译码, 执行, 更新PC 在cpu_exec——fetch_decode_exec_updatepc——fetch_decode\nfetch_decode_exec_updatepc()接受一个Decode类型的结构体指针s, 这个结构体用于存放在执行一条指令过程中的译码和执行信息, 包括指令的PC, 执行方式, 以及操作数的信息. 还有一些信息是ISA相关的, NEMU用一个结构类型ISADecodeInfo来对这些信息进行抽象, 具体的定义在nemu/src/isa/$ISA/include/isa-def.h中. fetch_decode_exec_updatepc()首先会调用fetch_decode()进行取指和译码, fetch_decode()会先把当前的PC保存到s的成员pc和snpc中, 其中s-\u0026gt;pc就是当前指令的PC, 而s-\u0026gt;snpc则是下一条指令的PC, 这里的snpc是 \u0026ldquo;static next PC\u0026quot;的意思.\n然后代码会调用isa_fetch_decode()函数(在nemu/src/isa/$ISA/instr/decode.c中定义), 它会随着取指的过程修改s-\u0026gt;snpc的值, 使得从isa_fetch_decode()返回后s-\u0026gt;snpc正好为下一条指令的PC. 这里的dnpc**是\u0026quot;dynamic next PC\u0026quot;的意思. **\n此外, isa_fetch_decode()还会返回一个编号idx, 用于对g_exec_table这一数组进行索引. g_exec_table是一个函数指针的数组, 数组中的每个元素都会指向一个用于模拟指令执行的函数, 我们把这样的函数称为\u0026quot;执行辅助函数\u0026rdquo;(execution helper function). 通过idx索引这个数组, 可以找到与一条指令相匹配的执行辅助函数, 并把它记录到s-\u0026gt;EHelper中.\n忽略fetch_decode()中剩下与trace相关的代码, 我们就返回到fetch_decode_exec_updatepc()中. 将会调用刚才记录到的执行辅助函数, 来模拟指令执行的真正操作. 最后会更新PC, 让PC指向下一条指令.\n显然, fetch_decode_exec_updatepc()函数覆盖了指令周期的所有阶段: 取指, 译码, 执行, 更新PC. 在这些阶段中, 代码都可以对s进行记录和访问. 取指(instruction fetch, IF) isa_fetch_decode()做的第一件事情就是取指令. 在NEMU中, 有一个函数instr_fetch()(在nemu/include/cpu/ifetch.h中定义)专门负责取指令的工作. instr_fetch()最终会根据参数len来调用vaddr_ifetch()(在nemu/src/memory/vaddr.c中定义), 而目前vaddr_ifetch()又会通过paddr_read()来访问物理内存中的内容. 因此, 取指操作的本质只不过就是一次内存的访问而已.\nisa_fetch_decode()在调用instr_fetch()的时候传入了s-\u0026gt;snpc的地址, 因此instr_fetch()最后还会根据len来更新s-\u0026gt;snpc, 从而让s-\u0026gt;snpc指向下一条指令.\nMotorola 68k系列的处理器都是大端架构的. 现在问题来了, 考虑以下两种情况:\n假设我们需要将NEMU运行在Motorola 68k的机器上(把NEMU的源代码编译成Motorola 68k的机器码)\n假设我们需要把Motorola 68k作为一个新的ISA加入到NEMU中 在这两种情况下, 你需要注意些什么问题? 为什么会产生这些问题? 怎么解决它们?\n答：我猜想可以在memory的host.h处以及map.c的地方通过位置调整（改变addr指针的偏移）解决问题。有朋友提出可以固定len然后再拼起来，也有朋友建议可以了解一下ntohl和ntohs的现有转换库\n译码(instruction decode, ID) 译码的目的是得到指令的操作和操作对象, 这主要是通过查看指令的opcode来决定的. 不同ISA的opcode会出现在指令的不同位置, 我们只需要根据指令的编码格式, 从取出的指令中识别出相应的opcode即可.\n和YEMU相比, NEMU使用一种抽象层次更高的译码方式: 模式匹配, NEMU可以通过一个模式字符串来指定指令中opcode:(def_INSTR_IDTAB 在 decode.c)\nnemu/include/cpu/decode.h 定义了这些各种各样的宏，包括模式匹配规则。\n宏展开def的定义宏后是这样的：（根据def_INSTR_raw）\ndo { uint32_t key, mask, shift; pattern_decode(\u0026#34;??????? ????? ????? ??? ????? 01101 11\u0026#34;, 37, \u0026amp;key, \u0026amp;mask, \u0026amp;shift); if (((s-\u0026gt;isa.instr.val \u0026gt;\u0026gt; shift) \u0026amp; mask) == key) { decode_U(s, 0); return table_lui(s); } } while (0); 操作对象(比如立即数是多少, 读入到哪个寄存器). 为了解决这个问题, 代码需要进行进一步的译码工作, 这是通过调用相应的译码辅助函数(decode helper function)来完成的. 译码辅助函数统一通过宏def_DHelper(在nemu/include/cpu/decode.h中定义)来定义\n每个译码辅助函数负责进行一种类型的操作数译码, 把指令中的操作数信息分别记录在译码信息s的dest成员, src1成员和src2成员中, 它们分别代表目的操作数和两个源操作数. nemu/include/cpu/decode.h中还定义了三个宏id_dest, id_src1和id_src2, 用于方便地访问它们.【注意，这里的关键是原操作数和目的操作数的是否可写入权限】\n寄存器和立即数这些操作数, 其实是非常常见的操作数类型. 为了进一步实现操作数译码和指令译码的解耦, 框架代码对这些操作数的译码进行了抽象封装, 指令译码过程由若干译码操作数辅助函数(decode operand helper function)组成. 译码操作数辅助函数统一通过宏def_DopHelper来定义\nDopHelper带有一个flag参数, 不同的DopHelper可以用它来进行不同的处理. 例如寄存器的DopHelper可以通过flag来指示是否写入（可以参考def_DopHelper(r)实现中的）\nvoid concat(decode_op_, name) (Decode *s, Operand *op, word_t val, bool flag)可以匹配decode_op_r和decode_op_i(def_DopHelper(r), def_DopHelper(i) )\nDopHelper带有一个flag参数, 不同的DopHelper可以用它来进行不同的处理. 例如寄存器的DopHelper可以通过flag来指示是否写入（可参考def_DopHelper(r)中的实现）\n有了这些译码操作数辅助函数, 我们就可以用它们来编写译码辅助函数:def_DHelper(I)、\ndef_DHelper(U)、 def_DHelper(S)\n由于CISC指令变长的特性, x86指令长度和指令形式需要一边取指一边译码来确定, 而不像RISC指令集那样可以泾渭分明地处理取指和译码阶段, 因此你会在x86的译码操作数辅助函数中看到​的操作.\nQ：mips32和riscv32的指令长度只有32位, 因此它们不能像x86那样, 把C代码中的32位常数直接编码到一条指令中. 思考一下, mips32和riscv32应该如何解决这个问题?\nA：指令和储存分开，而且可以用两个拼成一个，把数据存在32位寄存器，或者变成几个寄存器加减结果。或者有朋友说的可以高位低位分开储存(实际上你在手册中能看到部指令这样的实现之类的）。\n回到def_INSTR_IDTAB的宏展开结果,：\ndo { uint32_t key, mask, shift; pattern_decode(\u0026#34;??????? ????? ????? ??? ????? 01101 11\u0026#34;, 37, \u0026amp;key, \u0026amp;mask, \u0026amp;shift); if (((s-\u0026gt;isa.instr.val \u0026gt;\u0026gt; shift) \u0026amp; mask) == key) { decode_U(s, 0); return table_lui(s); } } while (0); 对于lui指令, 在译码辅助函数decode_U()执行结束后, 代码将会执行table_lui(). table_lui()的定义方式比较特殊, 部分宏展开后的定义:\ndef_THelper(lui) { return EXEC_ID_lui; } 其中宏def_THelper(在nemu/include/cpu/decode.h中定义) 用于**统一定义\u0026quot;表格辅助函数\u0026quot;(table helper function). **table_lui()做的事情很简单, 它直接返回一个标识lui指令的唯一ID. 这个ID会作为译码结果的返回值, 在fetch_decode()中索引g_exec_table数组.\n事实上, 译码的过程可以看成是若干查表的操作, 每一条模式匹配的规则都可以看成是表格中的一个表项, 因此我们可以使用表格辅助函数来描述这些译码的规则. 以riscv为例:\n这一模式字符串只能通过opcode匹配到load类型的指令, 为了进一步确定是哪一条load指令, 我们还需要匹配funct3字段（具体查看riscv手册就直到为什么要匹配那三个了。）, 因此我们引入一个新的表格辅助函数table_load(), 匹配到load类型指令的时候, 会进一步调用table_load(), 然后在其中通过额外的模式字符串来匹配funct3字段, 例如: 以riscv为例:\ndef_THelper(load) { def_INSTR_TAB(\u0026#34;??????? ????? ????? 010 ????? ????? ??\u0026#34;, lw); return EXEC_ID_inv; } def_INSTR_TAB也是一条字符串匹配规则, 但它并不需要调用译码辅助函数. 这条规则描述了\u0026quot;在load类型指令中, 如果funct3为010, 则为lw指令\u0026quot;.\n** NEMU把译码时的如下情况都看作是查表过程:** ​\n在isa_fetch_decode()中查主表(main decode table)\n在译码过程中分别匹配指令中的每一个域(如上文介绍的table_load()\n译码出最终的指令时认为是一种特殊的查表操作, 直接返回标识该指令的唯一ID\n如果所有模式匹配规则都无法成功匹配, 代码将会返回一个标识非法指令的ID.\n执行(execute, EX) 之前的关键是译码辅助函数（decode_U）——译码辅助函数统一通过宏def_DHelper(在nemu/include/cpu/decode.h)来定义；以及\u0026quot;表格辅助函数\u0026quot;def_THelper(也在nemu/include/cpu/decode.h)，他返回一个标识lui指令的唯一ID. 这个ID会作为译码结果的返回值, 在fetch_decode()中索引g_exec_table数组。\n一种好的做法是把译码, 执行和操作数宽度的相关代码分离来, 实现解耦. 在框架代码中, 实现译码和执行之间的解耦的是isa_fetch_decode()返回的编号, 这样我们就可以分别编写译码和执行的辅助函数, 然后进行组合:这很容易实现执行行为相同但译码方式不同的多条指令.\n现在我们需要注意的是执行辅助函数def_EHelper（在g_exec_table）。\n译码过程结束之后, 接下来会返回到fetch_decode()中, 并通过返回的ID来从g_exec_table数组中选择相应的执行辅助函数(execution helper function), 然后记录到s-\u0026gt;EHelper中. 返回到fetch_decode_exec_updatepc()后, 代码将会调用刚才记录的执行辅助函数. 执行辅助函数统一通过宏def_EHelper(在nemu/include/cpu/exec.h中定义)来定义\n（对x86来说, 大部分计算指令都可以访问内存, 来根据目的操作数类型的不同, 决定是写入寄存器还是写入内存; 对于mips32和riscv32, 访问内存只能通过特定的访存指令进行, 因此每条指令的目的操作数类型都是唯一的.）\n每个执行辅助函数都需要有一个标识该指令的ID以及一个表格辅助函数与之相对应, 通过一系列宏定义实现的. 在nemu/src/isa/$ISA/include/isa-all-instr.h中定义用于表示指令列表的宏INSTR_LIST, 它定义了NEMU支持的所有指令. 然后代码通过一种类似函数式编程的方式来定义如下相关的内容:\n在nemu/include/cpu/decode.h中为所有的执行辅助函数定义相应的ID. 以riscv32为例, 对def_all_EXEC_ID()进行宏展开后, 结果如下: #define def_all_EXEC_ID() enum { MAP(INSTR_LIST, def_EXEC_ID) TOTAL_INSTR }\n变为enum { EXEC_ID_lui, EXEC_ID_lw, EXEC_ID_sw, EXEC_ID_inv, EXEC_ID_nemu_trap, TOTAL_INSTR }\n其中TOTAL_INSTR的值正好为目前所有指令的总数\n只需要维护​中的指令列表, 就可以正确维护执行辅助函数和译码之间的关系了.\n更新PC 更新PC的操作非常简单, 在fetch_decode_exec_updatepc把s-\u0026gt;dnpc赋值给cpu.pc即可. 之前提到了snpc和dnpc, 它们的区别如下：\n在程序分析领域中, 静态指令是指程序代码中的指令, 动态指令是指程序运行过程中的指令\nsnpc是指代码中的下一条指令, 而dnpc是指程序运行过程中的下一条指令. dnpc应该指向跳转目标的指令. 显然, 我们应该使用s-\u0026gt;dnpc来更新PC, 并且在执行辅助函数中正确维护s-\u0026gt;dnpc.\n用RTL表示指令行为 这个很重要！大部分译码函数都通过这个实现（具体有些行为在op_c中可以找到）\n需要详细查看\n在NEMU中,使用RTL(寄存器传输语言)来描述（先实现这些简单操作, 然后再用它们来实现指令）. RTL寄存器的定义. 在NEMU中, RTL寄存器统一使用rtlreg_t来定义, 而rtlreg_t(在nemu/include/common.h中定义)其实只是一个word_t类型:\ntypedef word_t rtlreg_t; 在NEMU中的RTL寄存器：\n不同ISA的通用寄存器(在nemu/src/isa/$ISA/include/isa-def.h中定义)\n临时寄存器s0, s1, s2和t0(在nemu/include/rtl/rtl.h中定义)\n零寄存器rz(在nemu/include/rtl/rtl.h中定义), 它的值总是0\n（其实不需要使用 临时寄存器就可以完成大部分指令\n实现新指令 对译码, 执行和操作数宽度的解耦实现以及RTL的引入, 对在NEMU中实现客户指令提供了很大的便利, 为了实现一条新指令, 只需要\n在nemu/src/isa/$ISA/instr/decode.c中添加正确的模式匹配规则\n用RTL实现正确的执行辅助函数, 需要注意使用RTL伪指令时要遵守上文提到的小型调用约定\n在nemu/src/isa/$ISA/include/isa-all-instr.h中把指令添加到INSTR_LIST中\n必要时在nemu/src/isa/$ISA/include/isa-exec.h中添加相应的头文件\n请整理一条指令在NEMU中的执行过程. 指令集相关文件：\n各类指令RTL调用函数实现部分：/home/physico/ics2021/nemu/src/isa/riscv32/instr/ *.h\n译码函数部分：/home/physico/ics2021/nemu/src/isa/riscv32/instr/decode.c\n函数名-宏展开需要部分：/home/physico/ics2021/nemu/src/isa/riscv32/include/isa-all-instr.h（旁边的isa-exec可以包括1提到的）\nISADecodeInfo：/home/physico/ics2021/nemu/src/isa/riscv32/include/isa-def.h\nRTL实现相关：\n/home/physico/ics2021/nemu/src/engine/interpreter/rtl-basic.h （def_rtl_compute_reg_imm）\n/home/physico/ics2021/nemu/src/engine/interpreter/c_op.h（c_add(a, b) ((a) + (b)) 以及 interpret_relop类似RELOP_NE）\n踩坑心得 关键：理解立即数的符号位是怎么确定的，什么时候用无符号数有符号数，怎么样正确移位置，怎么样设置好src与dest的是否可读写权限。友情建议先实现diff（具体在哪请看讲义）。\n(注意，接下来的叙述是有问题的，之后会说问题在哪)\n一开始实现li，最后才知道li原来是伪指令，所以关键是先实现R、S、U的基础指令（RTSM有关中文部分）。一开始怎么样都无法编译，原来是忘记了computer相关头文件的函数实现，顺带修改了一下isa-def当中的结构体，终于编译通过（后来改成了先实现addi也就是R型指令）\n编译通过后，si还是会报错，在确定def_DHelper(R)初始化后反复检查发现是def_THelper(main)模式匹配就没匹配到（还好Log大法好一个个检查。。）直接看前面的指令是不正确的（不太清楚原因，就是手册开头有整理好基础类型，我对照结尾填写），通过直接搜addi（决定看英文的手册）改正后能搜到了不会报错。\n解决了编译和报错问题，写了一段a0相关的相加代码，发现还是有问题；最后排查是自己不够理解RTL的实现，要深入pseudo.h理解相关函数作用，然后再理解功能的实现套用即可得到正确的结果（一开始还把src2的立即数写成了src1.imm闹了笑话）\n这时候发现前面写的基础设施还是派上用场了\n一顿操作猛如虎，一样在做pa的朋友告诉我addi和lw一样都是I型，我一开始还不信（我以为相同低位表示一个类型）然后发现他们的低位不同也是I型（所以直接新增一个I类型的主表再同样的初始化后执行对应函数即可）\u0026hellip;..只能重新阅读手册理解类型是怎么区别的：\n当然前面虽然不小心“造了轮子”，但也不是坏事，还是能派上用场的。\n最困难的部分——怎么了解立即数？\nhttps://blog.csdn.net/qq_39507748/article/details/120150936\nhttps://www.cnblogs.com/mikewolf2002/p/11196680.html\n有朋友建议我看cs61b，于是我去翻了一下\nhttps://inst.eecs.berkeley.edu/~cs61c/su20/pdfs/lectures/lec08.pdf\n理解这张图的含义（看不懂就多读几遍，2.4是下面一张图）【关键是指令给了组成imm的部分，imm图展示了要从指令的哪儿拿】\n猜测：拿inst[31]是不是就是00000000000或者1111111111111，也是一种拓展\nQ:为什么要左移？\nA:我的看法是，我们的立即数一开始都要移位才能组装成真正的编码好的立即数（都是从0开始，为了让他到拼接的地方 我们必须移位）然后拼好后的立即数都要是这样的（2.4中都是组装好的立即数）也就是符号位扩展的。为什么说符号位扩展了？比如有inst31 的就是都000000 或者111111\n注意：伪函数是不需要实现的，编译器会帮你选择实现它真正的执行的函数，甚至都不用写。\n完成最简单的开始后~接下来就需要运行除了dummy各种各样的C文件了，确保指令都实现（比如基础的add和ifelse）\nQ：如果不知道哪个指令没实现怎么办？\nA：想想有了内存地址后在什么情况下能让他显示指令\n当然，更优雅的你可以在修改nemu.mk 中取消-b后缀即可让他完美停下来可以一步步看（在test中make的阶段），或者你也可以用这样的操作：（测试这个命令函参数找的我有点抑郁，注意-d后面的-，你也可以写-1）\n./riscv32-nemu-interpreter -d - --diff=/xxxxxx/ics2021/nemu/tools/spike-diff/build/riscv32-spike-so /xxxxxxx/ics2021/am-kernels/tests/cpu-tests/build/add-riscv32-nemu.bin 提前加了diff后，发现一直卡在add.c无法实现的痛苦（bne一直有问题）查了非常久的compute和decode译码都无法找到错误，最后发现是isa-def立即数环节出错。。。。。。只有最高位int其他uint我却把B指令的其他立即数也写成了int\u0026hellip;\u0026hellip;所以旧报错了，改完后成功通过add测试，感觉人生到了一种大和谐~~~~\n这里引发了一个思考：为什么中间不能用int？有个老哥说这是因为有符号数字在bitfield中会自动补1，这是不行的，我们可以做实验来验证是不是位域都会有这个性质（其实就是有符号数的扩展性质，如果无符号数直接零拓展）。\n后面在实现R型指令的时候又遇到了bug，也是同样的寄存器问题，后面排查发现是译码阶段寄存器写入开关我写成了true，但得是false\u0026hellip;.原因是：\n另外，对于RTL你需要有更深入的理解，R和I其实都在32位寄存器-寄存器类型和寄存器-立即数类型的基本算术/逻辑运算里了。包括rtl_(add|sub|and|or|xor|sll|srl|sra|setrelop)i?, 它们的定义用到了nemu/src/engine/interpreter/c_op.h中的C语言运算。当想不出来的时候思考一下add和addi的区别，他们是怎么得到的。有关寄存器和imm的操作都有了，可以直接用。\n这里还涉及到mul，当我们看到op_c会发现都是64位，为什么呢？因为32乘法的话是错误的（不是溢出而是就是错，涉及到符号位的问题），具体原因可以看：\nhttps://pages.cs.wisc.edu/~markhill/cs354/Fall2008/beyond354/int.mult.html\n程序, 运行时环境与AM 应用程序的运行需要运行时环境的支持, 包括加载, 销毁程序, 以及提供程序运行时的各种动态链接库(你经常使用的库函数就是运行时环境提供的)等. 为了让客户程序在NEMU中运行, 现在需要相应的运行时环境的支持了.\n计算机可以永不停止地执行指令, 但一般的程序都是会结束的, 所以运行时环境需要向程序提供一种结束运行的方法. PA1中提到的那条人工添加的nemu_trap指令, 就是让程序来结束运行的.\n只要有内存, 有结束运行的方式, 加上实现正确的指令, 就可以支撑最简单程序的运行了. 而这, 也可以算是最简单的运行时环境了.\n将运行时环境封装成库函数 通过库, 运行程序所需要的公共要素被抽象成API, 不同的架构只需要实现这些API, 也就相当于实现了支撑程序运行的运行时环境, 这提升了程序开发的效率: 需要的时候只要调用这些API, 就能使用运行时环境提供的相应功能.\nAM - 裸机(bare-metal)运行时环境 应用程序的运行都需要运行时环境的支持; 只进行纯粹计算任务的程序在TRM上就可以运行\n更高级的游戏需要运行时环境提供输入输出等的支持，我们需要收集这些需求，统一成一个API给程序，这样就可以支撑不同程序在各种架构上运行的库。\n每个架构都按照它们的特性实现这组API; 应用程序只需要直接调用这组API即可, 无需关心自己将来运行在哪个架构上. 由于这组统一抽象的API代表了程序运行对计算机的需求, 所以我们把这组API称为抽象计算机\nAM(Abstract machine)项目就是这样诞生的. 作为一个向程序提供运行时环境的库, AM根据程序的需求把库划分成以下模块\nAM = TRM + IOE + CTE + VME + MPE\nTRM(Turing Machine) - 图灵机, 最简单的运行时环境, 为程序提供基本的计算能力\nIOE(I/O Extension) - 输入输出扩展, 为程序提供输出输入的能力\nCTE(Context Extension) - 上下文扩展, 为程序提供上下文管理的能力\nVME(Virtual Memory Extension) - 虚存扩展, 为程序提供虚存管理的能力\nMPE(Multi-Processor Extension) - 多处理器扩展, 为程序提供多处理器通信的能力 (MPE超出了ICS课程的范围, 在PA中不会涉及)\n解耦和分层的艺术！\n(在NEMU中)实现硬件功能 -\u0026gt; (在AM中)提供运行时环境 -\u0026gt; (在APP层)运行程序\n(在NEMU中)实现更强大的硬件功能 -\u0026gt; (在AM中)提供更丰富的运行时环境 -\u0026gt; (在APP层)运行更复杂的程序\n整个AM项目分为两大部分:\nabstract-machine/am/ - 不同架构的AM API实现, 目前我们只需要关注NEMU相关的内容即可. 此外, abstract-machine/am/include/am.h列出了AM中的所有API, 我们会在后续逐一介绍它们.\nabstract-machine/klib/ - 一些架构无关的库函数, 方便应用程序的开发\n阅读abstract-machine/am/src/platform/nemu/trm.c中的代码, 你会发现只需要实现很少的API就可以支撑起程序在TRM上运行了:\nArea heap结构用于指示堆区的起始和末尾\nvoid putch(char ch)用于输出一个字符\nvoid halt(int code)用于结束程序的运行\nvoid _trm_init()用于进行TRM相关的初始化工作\n#include \u0026lt;am.h\u0026gt; #include \u0026lt;nemu.h\u0026gt; extern char _heap_start; int main(const char *args); Area heap = RANGE(\u0026amp;_heap_start, PMEM_END); #ifndef MAINARGS #define MAINARGS \u0026#34;\u0026#34; #endif static const char mainargs[] = MAINARGS; void putch(char ch) { outb(SERIAL_PORT, ch); } void halt(int code) { nemu_trap(code); // should not reach here while (1); } void _trm_init() { int ret = main(mainargs); halt(ret); } 最后来看看halt(). halt()里面调用了nemu_trap()宏 (在abstract-machine/am/src/platform/nemu/include/nemu.h中定义), 这个宏展开之后是一条内联汇编语句, 内联汇编语句允许我们在C代码中嵌入汇编语句, 显然, 这个宏的定义是和ISA相关的.\n这条特殊的指令是人为添加的, 标准的汇编器并不能识别它, objdump的反汇编结果也无法按照我们的想法将其反汇编为nemu_trap. nemu_trap()宏还会把一个标识结束的结束码移动到通用寄存器中, 这样, 这段汇编代码的功能就和nemu/src/isa/$ISA/instr/special.h 中的执行辅助函数def_EHelper(nemu_trap)对应起来了: 通用寄存器中的值将会作为参数传给rtl_hostcall, rtl_hostcall将会根据传入的id(此处为HOSTCALL_EXIT)来调用set_nemu_state(), 将halt()中的结束码设置到NEMU的monitor中, monitor将会根据结束码来报告程序结束的原因.\n（在哪结束，为什么结束）\n编译生成一个可以在NEMU的运行时环境上运行的程序的过程大致如下:\n（这部分看得我头痛）\ngcc将$ISA-nemu的AM实现源文件编译成目标文件, 然后通过ar将这些目标文件作为一个库, 打包成一个归档文件abstract-machine/am/build/am-$ISA-nemu.a\ngcc把应用程序源文件(如am-kernels/tests/cpu-tests/tests/dummy.c)编译成目标文件\n通过gcc和ar把程序依赖的运行库(如abstract-machine/klib/)也编译并打包成归档文件\n根据Makefile文件abstract-machine/scripts/$ISA-nemu.mk中的指示, 让ld根据链接脚本abstract-machine/scripts/linker.ld, 将上述目标文件和归档文件链接成可执行文件\n根据上述链接脚本的指示, 可执行程序重定位后的节从0x100000或0x80000000开始 (取决于_pmem_start和_entry_offset的值), 首先是.text节, 其中又以abstract-machine/am/src/$ISA/nemu/start.S中自定义的entry节开始, 然后接下来是其它目标文件的.text节. 这样, 可执行程序起始处总是放置start.S的代码, 而不是其它代码, 保证客户程序总能从start.S开始正确执行. 链接脚本也定义了其它节(包括.rodata, .data, .bss)的链接顺序, 还定义了一些关于位置信息的符号, 包括每个节的末尾, 栈顶位置, 堆区的起始和末尾.\n我们对编译得到的可执行文件的行为进行简单的梳理:\n第一条指令从abstract-machine/am/src/$ISA/nemu/start.S开始, 设置好栈顶之后就跳转到abstract-machine/am/src/platform/nemu/trm.c的_trm_init()函数处执行.\n在_trm_init()中调用main()函数执行程序的主体功能, main()函数还带一个参数, 目前我们暂时不会用到, 后面我们再介绍它.\n从main()函数返回后, 调用halt()结束运行.\n有了TRM这个简单的运行时环境, 我们就可以很容易地在上面运行各种\u0026quot;简单\u0026quot;的程序了. 当然, 我们也可以运行\u0026quot;不简单\u0026quot;的程序: 我们可以实现任意复杂的算法, 甚至是各种理论上可计算的问题, 都可以在TRM上解决.\n实现更多库函数 经过哭天喊地的实现终于。。。。。（sprintf实在是难度太大，我从网上找了好久找到一个最小实现printf魔改了一下，等更强了再来理解，实际上是要理解可变参数管理之类的才能解答。）\n批量测试通过 做个纪念:) （做ISA的时候真的感觉人要没了，但是就这样慢慢前进还是看到了曙光） ：\n重新认识计算机: 计算机是个抽象层 微观视角: 程序是个状态机 宏观视角: 计算机是个抽象层\n大家在做实验的时候也可以多多思考: 我现在写的代码究竟位于哪一个抽象层? 代码的具体行为究竟是什么?\n状态机视角可以从指令层次精确地描述程序运行的每一处细节, 但丢失了程序的语义. 为了更好地理解复杂程序, 我们需要从一个新的视角来切入.\n先来讨论在TRM上运行的程序, 看计算机系统是如何支撑这些需求的.\nTRM 计算 内存申请 结束运行 打印信息 运行环境 - malloc()/free() - printf() AM API - heap halt() putch() ISA接口 指令 物理内存地址空间 nemu_trap指令 I/O方式 硬件模块 处理器 物理内存 Monitor 串口 电路实现 cpu_exec() pmem[] nemu_state serial_io_handler() 计算. 这是程序最基本的需求, 以至于它甚至不属于运行时环境和AM的范畴. 所有计算相关的代码(顺序语句, 分支, 循环, 函数调用等), 都会被编译器编译成功能等价的指令序列, 最终在CPU上执行. 在NEMU中, 我们通过cpu_exec()函数来实现\u0026quot;CPU执行指令\u0026quot;的功能.\n内存申请. 有的程序需要在运行时刻动态地申请内存来使用. 和libc类似, klib提供了malloc()和free()来实现内存的动态管理(你将来会实现它们), 它们又会使用TRM中提供的API heap来获得堆区的起始和末尾. 而heap的区间又是由ISA-平台这个二元组对应的物理内存地址空间来决定的. 这一地址空间对应着物理内存的大小, 在NEMU中, 它就是大数组pmem[]的大小.\n结束运行. 一般程序都会有结束运行的时候, TRM提供了一个halt()的API来实现这一功能. 由于这个需求过于简单, 因此无需运行时环境提供更复杂的接口. halt()的具体实现和ISA有关, 我们使用了人为添加的nemu_trap指令来实现这一点. 执行nemu_trap指令会让NEMU从CPU执行指令的循环中跳出, 返回到Monitor中, 这是通过设置Monitor中的一个状态变量nemu_state来实现的.\n打印信息. 输出是程序的另一个基本需求. 程序可以调用klib中的printf()来输出, 它会通过TRM的API putch()来输出字符. 不同的ISA-平台有不同的字符输出方式, 在$ISA-nemu中, putch()通过I/O相关的指令把字符写入到串口, 最终在NEMU中通过serial_io_handler()将字符打印到终端. 关于输入输出的更多细节会在PA2的最后部分进行介绍.\n每一层抽象都有它存在的理由:\n概念相同的一个硬件模块有着不同的实现方式, 比如处理器既可以通过NEMU中简单的解释方式来实现, 也可以通过类似QEMU中高性能的二进制翻译方式来实现, 甚至可以通过verilog等硬件描述语言来实现一个真实的处理器.\nISA是硬件向软件提供的可以操作硬件的接口\nAM的API对不同ISA(如x86/mips32/riscv32)的接口进行了抽象, 为上层的程序屏蔽ISA相关的细节\n运行时环境可以通过对AM的API进行进一步的封装, 向程序提供更方便的功能\n对AM的进一步理解（待完成 暂时待填坑。。。\n","date":"2022-08-12T21:50:40+08:00","permalink":"https://sanbuphy.github.io/p/nju%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C-pa2%E7%AC%94%E8%AE%B0%E4%B8%80/","title":"NJU计算机课程基础实验 PA2笔记（一）"},{"content":"一些小工具 让你能做出和jyy一样的优雅ppt：https://sli.dev/\n代替grep的超级命令行工具——ripgrep：https://github.com/BurntSushi/ripgrep\nripgrep is a line-oriented search tool that recursively searches the current directory for a regex pattern. By default, ripgrep will respect gitignore rules and automatically skip hidden files/directories and binary files. ripgrep has first class support on Windows, macOS and Linux, with binary downloads available for every release. ripgrep is similar to other popular search tools like The Silver Searcher, ack and grep.\n网络包分析——Wireshark：https://www.cnblogs.com/linyfeng/p/9496126.html #########待更新\n","date":"2022-07-31T11:48:46+08:00","permalink":"https://sanbuphy.github.io/p/%E6%8E%A8%E8%8D%90%E5%B0%9D%E8%AF%95%E7%9A%84%E5%B0%8F%E5%B7%A5%E5%85%B7/","title":"推荐尝试的小工具"},{"content":"详细的缓冲区介绍请看这篇文章，非常详细 https://www.cnblogs.com/lanhaicode/p/10575049.html\n全缓冲：当缓冲区被填满以后才进行真正的输入输出操作\n行缓冲：当在输入或者输出的过程中遇到换行符时，才执行真正的输入输出操作\n无缓冲：没有缓冲区，立即进行输入输出\n实际上printf是行缓冲，如果printf(\u0026quot;hello\u0026quot;)而不加上\\n是不会出现结果的(之前在fork()的时候遇到这个问题)\n但为什么我们直接看结果是会出现的呢？\n原因是标准输出在程序正常退出的时候，会调用 fclose(stdout)，而 fclose 函数会调用 fflush。因此，如果你的程序提前崩溃了，那是看不到缓冲区中的内容打印到控制台上的。特别注意的是，exit（正常退出）的话会输出，exit在调用系统_exit 之前，首先调用退出处理函数，刷新I/O缓冲，关闭文件描述符，最后调用_exit 退出进程；_exit（立即终止进程）不会输出缓冲区。\n待补充内容：fork试验下printf失效的原理（jyy某一课 https://blog.csdn.net/takashi77/article/details/108077328\n待补充内容：常见IO的缓冲分类 ","date":"2022-07-31T11:33:06+08:00","permalink":"https://sanbuphy.github.io/p/c%E8%AF%AD%E8%A8%80%E6%A0%87%E5%87%86io%E7%9A%84%E7%BC%93%E5%86%B2%E5%8C%BA%E4%BB%8B%E7%BB%8D/","title":"C语言标准IO的缓冲区介绍"},{"content":"在做PA的过程中，发现这样的一段代码（模拟cpu的过程）：\n那么问题就来了——为什么这里op位段会自动匹配前面的部分？（为什么不匹配后面） 和大端法有关系吗？\n我怀疑就是小端定义，但不明白原因，于是开始了漫长的搜索\u0026hellip;..\n（直接看结果【不一定对，如果有疑问欢迎提出一起讨论，谢谢，我对编译器也不熟悉】）：\n我认为bit field的反向读取本质上也是由于计算机结构大小端实现的，编译器会先看机器是否有定义当然也可以改变定义，C语言标准中本身没有定义。）\n查到了也有人遇到类似的问题： 在一个编译器的网站下，我发现了这样一段话：\nFor big-endian mode, bit fields are packed into registers from most significant bit (MSB) to least significant bit (LSB) in the order in which they are defined. Bit fields are packed in memory from most significant byte (MSbyte) to least significant byte (LSbyte). For little-endian mode, bit fields are packed into registers from the LSB to the MSB in the order in which they are defined, and packed in memory from LSbyte to MSbyte.\n那此时我们知道确实可能和大小端法是有关的,至少在C语言上是这样的。而C++上只给了说明，没有为什么，只给出了定义。\n但问题又来了，一般机器中大小端看的是字节排序，但是我发的位域是对一个字节进行划分，一个字节内的bit也要遵循大小端排序吗？\n在查阅C标准中我发现原来这个位域排布是implementation-dependent的（也就是说不管怎么样，首先位域排布是C标准没有明确定义的，取决于编译器） Implementation dependent means that the standard says nothing about some occurance in C/C++ and leaves the choice up to the people who create compilers and operating systems. It means that what you use on one system/compiler may not work the same way on another, but the behavior is well defined for that particular implementation. For example, whether the result of a right bitwise shift on a signed variable results in a logical or arithmetic shift is implementation defined.\n那么我们的检索范围就可以缩小了，只要知道这个行为是不是编译器规定的即可。\n继续查看GCC的手册\nThis represents a reference to a sign-extended bit-field contained or starting in loc (a memory or register reference). The bit-field is size bits wide and starts at bit pos. The compilation option BITS_BIG_ENDIAN says which end of the memory unit pos counts from.\n答案很接近了，我猜想只要知道BITS_BIG_ENDIAN是做什么的即可\n同样继续查看GCC的手册StorageLayout\nBITS_BIG_ENDIAN Define this macro to have the value 1 if the most significant bit in a byte has the lowest number; otherwise define it to have the value zero. This means that bit-field instructions count from the most significant bit. If the machine has no bit-field instructions, then this must still be defined, but it doesn\u0026rsquo;t matter which value it is defined to. This macro need not be a constant. This macro does not affect the way structure fields are packed into bytes or words; that is controlled by BYTES_BIG_ENDIAN.\n里面出现了“If the machine has no bit-field instructions”，所以倾向于还是机器为准的。\n综上所述，我认为bit field的反向读取本质上也是由于计算机结构大小端实现的，编译器会先看机器是否有定义当然也可以改变定义，C语言标准中本身没有定义。\n","date":"2022-07-31T09:18:16+08:00","permalink":"https://sanbuphy.github.io/p/c%E4%BD%8D%E6%AE%B5/%E4%BD%8D%E5%9F%9Fbit-field%E7%9A%84%E6%8E%92%E5%BA%8F%E5%8E%9F%E7%90%86/","title":"C位段/位域(bit field)的排序原理"},{"content":"开始测试多线程的检测与英伟达板卡拉流压力测试，摄像头不够就用笔记本上。本文实现功能：\n将本地摄像头作为设备获取图像，用电脑建立服务器推送rtsp流并在其他同网段电脑下拉流。\n使用软件:\nFFmpeg(音视频编解码) EasyDarwin(流媒体服务器) 完整参考以下文章即可：（记得推送IP要改成指定的一个IP，而不是127那指的是本地IP）\n如果不能连接，除了ping之外还要用curl ip:port或者telnet等检测，如果不行就把推流机的公共防火墙关闭。（之前我没有关闭防火墙是不能拉流的）\n如果用的是ubuntu拉流，还要看看是不是虚拟网卡有所影响（虚拟网卡的ip不同可能访问策略优先）\nReference 流媒体服务器配置与管理——使用FFmpeg推流到EasyDarwin中再通过VLC观看\nEasyDarwin+ffmpeg进行PC(摄像头+麦克风)流媒体直播服务\nffmpeg\u0026ndash;使用命令+EasyDarwin推流笔记本摄像头\nEasyDarwin开源流媒体服务器\n","date":"2022-07-31T08:32:51+08:00","permalink":"https://sanbuphy.github.io/p/%E5%88%A9%E7%94%A8%E7%AC%94%E8%AE%B0%E6%9C%AC%E7%94%B5%E8%84%91%E8%BF%9B%E8%A1%8C%E6%8E%A8%E6%B5%81/","title":"利用笔记本电脑进行推流"},{"content":"提问：\n我们有什么检测手段（编译器或者操作系统自带检测）能防止stack overflow嘛？或者说防止出栈超界\n程序中的内存地址规定好r但不给w能防止栈溢出覆盖吗？或者出栈超界\n内核也是程序，如果发生了溢出会直接panic，是不是崩溃本身就作为了一种保护机制？\n答：（详细参考蒋炎岩的这一课：并发 Bug 和应对）\n1、请看如下解释\n2、值得做实验尝试，因为理论上我们是能够访修改内存地址权限的（这里有个小知识，为什么栈的内存地址不仅可读可写还可【执行】呢？因为这代表着CPU能读取译码并执行）\n3、是的，详见panic()\nBuffer Overrun 检查 Canary (金丝雀) 对一氧化碳非常敏感 用生命预警矿井下的瓦斯泄露 (since 1911)\n计算机系统中的 canary “牺牲” 一些内存单元，来预警 memory error 的发生 (程序运行时没有动物受到实质的伤害)\n比如把一些内存块“涂色”，如果发现它的“颜色被覆盖了”则说明有些保护的区域被访问了，这是错误的。（或者像PA那样的越界报错\n没用过 lint/sanitizers？ 具体请点击：并发 Bug 和应对\nAddressSanitizer (asan); (paper): 非法内存访问 Buffer (heap/stack/global) overflow, use-after-free, use-after-return, double-free, \u0026hellip; Demo: uaf.c; kasan\nThreadSanitizer (tsan): 数据竞争 Demo: fish.c, sum.c, peterson-barrier.c; ktsan\nMemorySanitizer (msan): 未初始化的读取\nUBSanitizer (ubsan): undefined behavior Misaligned pointer, signed integer overflow, \u0026hellip; Kernel 会带着 -fwrapv 编译\n","date":"2022-07-30T16:08:27+08:00","permalink":"https://sanbuphy.github.io/p/%E9%98%B2%E6%AD%A2stack-overflow%E5%86%85%E5%AD%98%E5%9C%B0%E5%9D%80%E6%9D%80%E6%AF%92/","title":"防止stack overflow——内存地址杀毒"},{"content":"Q：众所周知，有时候我们读取本地的视频信息，他有可能不全（比如直播录像，某些文件内容被破坏或者干脆没有比如）这是一个先有鸡还是先有蛋的问题——你怎么确定fps是对的：是opencv算的（先有了时长）还是说本身fps就是内嵌视频输出的信息而且保证不变然后opencv用这个去计算总时长（因为fps都是基本可以整除的所以基本只能看到opencv给出0.01精确度的时长）\nA：求总帧数是最准的，根据总时长可以计算出FPS，这才是最准确的。\n其他问题：如何看一个视频文件的容器/封装格式？ 答：使用xxd或其他可以看十六进制内容的程序直接打开视频文件，可以看到文件头里面有相关信息直接搜索相关内容（比如在未安装解码器的情况下，海康摄像头直播保存后的文件就是mpeg ps格式，有IMKH header）\n","date":"2022-07-30T15:00:59+08:00","permalink":"https://sanbuphy.github.io/p/%E6%9C%89%E5%85%B3fps%E8%AE%A1%E7%AE%97%E5%85%88%E6%9C%89%E9%B8%A1%E8%BF%98%E6%98%AF%E5%85%88%E6%9C%89%E8%9B%8B/","title":"有关fps计算——先有鸡还是先有蛋"},{"content":"有一天遇到需要实现shell脚本中变量连着括号一起读取，实现方法如下：\n如果不加双引号会翻车（你可以尝试去除不同的双引号看看效果）\n#!/bin/bash OLDIFS=IFS #IFS=`echo -e \u0026#34;\\n\u0026#34;` f1=\u0026#34;DAFS DFFS\u0026#34; f2=2 f3=3 f4=4 array=(\u0026#34;f1\u0026#34; $f2 $f3 f4) for element in \u0026#34;{array[@]}\u0026#34; do echo $element Reference：\nshell脚本中oldIFS=$IFS linux获得包含空白字符的行,Shell如何遍历包含空格的文本详解 ","date":"2022-07-30T09:29:20+08:00","permalink":"https://sanbuphy.github.io/p/shell%E8%84%9A%E6%9C%AC%E4%B8%AD%E5%8F%98%E9%87%8F%E6%97%A0%E6%B3%95%E8%AF%BB%E5%8F%96%E7%A9%BA%E6%A0%BC%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","title":"shell脚本中变量无法读取空格的解决方法"},{"content":"很多人根据数据结构的定义：\u0026ldquo;Data structure is a storage that is used to store and organize data. It is a way of arranging data on a computer so that it can be accessed and updated efficiently. Depending on your requirement and project, it is important to choose the right data structure for your project. \u0026ldquo;觉得类当然也是一种数据结构，因为符合定义中提到的行为。然而，经过一番查资料外加看了下经典clean coder blog的描述，发现事情没这么简单。\n关键还是要看“ 看你抽象了多少、抽象层级、想要对外暴露什么”，并且分析的角度也不同。\n潜在的标准答案\nClasses vs. Data Structures\n","date":"2022-06-25T15:07:48+08:00","permalink":"https://sanbuphy.github.io/p/classes-vs.-data-structures/","title":"Classes vs. Data Structures"},{"content":"作为几个月内重装过不下十次电脑的炸机猛男，强烈建议大家应该建立一个自己的“母盘”,储备好常见需要安装的软件（Anaconda、vscode等等）\n首先要保存一些常见的方法（当然可以类似鱼香ROS那样封装成为一个shell文件，自动换源并安装各种库）\n【环境配置】Ubuntu20.04如何更换国内源\ngit clone速度太慢的解决办法技巧分享 注：这里有个坑需要注意一下，当重置DNS的时候不要用文中方法（我是没有效用），你可以使用：sudo service network-manager restart\n如果你喜欢使用vim，建议你安装一键配置：vimplus 不过它的安装需要git clone，建议科学上网否则会出现大面积失败（常见功能还是能同步上的，就是非常非常慢。。。。）\nTODO:有时间了根据鱼香ROS的一键shell做一个属于自己的一键shell\n","date":"2022-06-25T14:50:08+08:00","permalink":"https://sanbuphy.github.io/p/%E7%B3%BB%E7%BB%9F%E9%80%83%E7%94%9F%E8%88%B1%E7%9A%84%E5%BF%85%E8%A6%81%E6%80%A7/","title":"系统逃生舱的必要性"},{"content":"su 的作用是切换当前用户，需要的是切换后账户的名字，即“su 账户名称”，如果后面不加账户时系统默认为root账户\nsu有两种用法： su Username/ su - Username，例子如下：\nsu root 输入root密码后切换之root用户但是pwd目录不变 su - root 输入root密码后切换之root用户但是pwd目录/root sudo 暂时切换到超级用户模式以执行超级用户权限，提示输入密码时该密码为当前用户的密码，而不是超级账户的密码\nsudo should be read as \u0026quot;su do\u0026quot;, that is, \u0026quot;switch user and do this command\u0026quot;.\nsudo -i root与sudo - root、sudo -i ,sudo - ，sudo root效果相同，提示输入密码时该密码为当前账户的密码 要求执行该命令的用户必须在sudoers中才可以\nsudo su 运行sudo命令给su命令提权，运行su命令\n","date":"2022-06-25T14:18:55+08:00","permalink":"https://sanbuphy.github.io/p/linux%E4%B8%ADsudosusu-%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/","title":"Linux中sudo、su、su-的那些事"},{"content":"Vision GNN: An Image is Worth Graph of Nodes 论文链接： https://arxiv.org/abs/2206.00272\n代码开源链接（暂无）：https://github.com/sanbuphy/CV-Backbones\n最近都在关注GNN在图像识别上的应用，发现已经被Huawei Noah’s Ark Lab做完了。。。\n但我很好奇他们是怎么处理训练集本身（loss是什么），对拆分后图结构的标注应该也是一个相对大的工程，这点需要等开源后仔细研究（也许还需要多读几遍Graph Representation of Image以及VIG BLock）\n该文基于图像的图表示（graph representation）提出了 vision graph neural network (ViG)。该文应该是首次将图神经网络用于视觉任务，同时取得很好的效果，在 ImageNet 分类任务上超过了 CNN (ResNet), MLP (CycleMLP) 和 transformer (Swin-T)\nThese parts linked by joints naturally form a graph structure. By analyzing the graph.\n通过图结构分解，各部分间的连接显得更加紧密：（相似的语义能够互相跨区域关联）\n“we are able to recognize the human. Moreover, graph is a generalized data structure that grid and sequence can be viewed as a special case of graph. Viewing an image as a graph is more flexible and effective for visual perception”\nVIG Block Huawei Noah’s Ark Lab提出了一个特殊的VIG块结构，相比GCNs可以提高特征的多样性，减少因网络深度加强导致的特征减少现象。ViG 块是构成 ViG 网络的基本构建单元，其由Grapher 模块和 FFN 模块叠加而成的。\n如何避免Feature diversity of nodes as layer changes 降低，即：\n“The over-smoothing phenomenon in deep GCNs will decrease the distinctiveness of node features and lead to performance degradation for visual recognition,”\n他们还提供了两种结构用于构建VIG，分别为各向同性与金字塔型：\n”we build two kinds of network architectures for ViG, i.e., isotropic architecture and pyramid architecture“\n验证数据集：\n跑数据集的设置：\n最后结果展示：\nIsotropic ViG：\nPyramid ViG\n在目标检测的效果：\nAblation Study测试的结果（关闭一些配件）\n过程的可视化：\n通过上图可以看到，浅层网络的跨区域图只是结合了颜色或形状等一些表象语义；\n而深层网络的图结构则更加专注于细化特征本身“比如鱼就是鱼，人就是人”\nThe pentagram is the center node, and the nodes with the same color are its neighbors\nTwo center nodes are visualized as drawing all the edges will be messy.\nWe can observe that our model can select the content-related nodes as the first order neighbors,\nIn the shallow layer, the neighbor nodes tend to be selected based on low-level and local features( such as color and texture)\nIn the deep layer, the neighbors of the center nodes are more semantic and belong to the same categor.\n以下是伪代码：\n","date":"2022-06-18T11:56:50+08:00","image":"https://sanbuphy.github.io/p/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBvision-gnn-an-image-is-worth-graph-of-nodes/image/image_AfAe9Ctp8A_hue88e56843ed6b1870c9b31fdca73cbf5_282168_120x120_fill_box_smart1_3.png","permalink":"https://sanbuphy.github.io/p/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBvision-gnn-an-image-is-worth-graph-of-nodes/","title":"论文阅读：Vision GNN: An Image is Worth Graph of Nodes"},{"content":"PA0比较简单，就不再重复说明。\nPA1的任务 从图上可以知道，我们的关键是要从Mon读取Mem和Reg的信息\nPA1.RTFSC apt-get install ccache which gcc 可以把gcc编译结果缓存，可跳过重复的编译过程\nmake -nB, 它会让 make程序以\u0026quot;只输出命令但不执行\u0026quot;的方式强制构建目标\nllvm推荐用PA里面说到的11先试试看，实在不行想要升级可参考：https://blog.csdn.net/weixin_44200757/article/details/122725577\n最简单的计算机称为\u0026quot;图灵机\u0026quot;(Turing Machine, TRM)\n结构上, TRM有存储器, 有PC, 有寄存器, 有加法器 工作方式上, TRM不断地重复以下过程: 从PC指示的存储器位置取出指令, 执行指令, 然后更新PC BIOS是固化在ROM/Flash中的, 它们都是非易失性的存储介质, BIOS中的内容不会因为断电而丢失.\n因此在真实的计算机系统中, 计算机启动后首先会把控制权交给BIOS, BIOS经过一系列初始化工作之后, 再从磁盘中将有意义的程序读入内存中执行. 对这个过程的模拟需要了解很多超出本课程范围的细节, 我们在PA中做了简化: 采取约定的方式让CPU直接从约定的内存位置开始执行.\n在GNU/Linux中, 你可以很容易得知操作系统在背后做了些什么. 键入 sudo dmesg, 就可以输出操作系统的启动日志, 操作系统的行为一览无余.\n你需要结合PA1 RTFSC内容来NEMU的框架代码.\n如果你不知道\u0026quot;怎么才算是看懂了框架代码\u0026quot;, 你可以先尝试进行后面的任务. 如果发现不知道如何下手, 再回来仔细阅读这一节\ncpu 先驱为CPU创造了一个特殊的计数器, 叫\u0026quot;程序计数器\u0026quot;(Program Counter, PC). 在x86中, 它有一个特殊的名字, 叫 EIP(Extended Instruction Pointer).\nwhile (1) { 从PC指示的存储器位置取出指令; 执行指令; 更新PC; } 第一项工作就是将一个内置的客户程序读入到内存中 先打开：nemu/src/isa/$ISA/init.c\nmonitor会调用 init_isa()函数(在 nemu/src/isa/$ISA/init.c中定义), 来进行一些ISA相关的初始化工作.\n第一项工作就是将一个内置的客户程序读入到内存中.\n内存是什么？C语言中我们就很自然地使用一个 uint8_t类型的数组来对内存进行模拟. NEMU默认为客户计算机提供128MB的物理内存(见 nemu/src/memory/paddr.c中定义的 pmem(如果找不到看看.h内有128*1024*1024) 需要将客户程序读入到内存的什么位置？我们需要一种方式让客户计算机的CPU知道客户程序的位置. 我们采取一种最简单的方式: 约定. 具体地, 我们让monitor直接把客户程序读入到一个固定的内存位置 init_isa()的第二项任务是初始化寄存器 CPU中, 寄存器是一个结构化特征较强的存储部件, 在C语言中我们就很自然地使用相应的结构体来描述CPU的寄存器结构. 不同ISA的寄存器结构也各不相同, 为此我们把寄存器结构体 CPU_state的定义放在 nemu/src/isa/$ISA/include/isa-def.h\n初始化寄存器的一个重要工作就是设置 cpu.pc的初值, 我们需要将它设置成刚才加载客户程序的内存位置, 这样就可以让CPU从我们约定的内存位置开始执行客户程序了. 对于mips32和riscv32, 它们的0号寄存器总是存放 0, 因此我们也需要对其进行初始化.\nCONFIG_MBASE：物理内存起始地址 RESET_VECTOR：客户程序读入的固定位置\n物理内存的起始地址 x86的物理内存是从0开始编址的, 但对于一些ISA来说却不是这样, 例如mips32和riscv32的物理地址均从 0x80000000开始. 因此对于mips32和riscv32, 其 CONFIG_MBASE将会被定义成 0x80000000. 将来CPU访问内存时, 我们会将CPU将要访问的内存地址映射到 pmem中的相应偏移位置, 这是通过 nemu/src/memory/paddr.c中的 guest_to_host()函数实现的. 例如如果mips32的CPU打算访问内存地址 0x80000000, 我们会让它最终访问 pmem[0], 从而可以正确访问客户程序的第一条指令. 这种机制有一个专门的名字, 叫地址映射, 在后续的PA中我们还会再遇到它.x86的物理内存是从0开始编址的, 但对于一些ISA来说却不是这样, 例如mips32和riscv32的物理地址均从0x80000000开始. 因此对于mips32和riscv32, 其CONFIG_MBASE将会被定义成0x8000000\nMonitor读入客户程序并对寄存器进行初始化后, 这时内存的布局如下:\npmem: CONFIG_MBASE RESET_VECTOR | | v v ----------------------------------------------- | | | | | guest prog | | | | ----------------------------------------------- ^ | pc NEMU返回到 init_monitor()函数中, 继续调用 load_img()函数 (在 nemu/src/monitor/monitor.c中定义). 这个函数会将一个有意义的客户程序从镜像文件读入到内存, 覆盖刚才的内置客户程序.\n如果运行NEMU的时候没有给出这个参数, NEMU将会运行内置客户程序.\n思考题1：-1参数 在 cmd_c()函数中, 调用 cpu_exec()的时候传入了参数 -1, 你知道这是什么意思吗?\n答:参数为uint64,无符号64位整型，-1表示取最大值（整数用补码表示，负数的补码为=反码+1，正数的补码就是其原码；负数的反码为符号位不变，数值位按位取反。-1的原码：1,000\u0026hellip;0001，因此，-1的补码为1,111\u0026hellip;111。）\n思考题2：谁来指示程序的结束? 在程序设计课上老师告诉你, 当程序执行到 main()函数返回处的时候, 程序就退出了, 你对此深信不疑. 但你是否怀疑过, 凭什么程序执行到 main()函数的返回处就结束了?\nmain()函数结束，如何再执行代码？\n使用 atexit() 函数，来执行相关的“ 清理 ”工作The function pointed by func is automatically called without arguments when the program terminates normally.A zero value is returned if the function was successfully registered. If it failed, a non-zero value is returned. 几种退出函数：https://blog.csdn.net/jinchaoh/article/details/50340743\nexit()函数用于在程序运行的过程中随时结束程序，其原型为： void exit(int state); exit的参数state是返回给操作系统或当前程序的调用程序，返回0表示程序正常结束，非0表示程序非正常结束。main函数结束时也会隐式地调用exit()函数。exit()函数运行时首先会执行由atexit()函数登记的函数，然后会做一些自身的清理工作，同时刷新所有输出流、关闭所有打开的流并且关闭通过标准I/O函数tmpfile()创建的临时文件。\natexit() 用于注册终止函数(即main执行结束后调用的函数)，其原型为： int atexit(void (*function)(void)); 很多时候我们需要在程序退出的时候做一些诸如释放资源的操作，但程序退出的方式有很多种，比如main()函数运行结束、在程序的某个地方用exit()结束程序、用户通过Ctrl+C或Ctrl+break操作来终止程序等等，因此需要有一种与程序退出方式无关的方法来进行程序退出时的必要处理。方法就是用atexit()函数来注册程序正常终止时要被调用的函数。\n额外思考：main是怎么开始的? http://wen00072.github.io/blog/2015/02/14/main-linux-whos-going-to-call-in-c-language/\n三个对调试有用的宏(在 nemu/include/debug.h中定义) Log()是 printf()的升级版, 专门用来输出调试信息, 同时还会输出使用 Log()所在的源文件, 行号和函数. 当输出的调试信息过多的时候, 可以很方便地定位到代码中的相关位置（非常好用！！！！非常推荐） Assert()是 assert()的升级版, 当测试条件为假时, 在assertion fail之前可以输出一些信息 panic()用于输出信息并结束程序, 相当于无条件的assertion fail 内存通过在 nemu/src/memory/paddr.c中定义的大数组 pmem来模拟.\n在客户程序运行的过程中, 总是使用 vaddr_read()和 vaddr_write() (在 nemu/src/memory/vaddr.c中定义)来访问模拟的内存.（这里已经告诉了你下面涉及问题的答案！）\nvaddr, paddr分别代表虚拟地址和物理地址.\nPA1.简易调试器 简易调试器(Simple Debugger, sdb)是NEMU中一项非常重要的基础设施.\n我们知道NEMU是一个用来执行其它客户程序的程序, 这意味着, NEMU可以随时了解客户程序执行的所有信息. 然而这些信息对外面的调试器(例如GDB)来说, 是不容易获取的. 例如在通过GDB调试NEMU的时候, 你将很难在NEMU中运行的客户程序中设置断点, 但对于NEMU来说, 这是一件不太困难的事情.\n为了提高调试的效率, 同时也作为熟悉框架代码的练习, 我们需要在monitor中实现一个具有如下功能的简易调试器:\n(1) 命令已实现 (2) 与GDB相比, 我们在这里做了简化, 更改了命令的格式 命令 格式 使用举例 说明 帮助(1) help help 打印命令的帮助信息 继续运行(1) c c 继续运行被暂停的程序 退出(1) q q 退出NEMU 单步执行 si [N] si 10 让程序单步执行N条指令后暂停执行,``当 N没有给出时, 缺省为 1 打印程序状态 info SUBCMD info rinfo w 打印寄存器状态``打印监视点信息 扫描内存(2) x N EXPR x 10 $esp 求出表达式EXPR的值, 将结果作为起始内存``地址, 以十六进制形式输出连续的 N个4字节 表达式求值 p EXPR p $eax + 1 求出表达式EXPR的值, EXPR支持的``运算请见调试中的表达式求值小节 设置监视点 w EXPR w *0x2000 当表达式EXPR的值发生变化时, 暂停程序执行 删除监视点 d N d 2 删除序号为N的监视点 你需要在实现一个功能之后对它进行充分的测试. 随着时间的推移, 发现同一个bug所需要的代价会越来越大.\n实现步骤：\n从键盘上读入命令后, NEMU需要解析该命令——利用框架代码调用单步执行——打印寄存器——扫描内存\n（NEMU默认会把单步执行的指令打印出来(这里面埋了一些坑, 你需要RTFSC看看指令是在哪里被打印的), 这样你就可以验证单步执行的效果了.）\n读入并解析 NEMU通过 readline库与用户交互\n解析命令的工作是通过一系列的字符串处理函数来完成的, 例如框架代码中的 strtok()、strlen(), strcpy()、sscanf()等\nreadline：（使用了系统库要记得-lreadline链接）\nstrtok:要注意两个参数，第二个参数会被他替换成\\0，第一个字符串读出后接下来的第一个参数就要用NULL替换\nstrtok不能保证字符串的完整，要保持字符串的完整可以用strchr和sscanf的组合。\n表达式的实现 关键：\n常见的operator需要匹配 留下两个冗余给指针解引用 这里我花了几天重构了（相当于重写）了一遍求解表达式的逻辑。大概消耗了一周。\n第一个难点在于如何优雅的把字符串保留到token[].str中，你需要搞明白什么是结构体数组与指针（之后的静态链表也会用到！\n第二个难点在于op匹配的过程中，需要如何给出op（优先级排列），这里参考了一下别人的算法（我自己的bug很多）采用了一个设计大到小覆盖的方法，能保证保留“最大”标识的符号作为op，（你从尾部开始扫描也行，换个方向覆盖符号罢了）。\n第三个难点在于如何优雅的检查括号，如果你只在p和q边界检查，容易出现(1+1)+(1+1)的错误，我尝试了很多很多办法，最后用了一个i+-并且判断会不会“还没读完i就变0了”来避免这个错误。\n第四个难点在于负数和指针的拦截，你需要在别的地方进行拦截，检查之前的符号。\n监视点的实现 监视点：实际上这个是一个“能改大小”的静态链表，不需要malloc，熟悉了链表操作实际上不难（我花时间手写了一下动态链表再看这儿结构体数组一开始还有点诧异）\n另一个关键是要理解static的奥义所在，实际上都是为了将这个链表隔离在该作用范围内不要被其他文件访问，所以所有的操作都要在sdb和watchpoint里进行，不要对外暴露变量，只需要暴露函数能够使得他被调用即可。这也是程序隔离的重要性所在（一开始我觉得麻烦，但减小耦合的角度来说这非常重要，要做到职责分离），所有的数据结构访问和操作都在链表的C文件中执行，也不要对外暴露；而CPU每次执行完后的检查也是通过调用链表C的头文件进行函数执行（直接执行），做到职责分离和隔离。至于包一个宏，这个通过RTFC多多尝试即可得到结果。\nReference 【重点】 ps:最好可以掌握一些常用的C字符串标准库，如strcpy strnpy\ngdb layout窗口 (其实也可以直接gdb xxx -tui)\nlayout：用于分割窗口，可以一边查看代码，一边测试。主要有以下几种用法： layout src：显示源代码窗口 layout asm：显示汇编窗口 layout regs：显示源代码/汇编和寄存器窗口 layout split：显示源代码和汇编窗口 layout next：显示下一个layout layout prev：显示上一个layout Ctrl + L：刷新窗口 Ctrl + x，再按1：单窗口模式，显示一个窗口 Ctrl + x，再按2：双窗口模式，显示两个窗口 Ctrl + x，再按a：回到传统模式，即退出layout，回到执行layout之前的调试窗口。\nGDB快捷键 100个gdb\n常见的命令：\n记住run和start的区别！\n如何打印变量的值？(print var)\n如何打印变量的地址？(print \u0026amp;var) 如何打印地址的数据值？(print *address) 如何查看当前运行的文件和行？(backtrace) 如何查看指定文件的代码？(list file:N) 如果程序是多文件的，怎样定位到指定文件的指定行或者函数？(list file:N) 如果循环次数很多，如何执行完当前的循环？(until)\n如何跳过不感兴趣的函数（n）\ngdb中跳入函数的命令是step，相当于Visual Studio中的快捷键F11， gdb中跳出函数的命令是finish，相当于Visual Studio中的快捷键Shift+F11，函数完整执行后返回\ngdb中还有一个直接返回的命令是return，它会跳过当前函数后面的语句直接返回，返回值可以自定义，紧跟在return命令后面即可\n进阶命令：\n如何打印内存？ gdb中使用“x”命令来打印内存的值，格式为“x/nfu addr”。含义为以 f格式打印从 addr开始的 n个长度单元为 u的内存值。参数具体含义如下： a）n：输出单元的个数。 b）f：是输出格式。比如 x是以16进制形式输出，o是以8进制形式输出,等等。 c）u：标明一个单元的长度。b是一个 byte，h是两个 byte（halfword），w是四个 byte（word），g是八个 byte（giant word）\n比如：以16进制格式打印数组前 a16个byte的值： x/16xb a\n如何打印堆栈信息？ 使用gdb调试程序时，可以使用“i frame”命令（i是 info命令缩写）显示函数堆栈帧信息。\n参考文档 余子濠 从mov指令到仙剑：通过NEMU构建简单完整的计算机系统 ","date":"2022-06-11T22:50:40+08:00","permalink":"https://sanbuphy.github.io/p/nju%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C-pa1%E7%AC%94%E8%AE%B0/","title":"NJU计算机课程基础实验 PA1笔记"},{"content":"如果想要了解更仔细地过程，建议看csapp或者《程序员的自我修养》\n最直接的编译过程 初始.c文件通过预处理器、编译器、汇编器、链接器得到最后的可执行程序（比如linux系统下的a.out）\nhello.i：hello.c经预处理生成的文本文件。\nhello.s：hello.i经编译生成的汇编语言文件。\nhello.o：hello.s经汇编生成的可重定位目标文件。\nhello：hello.o经链接生成的可执行目标文件。\n在经过不同处理阶段的程序到底是怎么样的呢？让我们用gcc分步调试即可：\n你可以使用这个命令获得所有输出：gcc -save-temps main.c –o main\n一、预处理过程 在预处理阶段，编译器主要完成了这几件事：\n去掉所有的注释\n展开所有的宏定义（也就是做字符替换）\n插入#include文件的内容\n处理所有的条件编译（形如#ifndef的语句，详见 条件编译\n如果想要获得.i的预处理文件，需要输入 gcc -E main.c -o main.i ，-E选项保留预处理器的输出文件，但默认输出到标准输出流，你需要-o指定一个输出文件。\n因为头文件可能相当大，如果源文件包括了多个头文件，那么它的预处理器输出可能会庞杂难读。使用-C选项会很有帮助，这个选项可以阻止预处理器删除源文件和头文件中的注释：gcc -E -C main.c -o main.c\n测试效果如下，我们能确实看到上述几件事情的发生：（可以使用cat main.i或者vim main.i查看结果）\n有关预编译，如果想知道更多信息，可以参考 预编译器\n标准输出流默认是显示器，但理论上通过控制stdout的实现来源dup可以修改成文件或者其他可写空间\n二、编译过程 编译能够将hello.i 文件编译生成汇编语言程序 hello.s，为之后的汇编过程做铺垫。汇编语言程序中的每条语句都以一种标准的文本格式确切地描述了一条低级机器语言指令，汇编语言为不同高级语言的不同编译器提供了通用的输出语言。如果想看懂他们，可以去看看csapp的第三章。\n使用gcc -S main.i -o main.s 或者 gcc -S main.c生成汇编程序，即可看到效果：\n如果你尝试不同代码，你会发现汇编代码逻辑比起源代码逻辑发生了简化甚至更换位置，这是因为编译器会自动对程序的汇编实现进行优化，编译器是很聪明的。但如果你想获得原汁原味结构的汇编代码，可以使用gcc -0g -E main.c获得符合结构的优化等级（如果要获得较好的优化一般需要把-0g改为-01或者-01） 三、汇编过程 接下来，汇编器将hello.s翻译成机器语言指令，把这些指令打包成一种叫做可重定位目标程序的格式，并将结果保存在目标文件main.o中。\n使用gcc -c main.s -o main.o或者gcc -c main.c得到main.o目标文件。main.o文件是一个二进制文件，它的字节编码是机器语言指令而不是字符，如果vim强制打开main.o文件，看到的将是一堆乱码：\n如果想看他的汇编代码，可以用反汇编器来查看它的编码：objdump –d main.o\n实际上，二进制文件也能直接改，在jyy操作系统课程中你能学到这种有趣的操作 四、链接过程 链接器（ld）负责将多个可重定位的目标文件（.o文件）合并为一个可执行文件，虽然前面已经得到了机器语言文件，但我们还需要把目标文件、操作系统的启动代码和用到的库文件进行组织得到最后的执行文件（比如printf就是从别的库文件来的）。\n通过链接过程将main.o变为可执行文件，使用gcc main.c -o main或者gcc main.c\n由于这里用到了其他文件的函数（实际上尝试实现了一个静态库，如果是单文件就按照前面的方法即可）需要使用gcc main.c get_minus.c -o run ，可以看到最后生成了run，使用./run即可看到结果：\n如果直接进行gcc main.c的操作，得到的将是a.out文件，用同样的方法可以运行得到结果。\n通过ls -l我们可以将.o文件与最后可执行文件进行大小比较，可以发现最后的执行文件大小还是大很多的。\n如果想用gdb进行调试，你需要这样对文件进行编译：gcc main.c -o main -g\n如果想进一步学习怎么生成自己的静态链接库与动态链接库，可以参考：静态链接库与动态链接库\nReference https://blog.csdn.net/Shrimp_millet/article/details/94574406\nhttps://zhuanlan.zhihu.com/p/307730265\nhttps://blog.csdn.net/u012184539/article/details/81348529\nhttps://www.runoob.com/cprogramming/c-examples.html\nhttps://wangjunstf.github.io/2021/09/30/jing-tai-ku-he-dong-tai-ku-zhi-zuo/\nhttps://www.runoob.com/cprogramming/c-functions.html\nhttp://c.biancheng.net/view/2375.html\n","date":"2022-05-18T13:24:37+08:00","permalink":"https://sanbuphy.github.io/p/c%E8%AF%AD%E8%A8%80%E7%BC%96%E8%AF%91%E8%BF%87%E7%A8%8B%E7%AE%80%E4%BB%8B/","title":"c语言编译过程简介"},{"content":"长话短说，直接贴图！ [部分收集自b站] 以下是图片及其对应生成输入（因为图片命名更改了格式，含有\u0026rsquo;_\u0026lsquo;字样，请自行处理一下或者写一个 str.replace()方法替换成空格,且吧末尾的200去除）\nA_beautiful_painting_of_a_romantic_and_elegant_wedding_at_sunset_A_bride_white_wedding_dress_A_church_by_the_sea_rose_beach_light_effect_Dream_Caspar_David_Friedrich_artstation_200 Light_effect_Dream_Galaxy_StarsGreg_Rutkowski_Unreal_engine_Artstation_Towering_waves_200 Splendid_colorful_fireworks_in_the_sky_desert_Dream_Karlsimon_Greg_Rutkowski_Unreal_Engine_James_Gurney_Artstation_200 The_mountains_follow_the_plains_and_the_river_flows_into_the_great_wildernessTrending_on_artstation_200 A_beautiful_painting_of_a_building_full_of_sakura_bridge_clouds_sunset_fairy_tale_Distant_town_light_effect_dream_Josan_Gonzalez_artstation_200 a_beautiful_painting_of_mysterious_hard_sci-fi_city_at_sunset_clouds_neon_light_Cyberpunk_Magnificent_Greg_Rutkowski_artstation_200 A_Moonlit_Night_On_The_Spring_River_Greg_Rutkowski_James_Gurney_Artstation_200 ps:你可能难以想象，他的英文出自《春江花月夜》↑\nThe_peach_blossom_lover_plants_peach_trees_in_days_fine_Greg_Rutkowski_James_Gurney_Artstation_200 ps:你可能难以想象，他的英文出自唐寅的《桃花庵歌》“桃花仙人种桃树” ↑\nA_Moonlit_Night_On_The_Spring_Riverromantic_In_the_morning_Greg_Rutkowski_James_Gurney_Artstation_160 ps:你可能难以想象，他的英文出自《春江花月夜》↑ Change_is_the_WayGreat_seas_have_turned_into_fieldsTrending_on_artstation_200 ps:你可能难以想象，他的英文出自【人间正道是沧桑】↑\nCherry_blossoms_grand_palaces_above_clouds_rivers_sunshine_dream_Greg_Rutkowski_James_Gurney_Artstation_200 Cherry_blossoms_village_river_sunshine_dream_Greg_Rutkowski_James_Gurney_Artstation_200 In_the_morning_light_some_ancient_Chinese_buildings_on_the_mountains_sakura_mysterious_and_serene_landscape_clouds_river_Ivan_Aivazovsky_artstation_200 ","date":"2022-05-12T22:25:38+08:00","image":"https://sanbuphy.github.io/p/disco-diffusion%E5%85%B3%E9%94%AE%E5%AD%97%E5%A4%A7%E8%B5%8F/cherry2_hud0ddbd73ac71be0ebba682dec347f5c6_597770_120x120_fill_box_smart1_3.png","permalink":"https://sanbuphy.github.io/p/disco-diffusion%E5%85%B3%E9%94%AE%E5%AD%97%E5%A4%A7%E8%B5%8F/","title":"Disco Diffusion关键字大赏"},{"content":"// TODO: //加入协程相关内容 // 资源安全性\n// 进程、线程间通信方式 // 如何捕获子线程异常\n简单理解进程和线程 什么是进程 一个任务就是一个进程，是操作系统资源分配的基本单位。\n例如打开浏览器，打开word，打开游戏、QQ等等，都是独立的任务，它们各自为一个或者多个进程。\n这里要注意的是，同一种任务打开多个，分别属于不同进程，例如chrome打开多个标签，实际上它创建了多个进程。 “运行”的程序才可以称为进程。未运行的程序仅仅是一些指令和数据的集合，并非进程。\n什么是线程 线程可以看作一个任务的各项子任务，是操作系统直接的执行单元。\n例如播放器，既要解码视频、也要解码音频，所以在进程下存在多线程。在一个进程下一定存在一个线程，可以称它为主线程。\n小结 操作系统创建进程时，会单独为每一个进程分配各自的资源，进程与进程之间相互隔离。进程在执行过程中拥有独立的内存单元，而多个线程共享内存。 可见，操作系统执行的粒度是线程，分配资源的粒度是进程，我们的多任务操作系统，在单核CPU上是在各个线程上不断切换而达到目的，而在多核CPU上则多个任务可以创建多个进程来完成，同时也可以创建多个线程来完成，线程是操作系统直接的执行单元。能同时执行多个线程任务。 值得注意的是，在python中，由于全局解释器锁的存在，线程并没有发挥并行计算的作用，而是提供了并发的能力。（只能在一个cpu核上运行）\n进程与线程的比较 进程的优缺点 多进程的优点是稳定性好，一个子进程崩溃了，不会影响主进程以及其余进程。 但是缺点是创建进程的代价非常大 ，因为操作系统要给每个进程分配固定的资源，并且，操作系统对进程的总数会有一定的限制，若进程过多，操作系统调度都会存在问题，会造成假死状态。。不过，进程与进程之间是完全隔离的，进程A崩溃了完全不会影响到进程B。\n线程的优缺点 多线程优点是效率较高一些，但是致命的缺点是任何一个线程崩溃都可能造成整个进程的崩溃，因为它们共享了进程的内存资源池，没有自己单独的内存地址空间，指针数据的错误可以导致任何同地址空间内其他线程的崩溃，包括进程。\n进一步理解进程和线程（可选） 进程 进程的组成 当一个程序被载入内存并成为一个进程后，它会占用一部分存储空间，此空间会分为 4 个区域： 这 4 个区域的作用分别是： 栈（Stack）：存储局部变量、函数参数等临时数据。 堆（Heap）：进程在执行期间可以动态申请这部分空间。 数据区（Data）：存储全局变量和静态变量。 文本区（Text）：存储进程要执行的机器指令代码。\n进程的生命周期 python中的GIL全局解释器锁 TODO:\n检查个人电脑的最大进程、线程数 不同电脑的配置状况决定了一个系统能够运行多少进程以及对应的线程数，简单粗暴的方法是用实例代码来检测到底能运行多少进程和线程：（一般情况下不要过于离谱即可） 不过需要注意的是，不同任务处理所需要占用的内存和cpu使用率是不同的，需要具体情况具体分析，但通常情况下的使用不会出现大问题（除非你考虑到数据共享安全性，想让一组线程执行完后再启动下一轮，那就要根据实际情况设计最大线程并加上线程锁；等到获取到的这些数据处理后才能继续处理下一轮数据；或者使用大小限定队列与线程池）\t多进程测试代码 首先，你可以用这个语句（linux与mac）进行直接查看:ubuntu\u0026gt; ps aux | wc -l,如果查询失败或者想要看到更直观的结果可以使用以下代码：\n#!/usr/bin/python import os import sys import re import threading import signal import time g_exit = 0 num = 0 def sig_process(sig, frame): global g_exit g_exit = 1 def sub_process(data): while not g_exit: time.sleep(1) print data def process(): num = int(sys.argv[1]) all_process = [] for i in range(num): try: pid = os.fork() except: pid = -1 if pid \u0026lt; 0: print \u0026#39;error in fork\u0026#39; all_process.append(-1) elif 0 == pid: sub_process(i) os._exit(0) else: all_process.append(pid) while not g_exit: time.sleep(100) for i in range(num): if -1 == all_process[i]: continue os.waitpid(all_process[i], 0) def main(): if len(sys.argv) != 2: print \u0026#39;wrong number parameter\u0026#39; return 0 signal.signal(signal.SIGINT, sig_process) process() if __name__ == \u0026#39;__main__\u0026#39;: main() 多线程测试代码\n#!/usr/bin/python import os import sys import re import threading import signal import time g_exit = 0 num = 0 def sig_process(sig, frame): global g_exit g_exit = 1 def sub_process(data): while not g_exit: time.sleep(1) print data def process(): num = int(sys.argv[1]) all_thread = [] for i in range(num): try: td = threading.Thread(target = sub_process, args=(i,)) td.start() except: all_thread.append(-1) continue all_thread.append(td) while not g_exit: time.sleep(100) for i in range(num): if isinstance(all_thread[i], int): continue all_thread[i].join() def main(): if len(sys.argv) != 2: print \u0026#39;wrong number parameter\u0026#39; return 0 signal.signal(signal.SIGINT, sig_process) process() if __name__ == \u0026#39;__main__\u0026#39;: main() Reference Python多线程与多进程学习\u0026mdash;-概念 操作系统，进程，线程 线程崩溃是否会造成进程崩溃 python编程（你的电脑能够执行多少线程和进程） python主线程捕获子线程异常 操作系统 ","date":"2022-04-24T19:23:03+08:00","permalink":"https://sanbuphy.github.io/p/python%E4%B8%AD%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A6%82%E5%BF%B5%E7%9A%84%E8%BF%9B%E9%98%B6%E6%8E%A2%E8%AE%A8/","title":"python中多进程、多线程概念的进阶探讨"},{"content":"待进一步完善\u0026hellip;龟速填坑中\n评价指标的基石 所有复杂问题都是简单问题的重复， 为了理解所有指标，首先需了解“四大天王”与“三大护法”\n四大天王——TP|FP TN|FN 我们认为positive代表了阳性（或者说正样本）， 而Negative代表了阴性（负样本)，那么在二分类中我们根据猜测的对错很容易排列出2x2种情况：\nTrue False Positive TP(猜对了阳) FP(猜错了阳) Negative TN(猜对了阴) FN(猜错了阴) 其中左半边表示真值和我的猜测一致（猜对了），右半边表示真值和我的猜测不一致（猜错了）；\n上半边表示猜测阳性的全体 $P$，下半边表示猜测阴性的全体$N$。\nTP+FN表示真值阳性的全体，TN+FP表示真值阴性的全体。\n三大护法——Pre、ACC、Recall 根据四大金刚，我们容易得出常见模型中的三个评价指标， (为什么不能只看一个呢？因为容易被“浮云遮望眼”)\nPre(Precision 精确率又称查准率) 精确和准确在中文上看起来是一个意思，但实际上有微小的区别； 我们可以通过投标的例子来理解什么是精确，什么是准确。 精确率是度量信噪的一种方式，是对偏差程度的反应（标准差大就不精确） 从上图可知，精确率高的数据其标准差较小，也就是“我投中了，投中的差别不大”;在二分类中或者说判断是否阳性中，我们关注的重点是在我对阳性的判断中，是否判断对了(存不存在错判阳性的偏差）；如果精确率高，就说明我预测阳性偏差小，阳性就是真的阳性，较少出差错。 总结来说，精确率高指的是“我对正例判断出差错（偏差）的情况怎么样？”，也就是： $$ Precision = \\frac{TP}{P} = \\frac{TP}{TP+FP} $$ 精确率越高，说明我对正例/阳性判断的偏差越小，也就是TP占总判断阳性中的比例越大。 这时候可能会有聪明的同学问了，那为什么我们不考虑对负例判断的偏差呢，比如构建一个TN/TN+FN的指标？ 其实是有的，一般的，Pre还有更深入的名字叫“positive predictive value (PPV)”，显然也有对应的“Negative predictive value (NPV) ” 只是因为负样本通常较少，正样本较多；所以把PPV作为一个更常用的指标，归为精确率。\nACC(Accuracy 准确率) 为什么说精准但“精确不一定准确呢”？\n你可以这么想，精密仪器显然是为了误差小，那精密仪器一定能得到准确结果吗？————答案是不一定，比如你没有调零!(做过大物实验的朋友都知道~) 没有调零就好像y=kx+b中多了一个b，也就是投标图像中的“整体偏移真值” （下图的上半部分） 虽然很精确，但很不准确！！ 左半侧更不准确，右半侧更准确 准确率更容易理解，准确率考虑的是更“全局”的结果是否正确， 也就是在我所有预测的结果中，我到底预测的“好不好”， 即： $$ Accuracy = \\frac{TP+TN}{所有预测} = \\frac{TP+TN}{TP+FP+TN+FN} $$\nRecall(召回率又称查全率) 顾名思义，查全的意思就是“我查的全不全”，我是否把所有的阳性覆盖到了（阳性全体为P），\n$$ Recall = \\frac{TP}{阳性全体}= \\frac{TP}{TP+FN} $$ 有时候查全率很高，但精确率很低。 比如我有3个阳性，97个阴性。我预测100个全为阳性（此时P=100且TP=3，FP=97），0个阴性；此时查全率为：3/3=100% ！\n但此时精确率为：3%。。。。。这显然是没有意义的。 有时候精确率很高，但查全率很低。 比如我还是有3个阳性，97个阴性。我刚好预测对某1个为阳性（此时P=1且TP=1，FP=0），99个阴性；此时精确率为：100% ！ 但此时查全率为：33.333%。。。。。这显然也是意义不大的。 查全率与精确率存在互逆关系\n我们能够隐约发现查全率和精确率的互逆关系，但究竟是为什么呢？ 仔细观察可以发现，Recall和Pre只在分母有差别，其中Recall的分母是TP+FN【不变量】，而Pre的分母是TP+FP【可变量】。\n为了提高Recall，我们需要增大TP，而分母不变； 但Pre中如果TP增加了FP也会跟着增加（我需要判断的东西变多了，精确率会下降，错误的概率会变大），分子的TP增加小于分母的TP+FP总体的增加。所以查全率和精确率是互逆的。\nF1、RPC、Roc、AUC 在充分了解了四大金刚与三大护法后，我们进一步来研究他们的衍生变体：\nReference 机器学习基础\u0026mdash;分类与检测的评价指标\u0026mdash;AP，mAP，PRC曲线 分类问题中的一些指标概念-Roc|AUC|Pre|Recall|ACC|AP|mAP|F1总结 分类器的ROC曲线及相关指标（ROC、AUC、ACC）详解 MCC — 机器学习中优于F1-score和accuracy的一个性能评价指标 Data Science in Medicine — Precision \u0026amp; Recall or Specificity \u0026amp; Sensitivity? ","date":"2022-04-12T20:53:41+08:00","permalink":"https://sanbuphy.github.io/p/%E8%AF%A6%E8%A7%A3%E6%9C%BA%E5%99%A8/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/","title":"详解机器/深度学习中常见评价指标"},{"content":"笔者因为要使用opencv c++版的需求，需要给家里的电脑配c/cpp的运行环境， 如果是Linux无脑Clion即可，windows上稍微有一些麻烦，附上全流程：\n【6月份回来看感到很搞笑，注：这是笔者刚开始玩c/cpp的纯粹青涩文章\u0026hellip;..】\n首先请按照这个博主的安装教程走一遍流程c++ c语言安装流程\n如果顺利的安装好环境，接下来就是运行环节，首先随便新建一个C或者cpp文件，可参考； C语言的版本：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;windows.h\u0026gt; int main() { printf(\u0026#34;Hello World\\n\u0026#34;); system(\u0026#34;pause\u0026#34;); return 0; } C++的版本：\n#include \u0026lt;iostream\u0026gt; using namespace std; int main() { cout \u0026lt;\u0026lt; \u0026#34;Hello Vscode\u0026#34; \u0026lt;\u0026lt; endl; return 0; } 接下来就是最重要的部分，我们有两种办法编译好文件运行， 第一种办法（直接编译）： 在终端中进入对应文件夹，输入gcc xxx.c 或者g++ xxxx.cpp 即可将文件编译成exe，然后直接终端中输入exe文件名字即可查看效果！ 如果你想运行后直接看跳出的结果，可以按照开头知乎链接的答主方法操作。\n第二种方法（间接编译）：我们要做两件事：\n首先在上面菜单栏找到终端，选择配置生成任务，选择对应的文件（gcc或者g++ 有可能只显示c++ 但点进去后会出现gcc) 左侧找到运行与调试在上面框框中点开，然后选择工作区对应的文件夹添加配置（会生成.vscode文件夹，内部就是配置文件！），或者直接运行中找到添加配置，然后同样找到对应gcc g++即可（gcc或者g++ 有可能只显示c++ 但点进去后会出现gcc) 如果第二种方法配置出现问题了（launch或者task），你可以把.vscode文件夹删除，重新配置即可。\n","date":"2022-03-20T16:28:01+08:00","permalink":"https://sanbuphy.github.io/p/c/c-%E5%9C%A8windows%E4%B8%8B%E7%9A%84%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E6%B5%81%E7%A8%8B%E5%92%8C%E8%BF%90%E8%A1%8C%E6%96%B9%E6%B3%95/","title":"C/C++在Windows下的环境配置流程和运行方法"},{"content":"本文源于和大学时期舍友分享毒打经验(被毒打)\n找工作的怪象与形成的本源【最重要的】 产业分布——我该去哪？ 一线：互联网企业、高新技术企业 ———— 房价很高 容不下肉身 二三线：事业单位、国企、各种你懂编制（研究所、老师。。。。。） —————— 房价不算特别高 可能容不下灵魂 建议对自己想去的地方有个目的性，趁早考虑。\n学校和社会生活的差距 思想上的准备落后 1. 考公务员 2. 当老师 3. 事业单位 。。。。。 其实是对找工作没有概念 【学校和社会生活的差距导致围城】 社会上温情确实更少一些 1.抱大腿？大腿你遇不到，小腿不想理你 2.跨部门的事情，基本是踢皮球 3. *在外面很难找男/女朋友* 1. 考虑现实 2.考虑远近 中心思想：你要真正断奶，为自己负责，为自己选择（来自家里人的建议，来自老师的建议，来自同学的建议）。\n一个毛病————追求生活的最优解 ——————不可能！ 生活其实没有最优解，只有不同阶段的局部最优 ——————追随心的声音\n问题：我们应该用现在的回报去估计将来的收入曲线吗？ 预测基本不可能——————追随心的声音\n怎么更好的获得回报/获得资料(工作岗位的需求) 假设：现在我要去追求二线的某某工作： 1、我要转行吗？做什么？怎么做？ 我是电子信息硕士生，不转行\n2、我要做本行吗？做什么？怎么做？\n第一步：信息获取 【获得信息是第一步的关键！】\n我导师研究的是什么，我的老师有什么资源——（学术的资源、人脉的资源（公司的联系）） 【我能获得什么？】 获得对应的学识 获得对应公司的内推机会 获得学长学姐的信息 了解公司的内部好坏和福利（比如宁德时代的一些黑历史） 学长学姐和历年就业去向表————找出最优秀的学长学姐 问他们是怎么过的，怎么努力的，怎么去获取资源的（可以请咖啡或者约面谈或者邮件或者微信，相信同校的学长学姐！） 第二步：选择方向（避免最坏的情况，追求好一些的情况，但不存在最好的情况） 电气工程师？做算法工程师？去国家电网？还是去当小学老师？\n给出可能的几个方向 求交集 各种找工作的网站 按照 1、关键词 2、城市 遍历每一家公司的招工需求—————获得待遇情况，或者是去搜索待遇曲线以及和学长学姐信息对比。 第三步：根据方向 努力！获取信息后努力！ 【根据社招的要求，去做校招，千万不要沦落到社招！】 【现在的国情就是校招yyds，应届生yyds，请搞清楚应届生有什么福利（落户政策，人才引进)!!!!!!!!!!!!!!!!!!!!】 【必须利用好应届生的身份，否则会后悔一辈子】\n自己做个文档（工作方需要什么经历，看重学生的什么素质，招工需要什么技术栈(ASIC\\会验证会测试\\会FPGA\\会python使用EDA验证等） 举个例子： 岗位职责： 1、深入了解ASIC设计及验证流程，可根据芯片设计规格书，编写验证需求，可搭建验证平台并完成验证用例和回归; 2、执行验证计划，编写验证用例，开展递归测试，完成问题的调试和修复； 3、负责芯片IP集成验证以及IP模块验证，有高速接口验证经验者优先; 4、负责SOC系统级验证，并收集、分析和提高验证覆盖率; 5、熟悉FPGA芯片架构，可协助测试工程师完成芯片测试工作。 任职要求： 1、微电子电子工程通信计算机等相关专业硕士及以上学历； 2、熟悉system *** 、OVMUVM等能独立搭建可重用的系统验证平台; 3、熟练掌握perl 、python等脚本语言熟练使用EDA验证工具(如VCS、NCsim等)； 工作认真、积极主动、严谨、敬业、有较强的沟通能力与团队组织协调能力。福利待遇：国企福利，六险二金，做五休二，餐费补助，交通补助，全勤奖，项目津贴，年终奖，健身房，羽乒馆等\n针对技术栈去努力提高，顺便找志同道合的人【群友、交流群、学长学姐（拉学弟学妹下水）】\n第四步：社交同样重要！ 学长学姐 交流群 群友。。。。。 为什么要实习 面试造火箭——实际上拧螺丝 【台积电的例子】\n如果在小厂。。。你可能要一个人干三个人的活 如果在大厂。。。拧螺丝！ 公司需要的是啥（什么价值？需要你产生什么价值，给公司带来什么，自己的可替代性强不强）\n弥补学校与社会的鸿沟\n攒经验，刷履历\n向小朱学习！！！\n舔狗的艺术 （找一切机会向优秀的大佬们学习）\n比起以后不能多请老婆喝一杯奶茶的委屈，比起以后不能多给儿子买一根棒棒糖的委屈，自己舔狗又有什么委屈的？ 说不定就舔到了呢？ 都是小概率事件，值得尝试！ 不被理睬才是最正常的现象，如果有就带上感谢！没有也没关系，这很正常！ 面子的问题怎么解决————反正几十年后大家都入土了，没什么好怕的 战胜遗忘的方法： 复习 复习 复习 （推荐一款app memory helper 根据遗忘曲线安排你应该什么时候复习什么 免费！） 干中学为什么忘得慢？ 因为你天天都得干 做这些的目的是。。。？ 青春一去不复返！ 获得更好的报酬 看到更好的自己 活在短暂未来的自己 比起炒股，你能做好的也就是这些了 ","date":"2022-02-21T21:18:24+08:00","permalink":"https://sanbuphy.github.io/p/%E8%80%83%E7%A0%94%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/","title":"考研，找工作的那些事"},{"content":"中心思想：遇事不决，降低版本 （numpy,paddlepaddle,opencv）\n以防万一的操作 1.安装PyQt5\nsudo apt-get install python3-pyqt5\n2.安装qt-designer\nsudo apt-get install qt5-default qttools5-dev-tools\n#命令行输入designer可测试是否安装成功\n推荐安装流程（从新建虚拟环境到安装一条龙服务） 请严格按照顺序！\n#[装错了想卸载重装，把install改成uninstall 不要加包括-i在内后面的信息即可]\n#创建虚拟环境\nconda create -n 改成你的虚拟环境名字 python=3.7 【3.7别打3.9】\n#进入虚拟环境\nconda activate 改成刚才你的虚拟环境名字\n#装坏了想炸掉虚拟环境（慎重别打错了）\nconda remove -n 你的虚拟环境名字 --all\n#此时你能看到终端左侧显示环境名，接下来安装各类程序\n#注：这里采用百度源作为示范，你也可以使用清华源：\n-i https://pypi.tuna.tsinghua.edu.cn/simple\n#升级pip\npip install --upgrade pip -i https://mirror.baidu.com/pypi/simple\t#以防万一的操作\npip install qtpy -i https://mirror.baidu.com/pypi/simple pip install pyqt5 -i https://mirror.baidu.com/pypi/simple #安装paddle github主页面 【这里采用的是cpu，如果要gpu详细安装过程参考gpu怎么看】\n（如果出现问题可以在paddlepaddle后面加上==2.1.0安装旧版本）\npython -m pip install paddlepaddle -i https://mirror.baidu.com/pypi/simple\n#安装PPOCRLabel（OCR） github主页面\npip install PPOCRLabel -i https://mirror.baidu.com/pypi/simple\npip install trash-cli -i https://mirror.baidu.com/pypi/simple\n#安装EISeg（图像处理） github主页面\n​\tpip install eiseg -i https://mirror.baidu.com/pypi/simple #只输入这个就行\n​\tpip install paddleseg -i https://mirror.baidu.com/pypi/simple #【最后】安装旧版本opencv（如果装了请先卸载）\npip install opencv-python==4.2.0.32 -i https://mirror.baidu.com/pypi/simple\n#接着测试ocr和eiseg：首先输入PPOCRLabel --lang ch\n#如果此时出现一段加载过程，最后出现界面，就说明你安装成功了！！\n#再次输入： eiseg 这时候大概率已经成功打开！\n倒霉人请看这 如果eiseg打开不成功可以尝试曲线方案（先安装这些依赖库）：\n(pip不成功就改成conda)\n#首先先把paddleseg的整个项目clone到本地 （以下安装还打不开可以这么做）\nconda install gdal\npip install qtpy\npip instal pyqt5\npip install easydict\npip install scikit-image\n这时候再进入即可！ （如果你还是打不开，就clone后进入eiseg子文件，按照这个帖子运行exe.py\t）\n最后使用conda deactivate退出虚拟环境！！\n","date":"2022-02-19T20:45:40+08:00","permalink":"https://sanbuphy.github.io/p/%E5%AE%8C%E7%BE%8E%E5%AE%89%E8%A3%85paddleppocrlabeleiseglinux/","title":"完美安装paddle、PPOCRLabel、eiseg(linux)"},{"content":"备注:我正在写一份目标检测\u0026amp;图像异常检测的综述slides，如果有兴趣可以等我出！欢迎邮件催更提建议：physicoada@gmail.com\nopencv基础 推荐参考： 基于Python的Opencv全系列速成课 3天建立计算机视觉移动应用程序-支持iOS与Android 无人机编程与Python教学\n项目地址：https://github.com/jasmcaus/opencv-course\n几个大型综述 Object Detection in 20 Years: A Survey 相关笔记：https://zhuanlan.zhihu.com/p/192362333\n综述：目标检测二十年（2001-2021） 目标检测近5年发展历程概述，从R-CNN到RFBNet（2013\u0026ndash;2018） (韩国人整的) 目标检测：Anchor-Free时代 - 陀飞轮的文章 - 知乎 https://zhuanlan.zhihu.com/p/62103812 CVPR 2021 论文大盘点-目标检测篇 - 我爱计算机视觉的文章 - 知乎 https://zhuanlan.zhihu.com/p/387510116 目标检测的精进路径 - mileistone的文章 - 知乎 https://zhuanlan.zhihu.com/p/266648028 目标检测入门，看这篇就够了（上） - 最刚烈的文章 - 知乎 https://zhuanlan.zhihu.com/p/60120331 国内做深度学习目标检测的有哪些大牛和厉害的课题组？ - Amusi的回答 - 知乎 https://www.zhihu.com/question/330390445/answer/723973941 ICCV 2021 结果出炉！最新200篇ICCV2021论文分方向汇总（更新中） https://zhuanlan.zhihu.com/p/392575669\nhttps://zhuanlan.zhihu.com/p/354043252\n7.CVPR2021论文分方向盘点 https://github.com/extreme-assistant/CVPR2021-Paper-Code-Interpretation#7\n一文看尽 27 篇 CVPR2021 2D 目标检测论文 https://mp.weixin.qq.com/s/Ho7qtrpF9FhHGaamkQo6Lw CVPR 2020 论文大盘点-目标检测篇\nhttps://bbs.cvmart.net/articles/2732\n其他 《目标检测》-第24章-YOLO系列的又一集大成者：YOLOX！https://zhuanlan.zhihu.com/p/391396921 目标检测可以先从成熟框架开始上手，比如mmdetection和detectron2。 如果基础。。。。。。目标检测该怎么学呀，目前研一，老师啥也不会，感觉毕不了业了？ - 小小将的回答 - 知乎 https://www.zhihu.com/question/510784176/answer/2305603811 系统地学习目标检测可以遵从下面的学习路线： 1.学习经典工作。经典工作包括RCNN系列（RCNN、Fast RCNN、Faster RCNN），宏观上可以学习到什么是目标检测、目标检测是做什么的，微观上可以学习到诸如Region Proposal Network（后续one-stage工作的基础）、Anchor box等基础技术。这个系列后来被划定为“two-stage”工作，检测精度好、速度要慢一些。随后，再学习早期的YOLO系列工作（YOLOv1、YOLOv2），宏观上可以学习到什么是one-stage目标检测方法、如何进行端到端的训练和推理，同时，学习SSD，可以初次接触到多级检测方法——使用更多的特征图去检测不同大小的物体。最后，学习FPN、YOLOv3以及RetinaNet（Focal loss），掌握当下主流检测框架“分而治之”方法。学习玩这些经典工作，最好能从中挑选出一至两个工作，进行复现，那么，目标检测就入门了。目标检测该怎么学呀，目前研一，老师啥也不会，感觉毕不了业了？ - Kissrabbit的回答 - 知乎 https://www.zhihu.com/question/510784176/answer/2305881442 目标检测（Object Detection）入门概要https://blog.csdn.net/f290131665/article/details/81012556 Reference 目标检测位置回归损失函数整理 目标检测回归损失函数简介：SmoothL1/IoU/GIoU/DIoU/CIoU Loss 边框回归(Bounding Box Regression)详解 Faster RCNN 中检测框位置回归是怎么做的 目标检测（1）-Selective Search 第三十三节，目标检测之选择性搜索-Selective Search Object Detection\u0026ndash;RCNN,SPPNet,Fast RCNN，FasterRCNN论文详解 什么是anchor-based 和anchor free？ ","date":"2022-02-08T15:28:17+08:00","permalink":"https://sanbuphy.github.io/p/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99%E6%B1%87%E6%80%BB/","title":"目标检测相关资料汇总"},{"content":"todo:https://www.cnblogs.com/charlotte77/p/5629865.html TODO:https://blog.csdn.net/Serins/article/details/121508468 TODO:https://www.bilibili.com/video/BV16x411V7Qg?spm_id_from=333.337.search-card.all.click\n在介绍具体的算法之前，我们得先认识一下神经网络以及为什么要构造这样的神经网络。 注，如果你对神经网络的发展史感兴趣，可参考神经网络浅讲：从神经元到深度学习\n神经网络基础 首先，我们知道人的神经网络是由神经元组成的，每个神经元与其他神经元相连。当某个神经元 “兴奋”时, 就会向相连的神经元发送化学物质，改变这些神经元内的电位；如果某神经元的电位超过了一个“阈值” ( threshold), 那么它就会被激活，即 “兴奋” 起来，接着向向其他神经元发送化学物质。 我们可以把神经元抽象成“神经单元”，即从单纯的输入0或1，阶跃函数型激活模式，输出0或1（即点火）的生物模型；变为允许输入任何模型框架内数值，自选激活函数且将结果转化为兴奋度的一般模型。 一般的，我们常用sigmoid函数作为激活函数，如果你想了解其他激活函数，可以自行搜索（网络上真的很多）： MP神经元模型 by：周志华-机器学习 常见激活函数 by：周志华-机器学习 由上可知，神经单元可以拆解为三大要素： $$ \\text{输入：} z=w_1x_1+\\cdots +w_nx_n+b\\cdot 1 \\\\ \\text{输出：} a=f\\left( z \\right) \\\\ \\text{激活函数：}f\\left( z \\right) =\\frac{1}{1+e^{-z}} $$ 其中b为偏置（为了形式美观，我们令阈值 $ \\theta = -b $ ），b·1的意思是常数1作为b对应的输入值（这样可以在之后将等式写成更美观的矩阵，类似多元回归时把常数放入矩阵的操作） 有了神经单元，把他们连接后就形成了神经网络（不同层的作用将在下部分给出） 阶层型神经网络 by：深度学习的数学 神经网络的运作原理 假设，你是一只爱吃“0”与“1”图样猫粮且非常挑食的小猫，出于懒惰，你想让计算机帮自己把这两类图案的猫粮完全区分。在以前，我们学过了分类法的线性回归(逻辑回归)，单纯的二维数据点分类不是件难事，但当我们遇到图像后该怎么办呢？为了方便，我们需要引入上述的神经网络。 为了引入神经网络，首先需要对猫粮图案处理成计算机可识别的内容，我们可以这样进行编号：（举例图案为4x3的格子） 将猫粮的0/1图案使用格子划分 其中编号代表有多少个信号源输入，信号输入的大小可以根据黑白设定，给出相应的0/1。（比如黑格子给神经元1的输入，白格子为0的输入） 将图像信息输入神经网络 在这里为了简化，我们只有简单的三层，一层输入，一层隐藏层（你可以理解为进一步处理数据），一层输出（用于判断结果是0还是1）。我们把它称为两层神经网络（有些地方觉得输入层需要计入，但在此我们采用“因为输入层不活动只是输入”的观点，将输入层排除在层数计算外） 有了数据输入，接下来便需要进一步认识神经单元的符号语言，从而理解数据在神经网络中是怎么传导的。（此处友情建议复习小节一的神经单元三大要素） 神经单元的符号语言 如何理解这套符号呢？如图所示，“我们现在所研究的”对象是第L层的第j个神经单元，而他前一层的神经网络即为L-1层，且我们设前一层神经单元的标号为i。根据这套符号以及我们前面学到的神经单元三大要素，我们知道了第L层第j个神经单元的输入为 $ \\mathrm{z}_{j}^{l} $，输出为 $ \\mathrm{a}_{j}^{l} $ ,其中b为偏置，且L-1层第i个神经单元对L层第j个神经单元的影响权重为 $\\mathrm{w}_{ji}^{l}$，激活函数负责把神经单元的“左半边”变成右半边的输出。（注，有些地方权重编号的ji可能互换为ij，但不影响最后结果）\n有了神经网络，我们自然想到它到底有什么用？让我们回望初心——分类，我们的目的是通过模型对样本进行分类；操作是通过对训练集的学习，将某种参数决定下的模型预测值（某种特征）与对应的现实特征比较，让现实和预测的差别尽量小，从而实现分类的效果。而神经网络也是如此，决定分类结果的是输出层，我们可以设输出层（参考上面出现的两层神经网络）的第一个神经单元的输出值 $a_1^3$ 在图样为1的时候接近1（现实目标为1），第二个神经单元的输出值 $a_2^3$在图样为0的时候接近1（显示目标为0），即为：（注意，值为1表示的是神经单元“兴奋”）\n为什么需要梯度下降法 前向传播原理 反向传播原理 一般化处理 浅析西瓜书中的BP算法 Reference 温故知新——前向传播算法和反向传播算法（BP算法）及其推导 反向传播算法详细推导 深度学习之反向传播算法 上/下 Part 3 ver 0.9 beta 《深度学习的数学》 涌井良幸 涌井贞美 《机器学习 Machine Learning》 周志华 ","date":"2022-01-29T16:18:00+08:00","image":"https://sanbuphy.github.io/p/%E5%B0%8F%E7%8C%AB%E4%B9%9F%E8%83%BD%E7%9C%8B%E6%87%82%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/jeff-rodgers-DaPabnoYMKc-unsplash_hu994d601531656c23f7e611d455c8d878_8153127_120x120_fill_q75_box_smart1.jpg","permalink":"https://sanbuphy.github.io/p/%E5%B0%8F%E7%8C%AB%E4%B9%9F%E8%83%BD%E7%9C%8B%E6%87%82%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/","title":"小猫也能看懂的反向传播算法"},{"content":"首先，我们需要认识什么是信息量与信息熵:\n自信息量 通常自信息可以从两个方面来理解:\n自信息是事件发生前,事件发生的不确定性。 自信息表示事件发生后,事件所包含的信息量。 (比如你看到这，会想问作者也许不是一只猫而是人类————那我当然不是猫，这就没有不确定性可言，没有什么信息量；如果有一天我真的是猫了，那便是大新闻了！！) 自然而然，我们会想到所谓信息量应当与概率有关，且应该可以加合（两个事件发生时带来的信息量应该是分别发生时的和），也就是满足以下特质：\n$f\\left( P \\right) \u0026gt;0 \\; \\; \\; \\; P\\left( x \\right) \\in \\left( 0,1 \\right) $ $f\\left( P_A·P_B \\right) =f\\left( P_A \\right) +f\\left( P_B \\right) $ $f\\left( 1 \\right) =0$ 事件发生概率越大，自信息量越小 此时我们可以才想到对数会满足这样的性质，于是可以给出：$I\\left( x \\right) =-\\log \\left( P\\left( x \\right) \\right) $ 因为在计算机领域中习惯用二进制，所以我们通常以2为底，这样自信息量的单位就为比特bit,——即二进制数的一位包含的信息或2个选项中特别指定1个的需要信息量。而机器学习中常选择以e为底，单位为奈特nats 你可以通过以下例题来更好的理解自信息量： 以2为底的对数符号lb 信息熵 接下来，我们将进一步研究什么是信息熵，在前面我们学会了如何衡量一个事件的不确定性，但一个随机变量可能包含的多个事件，我们该如何对这个 随机变量的不确定性 进行刻画呢？ 我们会自然想到求出所有事件的信息量期望，且熵越大，事件的不确定性越强，当满足均匀分布时熵最大(有约束情况下要额外考虑，一阶矩二阶矩不同时的最大熵分布不同，详情可参考最大熵原理）；如果熵值小，证明某个事件发生的概率比较大，随机变量取某个值的概率大，不确定性就小了。(另外，信息熵也可以理解为解除信源不确定性所需要的信息量) 于是我们给出： (其中规定)$0\\log 0=0$ $$ H\\left( x \\right) =-\\sum_{i=1}^n{p\\left( x_i \\right) \\log \\left( p\\left( x_i \\right) \\right)} $$ 我们可以验证，当n个事件满足等概率分布时其中当结果为logn（n为总数）信息熵达到最大值。 另外可以给出条件熵(你可以运用条件概率辅助理解)： $$ H\\left( Y|X \\right) =-\\sum_x{\\sum_y{p\\left( xy \\right) \\log P\\left( y|x \\right) =\\sum_x{-\\sum_y{P\\left( y|x \\right) \\log P\\left( x \\right) =\\sum_x{P\\left( x \\right) H\\left( Y|x \\right)}}}}} $$\n相对熵 如果我们对于同一个随机变量x有两个单独的概率分布P(x) 和 Q(x)，我们可以使用KL散度（Kullback-Leibler (KL) divergence）或者叫相对熵来衡量这两个分布的差异情况，其中p对q的相对熵写作(在机器学习中，我们可以把P(x)看作真实分布，而Q(x)作为预测的分布)： $$ D_{KL}\\left(p||q \\right) =\\sum_x{p\\left( x \\right) \\log \\frac{p\\left( x \\right)}{q\\left( x \\right)}=E_{p\\left( x \\right)}\\log \\frac{p\\left( x \\right)}{q\\left( x \\right)}} $$ 同时KL散度还满足以下条件： $$ D_{KL}\\left(p||q \\right) \\ne D_{KL}(q||p) \\\\ D_{KL}\\left( p||q\\right) \\geqslant 0 $$ 对于第一个式子，我们可以借助以下内容理解： by Deep Learning.Ian Goodfellow and Yoshua Bengio and Aaron Courville 用比较通俗的话来说，让我们回到公式之中，且注意到P(x)作为真实分布，Q(x)作为预测的分布；\n$$ D_{KL}\\left( p||q \\right) =E_{p\\left( x \\right)}\\log \\frac{p\\left( x \\right)}{q\\left( x \\right)} $$\n当第一种情况，如果P(x)是较大的，那么q(x)也应该较大来保证相对熵最小化；如果P(x)是较小的，那实际上q(x)的大小对相对熵影响不大；所以我们只需要特别注意前者的情况。此时在看图你就可以更加理解了。 $$ D_{KL}\\left( q||p \\right) =E_{q\\left( x \\right)}\\log \\frac{q\\left( x \\right)}{p\\left( x \\right)} $$\n当第二种情况，很显然会与第一种情况相反，如果P(x)是较小的，那么q(x)也应该较小来保证相对熵最小化————这就是为什么说图中提到概率小的地方比较重要，而q(x)较大的时候就影响不大了。 交叉熵 接下来我们要了解常用的一种更常用的熵————交叉熵，由前面学到的相对熵可以进一步推导：\n$$ \\begin{aligned} D_{KL}\\left( p||q \\right) \u0026amp;=\\sum_{i=1}^n{p\\left( x_{\\mathrm{i}} \\right) \\log \\left( \\frac{p\\left( x_i \\right)}{q\\left( x_i \\right)} \\right)}\\\\ \\mathrm{ }\u0026amp;=\\sum_{i=1}^n{p\\left( x_i \\right) \\log \\left( p\\left( x_i \\right) \\right)}-\\sum_{i=1}^n{p\\left( x_i \\right)}\\log \\left( q\\left( x_i \\right) \\right)\\\\ \u0026amp;=-H\\left( p \\right) -\\sum_{i=1}^n{p\\left( x_i \\right)}\\log \\left( q\\left( x_i \\right) \\right)\\ \\end{aligned} $$\n其中第一项我们可通过推导得知是针对真实分布概率p(x)的信息熵，而后一项我们定义为交叉熵； $$ H\\left( p,q \\right) =-\\sum_{i=1}^n{p\\left( x_i \\right)}\\log \\left( q\\left( x_i \\right) \\right) $$ 交叉熵可以理解为，消除体系不确定性所需要付出的努力大小。\n交叉熵与极大似然估计的联系 由于真实分布的信息熵是确定的，在优化过程中（最小化相对熵），我们可以把他忽略，只看交叉熵的部分。此外，最小化交叉熵其实与极大似然估计是等价的，具体证明如下：（参考Deep Learning.Ian Goodfellow and Yoshua Bengio and Aaron Courville） 我们考虑一组含有m个样本的数据集$\\mathbf{X}=({ x^{(1)},\\cdots ,x^{(m)} }) $,此时可以定义 $ \\theta $ 的极大似然为(其中P为模型的联合概率)：(如果你不懂argmax是什么意思可以参考argmax科普) $$ \\begin{aligned} \\mathbf{\\theta }_{ML}\u0026amp;=\\underset{\\theta}{\\mathrm{argmax}}P_{model}\\left( \\mathbf{X};\\theta \\right)\\\\ \\mathrm{ }\u0026amp;=\\underset{\\theta}{\\mathrm{argmax}}\\prod_{i=1}^m{P_{model}\\left( \\boldsymbol{x}^{\\left( i \\right)};\\theta \\right)} \\end{aligned} $$ 由于乘积不好计算，我们可以取log将他转换为加和形式，取最值时的参数不变；且可以乘上不影响结果的 $ \\frac{1}{m} $。 $$ \\begin{aligned} \\mathbf{\\theta }_{ML}\u0026amp;=\\underset{\\theta}{\\mathrm{argmax}}\\sum_{i=1}^m \\mathrm{log} {P_{model}\\left( \\boldsymbol{x}^{\\left( i \\right)};\\theta \\right)}\\\\ \\mathrm{ }\u0026amp;=\\underset{\\theta}{\\mathrm{argmax}}\\frac{1}{m}\\sum_{i=1}^m \\mathrm{log} {P_{model}\\left( \\boldsymbol{x}^{\\left( i \\right)};\\theta \\right)} \\end{aligned} $$ 由大数定律可知（算术平均值依概率收敛于期望）： $$ \\frac{1}{m}\\sum_{i=1}^m{X_i\\longrightarrow} \\mu $$ 可以将原式进一步化为： $$ \\begin{aligned} \\mathbf{\\theta }_{ML}\u0026amp;=\\underset{\\theta}{\\mathrm{arg}\\max}\\mathbb{E}_{\\mathbf{x}~\\hat{p}_{data}}\\log P_{model}\\left( \\boldsymbol{x};\\boldsymbol{\\theta } \\right)\\\\ \u0026amp;=\\underset{\\theta}{\\mathrm{arg}\\max}\\sum_x{p\\left( x \\right) \\log q\\left( x \\right)}\\\\ \u0026amp;=\\underset{\\theta}{\\mathrm{arg}\\min}\\left[ -\\sum_x{p\\left( x \\right) \\log q\\left( x \\right)} \\right]\\\\ \\end{aligned} $$ Bravo!!! 此时你惊喜的发现这就是我们前面推导得到的交叉熵公式，至此，对于真实分布和模型分布，我们明白了MLE方法（让似然最大化）等价于两者间交叉熵的最小化。好奇的你也许想问“MLE与KL散度也是共通的吗？”————这个问题你可以自己试试看，就用上式类似办法加常数即可！\nReference 一文搞懂交叉熵损失 详解机器学习中的熵、条件熵、相对熵和交叉熵 信息论基础 数字世界逼近现实世界——浅谈分布近似与最大似然估计 ","date":"2022-01-22T22:34:11+08:00","image":"https://sanbuphy.github.io/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BF%A1%E6%81%AF%E8%AE%BA%E5%9F%BA%E7%A1%80/michael-sum-LEpfefQf4rU-unsplash_hu05be89c43654817bfc3a6d1d1f1925fe_2269278_120x120_fill_q75_box_smart1.jpg","permalink":"https://sanbuphy.github.io/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BF%A1%E6%81%AF%E8%AE%BA%E5%9F%BA%E7%A1%80/","title":"机器学习中的信息论基础"},{"content":"本文为个人对西瓜书不成熟的一些理解和资料整理，欢迎批评指出意见，谢谢！(可邮箱联系physicoada@gmail.com)\n西瓜书章节三 线性模型 文字版浓缩可参考：周志华机器学习笔记 by:Vay-keen\n简略而言，本章主要涉及到三大块内容\n线性回归及极大似然估计 对数几率回归及交叉熵思想 二分类线性判别分析 数学基础 极大似然估计 凸函数 本图来自：凸函数的四种判断方法 多元函数判别法(Hessian矩阵正定性)：\n机器学习中凸函数的好处：函数具有唯一的极小值。这意味着我们求得的模型是全局最优，不会陷入局部最优（想象一下无数波浪的函数，难以在梯度下降中找到最小值）。\n信息熵、相对熵与交叉熵 请参考数学专栏中的文章（机器学习中的信息论基础）\n拉格朗日乘子法 线性回归 矩阵推导 矩阵求导方法及其完整过程请参考我的另外一篇文章：矩阵求导建议入门手册\n极大似然估计法 对数几率回归(逻辑回归) 极大似然估计法 线性判别分析 多分类学习 ECOC码 在书中，我们会看到这样的一张图： 其中涉及到所谓的海明距离与欧氏距离。 海明距离指的是：对于长度相等的两个字符串，在相同位置上不同字符的个数。\n而欧氏距离指的是多维空间中两点间绝对距离： $ dist\\left( X,Y \\right) =\\sqrt{\\sum_{i=1}^n{\\left( x_i-y_i \\right) ^2}} $ 由此我们可以计算出图中的数字，对(a)图中可有： $$ \\qquad \\text{示例}-1 {\\color{red} -1 +1 -1 }+1 \\\\ C1\\text{编码} \\ -1 {\\color{red} +1 -1 +1 }+1 $$ 容易看出海明距离为3，而欧氏距离为 $$ \\sqrt{\\left( -1-\\left( -1 \\right) \\right) ^2+\\left( -1-1 \\right) ^2+2^2+2^2+0}=2\\sqrt{3} $$ 其他值可以用相同的办法推导得到。\nReference 逻辑回归的原理、推导和常见问题 凸函数、损失函数、线性模型的基本形式、线性回归、w* 的代码实现 ","date":"2022-01-17T22:53:41+08:00","permalink":"https://sanbuphy.github.io/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%A5%BF%E7%93%9C%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%BA%8C/","title":"《机器学习》西瓜书笔记(二)"},{"content":" 初始介绍 符号规定 在本文中，我们做如下规定：\nMatrix矩阵为：$\\mathbf{A}, \\mathbf{X}, \\mathbf{Y}$ Vector向量（规定为$\\color{red} {列} $向量）为：$ \\mathbf{a}, \\mathbf{x}, \\mathbf{y}$\nScalar标量为：$a, x, y$\n分子布局 在矩阵求导中，我们有两种布局（分子与分母） 为了方便起见，本文只阐述了分子布局即：\n$$\\frac{\\partial \\mathbf{y}}{\\partial {x}}=\\left[\\begin{array}{c} \\frac{\\partial y_{1}}{\\partial x} \\\\ \\frac{\\partial y_{2}}{\\partial x} \\\\ \\vdots \\\\ \\frac{\\partial y_{m}}{\\partial x}\\end{array}\\right]\\ \\ \\ \\frac{\\partial y}{\\partial \\mathbf {x}} = \\left[\\frac{\\partial y}{\\partial x_{1}} ,\\frac{\\partial y}{\\partial x_{2}}, \\cdots ,\\frac{\\partial y}{\\partial x_{n}}\\right]$$ 分母布局为分子布局的转置。 记忆方法：分子列向量分母标量，看作长筒冰淇淋，分母看作小盒子，“能站住”。分子标量分母列向量，则盒子把冰淇淋“压倒了”。或可看最后结果的行数，是分子的行数便是分子布局。 一般的，我们会遇到如下布局,且可用记忆方法配合右图形象理解(下面是结果）： by: Reference 2 by: Reference 2 当分子为矢量、矩阵时，结果为分子的行；当分子为标量时，结果是分母转置的行。\nVector-by-Vector 另外我们有：\n$\\mathbf{y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_m \\end{bmatrix}$ $\\mathbf{x}=\\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix}$ 由 $ \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}}$ 运算后产生m行n列矩阵： $ \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} \\stackrel{\\text { def }}{=}\\left[\\begin{array}{cccc}\\frac{\\partial y_{1}}{\\partial x_{1}} \u0026amp; \\frac{\\partial y_{1}}{\\partial x_{2}} \u0026amp; \\ldots \u0026amp; \\frac{\\partial y_{1}}{\\partial x_{n}} \\\\ \\frac{\\partial y_{2}}{\\partial x_{1}} \u0026amp; \\frac{\\partial y_{2}}{\\partial x_{2}} \u0026amp; \\ldots \u0026amp; \\frac{\\partial y_{2}}{\\partial x_{n}} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots\\\\ \\frac{\\partial y_{m}}{\\partial x_{1}} \u0026amp; \\frac{\\partial y_{m}}{\\partial x_{2}} \u0026amp; \\ldots \u0026amp; \\frac{\\partial y_{m}}{\\partial x_{n}}\\end{array}\\right] $ 这种矩阵可被称为Jacobian matrix。 接下来举个例子，若我们有： $$\\mathbf{y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\end{bmatrix} \\ \\ \\ \\mathbf{x}=\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}\\ \\ 且y_1=x^2_1-2x_2 \\ ,\\ y_2=x^2_3-4x_2$$ 则能得到: $$\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} =\\begin{bmatrix} 2x_1 \u0026amp; -2 \u0026amp; 0 \\\\ 0 \u0026amp; -4 \u0026amp; 2x_3 \\\\ \\end{bmatrix} $$\nMatrix-by-Scalar 同样的，我们可以给出矩阵与向量间的运算关系： $ \\frac{\\partial \\mathbf{Y}}{\\partial {x}} \\stackrel{}{=}\\left[\\begin{array}{cccc}\\frac{\\partial Y_{11}}{\\partial x} \u0026amp; \\frac{\\partial Y_{12}}{\\partial x} \u0026amp; \\ldots \u0026amp; \\frac{\\partial Y_{1n}}{\\partial x} \\\\ \\frac{\\partial Y_{21}}{\\partial x} \u0026amp; \\frac{\\partial Y_{22}}{\\partial x} \u0026amp; \\ldots \u0026amp; \\frac{\\partial Y_{2n}}{\\partial x} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots\\\\ \\frac{\\partial Y_{m1}}{\\partial x} \u0026amp; \\frac{\\partial Y_{m2}}{\\partial x} \u0026amp; \\ldots \u0026amp; \\frac{\\partial Y_{mn}}{\\partial x}\\end{array}\\right]$ $ \\ \\ \\ \\ \\ and \\ \\ \\ \\ \\frac{\\partial y}{\\partial\\mathbf{X}} \\stackrel{}{=}\\left[\\begin{array}{cccc}\\frac{\\partial y}{\\partial X_{11}} \u0026amp; \\frac{\\partial y}{\\partial X_{21}} \u0026amp; \\ldots \u0026amp; \\frac{\\partial y}{\\partial X_{m1}} \\\\ \\frac{\\partial y}{\\partial X_{12}} \u0026amp; \\frac{\\partial y}{\\partial X_{22}} \u0026amp; \\ldots \u0026amp; \\frac{\\partial y}{\\partial X_{m2}} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots\\\\ \\frac{\\partial y}{\\partial X_{1n}} \u0026amp; \\frac{\\partial y}{\\partial X_{2n}} \u0026amp; \\ldots \u0026amp; \\frac{\\partial y}{\\partial X_{mn}}\\end{array}\\right] $\n可以注意到当矩阵在分母时$\\mathrm{X}$已经“被转置”\n常用求导公式 注：其中$\\mathbf{a},\\mathrm{A}$都不是$\\mathbf{x}, \\mathrm{X}$的函数 $$\\frac{\\mathrm{d} \\mathbf{a}}{\\mathrm{d} x} =\\mathbf{0} \\tag{1} \\qquad (column \\ matrix)$$ $$\\frac{\\mathrm{d}a }{\\mathrm{d} \\mathbf{x}} =\\mathbf{0}^{\\mathrm{T}} \\tag{2} \\qquad (row \\ matrix)$$ $$\\frac{\\mathrm{d}a }{\\mathrm{d} \\mathbf{X}} =\\mathbf{0}^{\\mathrm{T}} \\tag{3} \\qquad (matrix)$$ $$\\frac{\\mathrm{d} \\mathbf{a} }{\\mathrm{d} \\mathbf{X}} =\\mathbf{0} \\tag{4} \\qquad (matrix)$$ $$\\frac{\\mathrm{d} \\mathbf{x} }{\\mathrm{d} \\mathbf{x}} =\\mathbf{I} \\tag{5} \\qquad (matrix)$$ 若想从“直观上”理解结果为什么会有转置符，可以反复理解 (1.2)分子布局 中的右图 $$\\frac{\\mathrm{d} \\mathbf{a}^{\\mathrm{T}}\\mathbf{x} }{\\mathrm{d} \\mathbf{x}}=\\frac{\\mathrm{d} \\mathbf{x}^{\\mathrm{T}}\\mathbf{a} }{\\mathrm{d} \\mathbf{x}}=\\mathbf{a}^{\\mathrm{T}} \\tag{6} $$ $$\\frac{\\mathrm{d} \\mathbf{x}^{\\mathrm{T}}\\mathbf{x} }{\\mathrm{d} \\mathbf{x}}=2\\mathbf{x}^{\\mathrm{T}} \\tag{7} $$ $$\\frac{\\mathrm{d} ({\\mathbf{x}^{\\mathrm{T}}\\mathbf{a}})^2 }{\\mathrm{d} \\mathbf{x}}=2\\mathbf{x}^{\\mathrm{T}}\\mathbf{a}\\mathbf{a}^{\\mathrm{T}} \\tag{8} $$ $$\\frac{\\mathrm{d} \\mathbf{Ax} }{\\mathrm{d} \\mathbf{x}} =\\mathbf{A} \\tag{9} $$ $$\\frac{\\mathrm{d} \\mathbf{x}^{\\mathrm{T}}\\mathbf{A} }{\\mathrm{d} \\mathbf{x}}=\\mathbf{A}^{\\mathrm{T}} \\tag{10} $$ $$\\frac{\\mathrm{d} \\mathbf{x}^{\\mathrm{T}}\\mathbf{A}\\mathbf{x} }{\\mathrm{d} \\mathbf{x}}=\\mathbf{x}^{\\mathrm{T}}(\\mathbf{A}+\\mathbf{A}^{\\mathrm{T}}) \\tag{11} $$\n注：其中(11)用到了矩阵求导中的\u0026quot;莱布尼兹法则\u0026quot;（仔细思考前者的行列与后者的行列就可以明白）: $$\\frac{\\partial \\mathbf u^{\\mathrm{T} }\\mathbf v}{\\partial \\mathbf x} = \\mathbf u^{\\mathrm{T}} \\frac{\\partial \\mathbf v}{\\partial \\mathbf x} + \\mathbf v^{\\mathrm{T}}\\frac{\\partial \\mathbf u}{\\partial \\mathbf x}$$\n实例练习 我们会好奇一个问题：为什么大多数求导后以及求导时形式都是转置在前？ 可以这么理解，假设有参数$\\mathbf{\\Theta } =\\begin{bmatrix} \\theta_0\\\\ \\theta_1\\\\ \\theta_2 \\end{bmatrix}$ 以及列向量$\\mathbf{x}=\\begin{bmatrix} 1 \\\\ x_1 \\\\ x_2 \\end{bmatrix}$ 我们可以把多元函数表达为$$f(x_1,x_2)=\\Theta^{\\mathrm{T}} \\mathbf{x}=\\theta_0 + \\theta_1x_1 + \\theta_2x_2$$ 方便计算，且符合目的。在计算结果直觉中一定要紧紧把握结果与分子（上下拉长）分母（左右拉宽）的关系。\n多元线性回归推导 在西瓜书第三章开头中，我们需要求解最小error$\\ E=(\\boldsymbol{y}-\\mathbf{X}\\boldsymbol{\\hat{w}})^{\\mathrm{T}}(\\boldsymbol{y}-\\mathbf{X}\\boldsymbol{\\hat{w}}) $ 对其展开有：$$ \\begin{aligned}(\\boldsymbol{y}-\\mathbf{X}\\boldsymbol{\\hat{w}})^{\\mathrm{T}}(\\boldsymbol{y}-\\mathbf{X}\\boldsymbol{\\hat{w}}) \u0026amp;=(\\boldsymbol{y}^{\\mathrm{T}}-\\boldsymbol{\\hat{w}}^{\\mathrm{T}}\\mathbf{X}^{\\mathrm{T}})(\\boldsymbol{y}-\\mathbf{X}\\boldsymbol{\\hat{w}}) \\\\ \u0026amp;= \\boldsymbol{y}^{\\mathrm{T}} \\boldsymbol{y}- (\\boldsymbol{y}^{\\mathrm{T}} \\mathbf{X}) \\boldsymbol{\\hat{w}}-\\boldsymbol{\\hat{w}}^{\\mathrm{T}} (\\mathbf{X}^{\\mathrm{T}} \\boldsymbol{y}) +\\boldsymbol{\\hat{w}}^{\\mathrm{T}} (\\mathbf{X}^{\\mathrm{T}} \\mathbf{X}) \\boldsymbol{\\hat{w}} \\end{aligned}$$\n把括号中看作常数，每一项分别对 $\\boldsymbol{\\hat{w}}$ 求导，利用公式$(9),(10),(11)$可得: $$ \\frac{\\partial \\boldsymbol{E}_{\\boldsymbol{\\hat{w}}} }{\\partial \\boldsymbol{\\hat{w}}} = -\\boldsymbol{y}^{\\mathrm{T}} \\mathbf{X} - \\boldsymbol{y}^{\\mathrm{T}} \\mathbf{X} + \\boldsymbol{\\hat{w}}^{\\mathrm{T}} [\\mathbf{X}^{\\mathrm{T}} \\mathbf{X}+(\\mathbf{X}^{\\mathrm{T}} \\mathbf{X})^{\\mathrm{T}}] = -2\\boldsymbol{y}^{\\mathrm{T}} \\mathbf{X} + 2\\boldsymbol{\\hat{w}}^{\\mathrm{T}} \\mathbf{X}^{\\mathrm{T}} \\mathbf{X} $$ 令其等于零可得： $$\\boldsymbol{y}^{\\mathrm{T}} \\mathbf{X} = \\boldsymbol{\\hat{w}}^{\\mathrm{T}} \\mathbf{X}^{\\mathrm{T}} \\mathbf{X}$$ 同时转置可得： $$ \\mathbf{X}^{\\mathrm{T}} \\boldsymbol{y} = \\mathbf{X}^{\\mathrm{T}} \\mathbf{X} \\boldsymbol{\\hat{w}} $$ 若此时 $\\mathbf{X}^{\\mathrm{T}} \\mathbf{X}$ 为满秩、非奇异矩阵，我们可以得到： $$\\boldsymbol{\\hat{w}}=( \\mathbf{X}^{\\mathrm{T}} \\mathbf{X})^{-1} \\mathbf{X}^{\\mathrm{T}} \\boldsymbol{y} \\\\ \\ \\\\ Q.E.D$$\n上文公式的证明过程 如果你不知道计算结果是否正确，可以使用验算矩阵求导结果是否正确进行验证。 证明(6) $$ Let \\; s=\\boldsymbol{a}^T\\mathbf{x}={a}_1x_1+\\cdots +a_nx_n.\\quad Then,\\;\\frac{\\partial s}{\\partial x_i}=a_i \\\\ So,\\:\\frac{\\mathrm{d} \\boldsymbol{a}^{\\mathrm{T}}\\mathbf{x} }{\\mathrm{d} \\mathbf{x}}=\\frac{\\mathrm{d} s}{\\mathrm{d} \\mathbf{x}}=\\left[ \\frac{\\mathrm{d}s}{\\mathrm{d}x_1},\\frac{\\mathrm{d}s}{\\mathrm{d}x_2},\\cdots ,\\frac{\\mathrm{d}s}{\\mathrm{d}x_n} \\right] =\\left[ a_1,a_2,\\cdots ,a_n \\right] =\\boldsymbol{a}^T $$\n证明(7) $$ Let \\; s=\\boldsymbol{\\mathbf{x}}^{\\mathrm{T}}\\mathbf{x}=\\sum_i{x_{i}^{2}}. \\quad Then,\\;\\frac{\\partial s}{\\partial x_i}=2x_i \\\\ So, \\;\\; \\frac{\\mathrm{d} s}{\\mathrm{d} \\mathbf{x}}=2\\mathbf{x}^{\\mathrm{T}} $$\n证明(8) 当成复合函数即可，相信你可以自己证明！\n证明(9) 比较麻烦的方法，由： $$ \\mathbf{A}\\mathbf{x}=\\left[ \\begin{matrix} a_{11}\u0026amp;\t\\cdots\u0026amp;\ta_{1n}\\\\ \\vdots\u0026amp;\t\\ddots\u0026amp;\t\\vdots\\\\ a_{n1}\u0026amp;\t\\cdots\u0026amp;\ta_{nn}\\\\ \\end{matrix} \\right] \\left[ \\begin{array}{c} x_1\\\\ \\vdots\\\\ x_n\\\\ \\end{array} \\right] =\\left[ \\begin{array}{c} a_{11}x_1+\\cdots +a_{1n}x_n\\\\ \\vdots\\\\ a_{n1}x_1+\\cdots +a_{nn}x_n\\\\ \\end{array} \\right] $$ 再由“分子决定行，分母决定列，分别求导”原则（如果不理解可以返回开头再看一遍） 得到： $$ \\left[ \\begin{matrix} a_{11}\u0026amp;\t\\cdots\u0026amp;\ta_{1n}\\\\ \\vdots\u0026amp;\t\\ddots\u0026amp;\t\\vdots\\\\ a_{n1}\u0026amp;\t\\cdots\u0026amp;\ta_{nn}\\\\ \\end{matrix} \\right]=\\mathbf{A} $$ 比较简单的方法：（类似上面的证明）\n$$ Let\\,\\, \\boldsymbol{s}=\\mathbf{A} \\mathbf{x}. \\;\\; Then, s_i=\\sum_j{\\begin{array}{c} a_{ij}x_j\\\\ \\end{array}}, and\\,\\,\\frac{\\partial s_i}{\\partial x_j}=a_{ij}. \\\\ So, \\frac{\\mathrm{d} \\boldsymbol{s}}{\\mathrm{d} \\mathbf{x}}=A. $$\n注释:有些情况（比如矩阵对向量、向量对矩阵、矩阵对矩阵求导）可能存在不好表达的情况（详情参考Reference4)因为列向量对列向量求导本质是用雅可比矩阵定义的。在这里建议直接记住结果,或者用网站验证结果；如果会用张量指标计算也行。如果你想学习更一般地做法，可以参考附录3的文章。\nReference matrix_calculus NTU (Po-Chen Wu) Matrix Differentiation NUS(Leow Wee Kheng) 矩阵求导公式的数学推导（矩阵求导——基础篇） 机器学习中的矩阵、向量求导 ","date":"2022-01-12T21:54:58+08:00","permalink":"https://sanbuphy.github.io/p/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E7%AE%80%E6%98%93%E5%85%A5%E9%97%A8%E6%89%8B%E5%86%8C/","title":"矩阵求导简易入门手册"},{"content":" 本文为个人对西瓜书不成熟的一些理解和资料整理，欢迎批评指出意见，谢谢！(可邮箱联系physicoada@gmail.com)\n西瓜书章节一 绪论 文字版浓缩可参考：周志华机器学习笔记1 by:Vay-keen\n简易版思维导图：周志华第一章 by:Sophia-11 其中一些计算问题:\np21 如何理解假设空间 考虑到通配符，假设如文中一般原始参数的取值分别为3，3，3；则总可能值为(3+1)（3+1）（3+1）+1=65种 或者更复杂一些，可以枚举求得：枚举法理解版本空间\np22 如何理解版本空间 简单而言，版本空间用于对学习内容进行收敛，是为了收敛假设空间从而使其成为与数据集一致的所有假设的子集集合。本质是缩减假设范围，也就是我们研究问题的范围。操作上可形象理解为“矩阵边界的集合”，有上下界，需要有一定的泛化程度。 从图上理解： Photo by WIKI 从假设空间的分布缩减理解：version space算法\np24 NFL定理的推导理解 Photo by 我自己 如果还不能理解，可以参考：\n浅谈NFL没有免费的午餐定理\nNFL公式推导 如果还不能理解1/2，可参考南瓜书中的真实函数展开\n西瓜书章节二 模型评估与选择 文字浓缩版可参考：性能度量方法 假设检验\u0026amp;方差\u0026amp;偏差\n加强理解查准率、查全率以及ROC、AUC 一文带你彻底理解ROC曲线和AUC值 本文用患病的例子生动形象直观解释了所有概念。 那么，ROC、AUC具体是如何计算的呢？ 请参考南瓜书(2.20)公式，以及(2.21)。\np61 如何理解噪声与f独立从而使得最后项为0 Photo by 我自己 Photo by 我自己 其他问题 什么是P问题、NP问题和NPC问题\n部分内容未补全，慢慢补全\n","date":"2022-01-11T20:53:41+08:00","permalink":"https://sanbuphy.github.io/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%A5%BF%E7%93%9C%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%80/","title":"《机器学习》西瓜书笔记(一)"},{"content":" 注意事项 在开始菜单，需要使用管理员模式打开git bash 在linux操作中（比如git）粘贴操作是shift+insert或单击鼠标的滚轮。而复制只要选中即可。（粘贴后修改就很麻烦了，推荐先修改好再粘贴） 生成SSH账号密码 如果你是第一次使用,可以先设置git的user name和email：\ngit config --global user.name \u0026#34;这里改成你的名字\u0026#34; git config --global user.email \u0026#34;这里改成你的邮箱\u0026#34; 接下来即可生成ssh密钥：（注意别把$和#注释部分也给复制进去了，只需要复制考虑$后面的部分）\n$ ssh-keygen -t rsa -b 4096 -C \u0026#34;这里改成你的邮箱\u0026#34; # -t 密钥方式设定 # -b 密钥强度设定 # -C 注释设定 # 你会看到出现以下信息： Generating public/private rsa key pair. Enter file in which to save the key (/Users/ts/.ssh/id_rsa): /Users/ts/.ssh/id_rsa_github # 此时输入你的密钥用户名(可以是邮箱) Enter passphrase (empty for no passphrase): #此时输入你的密钥密码 Enter same passphrase again: # 再次输入密码 #以防万一忘记账户密码，你可以记在其他地方 #看到以下信息，便说明你大概率生成成功 Your identification has been saved in id_rsa_github. Your public key has been saved in id_rsa_github.pub. 接下来需要检查我们是不是真的生成成功：\n$ ls -l ~/.ssh #如果你看到以下信息，就说明已生成成功（没看到config也没关系） -rw------- 1 ts staff 938 9 15 22:53 config -rw------- 1 ts staff 3326 11 8 21:52 id_rsa_github #私密密钥 -rw-r--r-- 1 ts staff 757 11 8 21:52 id_rsa_github.pub #公开密钥 注意这个要用记事本模式打开，然后在下一步骤中粘贴 注意，这时候可能找不到密钥，但在文件夹中又看得到rsa密钥文件，此时可以在不同文件夹（可能生成在某个子类文件夹内）右键打开git bash再输入上述命令，直到能出现以上信息为止。【记住此时的文件夹，在第四步还有用】\n在github添加SSH key 这一步比较简单，在github中右上角找到settings，找到SSH and GPG keys，再选择New SSH key，把上一个步骤中的公开密钥内信息全部粘贴到key中，Title可以随便写。最后点击Add key即可完成（如果想看图文操作可以参考reference）\n最后修改与验证 此时回到第二步末尾中的文件夹，输入以下代码：\n$ vim ~/.ssh/config 此时已在命令行格式中进入文件,粘贴以下讯息：\nHost github HostName github.com IdentityFile ~/.ssh/id_rsa_github #指定私密密钥 User git 粘贴后（此时还在文件中），我们需要按ESC键跳到命令模式，然后输入下列指令：\n$ :wq #冒号是必须的，意思是保存文件并退出vi 最后修正权限：\n$ chmod 600 ~/.ssh/config 接下来我们尝试连接，首先确认ssh-agent是否正常运行:\n$ eval \u0026#34;$(ssh-agent -s)\u0026#34; Agent pid 32047 # 出现类似信息则表示正常运行 $ ssh-add ~/.ssh/id_rsa_github Enter passphrase for /Users/ts/.ssh/id_rsa_github: # 此时输入第二步中设定的密码 Identity added: /Users/ts/.ssh/id_rsa_github (/Users/ts/.ssh/id_rsa_github) 最后进行连接！\n$ ssh -T git@github.com Hi mackerel7! You\u0026#39;ve successfully authenticated, but GitHub does not provide shell access. #恭喜你，当出现如上信息则表示你已经成功链接！ Reference GitHubにssh接続できるようにする GitHub如何配置SSH Key ","date":"2022-01-05T22:54:06+08:00","permalink":"https://sanbuphy.github.io/p/%E5%88%A9%E7%94%A8git%E7%94%9F%E6%88%90ssh%E5%B9%B6%E4%B8%8Egithub%E8%BF%9E%E6%8E%A5/","title":"利用git生成SSH并与github连接"},{"content":" 机器学习的数学基础 基础不牢地动山摇，好好打数理基础！但一口吃不成大胖子—— 有答主提到：\n”在很多相关的回答中，我都一再强调不要试图补足数学知识再开始学习机器学习。一般来说，大部分机器学习课程/书籍都要求：\n线性代数：矩阵/张量乘法、求逆，奇异值分解/特征值分解，行列式，范数等 统计与概率：概率分布，独立性与贝叶斯，最大似然（MLE）和最大后验估计（MAP）等 优化：线性优化，非线性优化(凸优化/非凸优化)以及其衍生的求解方法如梯度下降、牛顿法、基因算法和模拟退火等 微积分：偏微分，链式法则，矩阵求导等 信息论、数值理论等\n一般人如果想要把这些知识都补全再开始机器学习往往需要很长时间，容易半途而废。而且这些知识是工具不是目的，我们的目标不是成为优化大师。建议在机器学习的过程中哪里不会补哪里，这样更有目的性且耗时更低。” [本文只包含开源部分的下载链接] 线性代数 Introduction to Linear Algebra 适合入门、相对简单友好的书\n下载地址 视频教程 台湾清华大学 趙啟超教授 课程首页\n矩阵求导相关 推荐一下我自己写的入门：矩阵求导简易入门手册 台湾大学 Matrix Calculu by Po-Chen Wu 我个人觉得是简要却齐全的速成ppt。 查阅手册：matrixcookbook 在线计算与验证：MatrixCalculus 线性代数 拓展(应用数学系) 線性代數(一) Linear Algebra I 视频地址 線性代數(二) Linear Algebra II 课程用书：Linear Algebra, 4th Edition, S. Friedberg, A. Insel and L. Spence, 2003, Prentice Hall.\n概率论与统计学 洪永淼 概率论与统计学 课件与习题解答\nMathematics for Machine Learning 本书主页 下载地址 学习视频及其笔记 本书结构： Part I: Mathematical Foundations Introduction and Motivation\nLinear Algebra Analytic Geometry Matrix Decompositions\nVector Calculus\nProbability and Distribution Continuous Optimization\nPart II: Central Machine Learning Problems When Models Meet Data\nLinear Regression\nDimensionality Reduction with Principal Component Analysis Density Estimation with Gaussian Mixture Models\nClassification with Support Vector Machines\n机器学习入门 李宏毅2021春机器学习课程 课程地址： https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.html\n课件和资料Github版： https://github.com/Fafa-DL/Lhy_Machine_Learning 可参考笔记： https://github.com/unclestrong/DeepLearning_LHY21_Notes\n机器学习实战：基于Scikit-Learn和TensorFlow 好书，看就完了!!（翻译可能有时候不靠谱） [涉及到的代码]](https://github.com/ageron/handson-ml2)\npython机器学习手册 本书的特色是任务制学习\n机器学习进阶 李航老师 统计学习 入门选手可参考学习路径 Photo by NLP从入门到放弃 深度学习 待更新（开摆）\n计算机视觉 待更新（开摆）\nReference 如何用3个月零基础入门「机器学习」？by微 三个月从零入门深度学习，保姆级学习路线图 刘建平博客 ","date":"2021-12-31T19:48:48+08:00","image":"https://sanbuphy.github.io/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E8%B7%AF%E5%BE%84%E5%8F%8A%E5%85%B6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/knowledge-3_hu3adb970a553883b0b7ae744c75f65cb9_2096564_120x120_fill_q75_box_smart1.jpg","permalink":"https://sanbuphy.github.io/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E8%B7%AF%E5%BE%84%E5%8F%8A%E5%85%B6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/","title":"机器学习入门路径及其数学基础"},{"content":" 前置要求 你可能需要学习如何使用git，可参考本博中的教程或观看狂神git简单教程。 你也许也想知道怎么利用GitHub Desktop上传东西到github上，可参考GitHub Desktop 的使用教程 认识hugo Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。 中文文档地址： https://www.gohugo.org/ 图文安装教程1 图文安装教程2\nhugo的结构 hugo的基本用法和页面改造\nhugo中文帮助文档\n皮肤下载 https://www.gohugo.org/theme/ 注：我用的是hahwul 写的stack： https://github.com/CaiJimmy/hugo-theme-stack\n主题手册\n建议安装方法：\nhugo new site myblog 在myblog/config.toml加一行 theme=xxxx（下载后theme文件夹的名） 下载放到theme 把example的config和yaml覆盖放到首页（首页的config是空的） hugo server markdown语法检索 https://www.appinn.com/markdown/#%E5%AE%97%E6%97%A8 常见的markdown写法\n创建你的第一个文章 使用 hugo new xxxxx.md 注意命名时不可以空格，可以用-代替\n然后就可以使用 hugo server 来查看效果啦！\n发布你的博客 我们将使用github.io来代替服务器以及域名：推荐参考教程 几个注意事项：\nGit要上传或执行的文件可以在文件夹中，右键空白地区点git bash here从而实现目录内操作。 在linux操作中（比如git）粘贴操作是shift+insert或单击鼠标的滚轮。而复制只要选中即可。 **【非常重要】**github的域名地址与用户名必须一致，比如你的github名字叫sakura，那么域名必须是sakura.github.io。 hugo命令 hugo --baseUrl=\u0026quot;https://改为你的名字.github.io/\u0026quot;执行完后，会生成一个public文件夹，在public文件中执行1.操作即可推送。 用git推送的时候 git pull --rebase origin master语句可能会出错显示没有文件，不用担心，这是因为此时目标仓库是空的，直接下一步最后，你只需要输入对应网址，即可看到自己的宝贝博客了！ *（可选）如果你想给博客加上评论系统，请参考这样的流程:WALINE且记得修改config.yaml配置文件中的commit和对应waline项即可 更新你的博客 在博客目录下使用 hugo --baseUrl=\u0026quot;https://改为你的名字.github.io/\u0026quot;覆盖原来的public文件夹 进入public文件夹右键git bash 分别执行 git add . // git commit -m \u0026lsquo;写你的备注\u0026rsquo; // git push 可能存在的问题： 界面出现404 使用Shift+F5强制刷新页面 检查域名是否和github的名字对应 github上存放文件的仓库是否只有一个分支（创建时不要勾选生成README.md) 正常public上传github仓库后会只有一个分支，且包含了public内的所有文件 文章看不到 检查是否格式正确，使用了hugo new xxxx.md 检查是否包含了 draft: true，若有则删除或使用 hugo server -D，若草稿模式开启是看不到文章的 数学公式不显示 是否使用了 math: true，或尝试导入MathJax包，可参考Hugo に MathJax を導入して数式を書けるようにする或者分离式的mathjax调用方法HugoでMathJaxを使うMathJax的中文文档：https://www.gohugo.org/doc/tutorials/mathjax/Mathjax的日文文档：https://www.eng.niigata-u.ac.jp/~nomoto/download/mathjax.pdf\n注意此时 \\\\换行不成功的话，用 \\\\\\试试看，有些 \\,的无效也可以用 \\\\,代替尝试。\n有时候数学公式正确也会显示不出来，此时你可以检查代码界面或网页公式处是否存在斜体如\u0026quot;_j\u0026quot;，此时改为\u0026quot;_j\u0026quot;即可恢复正常，特别是_{}时要注意，可以把开始倾斜的代码（找到这里的\u0026quot;_\u0026quot;)改为_{}就可以正常显示。\n文章图片加载很慢 可以参考这个文章Hugo Content 使用图源、压缩与工具介绍 文章头看到了不同的格式比如+++与\u0026mdash; Front Matter支持三种格式，yaml，toml与json方式，你可以参考：基础文件和头部格式介绍 git push不成功 此时大概率是网络通信有问题，可以关掉git终端后科学上网；重启git 终端后（windows需要，linux系统不需要）再进行push大概率就可以解决问题了；此时无需再进行git init 等初始化操作因为之前已经做完。 ","date":"2021-12-28T18:39:12+08:00","permalink":"https://sanbuphy.github.io/p/%E5%A6%82%E4%BD%95%E8%BF%90%E7%94%A8hugo%E4%B8%8Egithub.io%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","title":"如何运用hugo与github.io搭建个人博客"},{"content":" 环境配置相关 anaconda anaconda与Jupyter notebook安装教程https://zhuanlan.zhihu.com/p/37093476 国内的anaconda镜像下载：https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/ anaconda更新与下载包的镜像源更换：https://zhuanlan.zhihu.com/p/35985834 计算机原理 从二进制到处理器原理\nGIT小知识 要熟练使用 Git，恐怕要记住这60个命令 git 入门小知识\n其他数学 数学之美番外篇：平凡而又神奇的贝叶斯方法\n","date":"2021-12-28T18:39:12+08:00","permalink":"https://sanbuphy.github.io/p/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9F%A5%E8%AF%86%E5%BA%93/","title":"杂七杂八知识库"}]